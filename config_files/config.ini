# The base configuration of the benchamrk
[Base]
log =           bool ; yes
name =          list_str ; Plausible
label =         str ; _
type =          str ; .hdf5
views =         list_str ; all
pathF =         str ; ../Data/
nice =          int ; 0
randomState =   str ; 42
nbCores =       int ; 1
full =          bool ; yes
debug =         bool ; yes
add_noise =     bool ; yes
noise_std =     list_float ; 0.0
res_dir =       str ; ../Results/


# All the classification-realted configuration options
[Classification]
multiclassMethod = str ; oneVersusOne
split = float ; 0.8
nbFolds = int ; 2
nbClass = int ; 2
classes = list_str ; yes no
type = list_str ; multiview
algos_monoview = list_str ; all
algos_multiview = list_str ; all
statsiter = int ; 2
metrics = list_str ; accuracy_score f1_score
metric_princ = str ; f1_score
HPS_type = str ; randomized_search
HPS_iter = int ; 2



#####################################
# The Monoview Classifier arguments #
#####################################

[random_forest]
n_estimators = list_int ; 25
max_depth = list_int ; 3
criterion = list_str ; entropy

[svm_linear]
C = list_float ; 1

[svm_rbf]
C = list_float ; 1

[svm_poly]
C = list_float ; 1
degree = list_int ; 2

[adaboost]
n_estimators = list_int ; 50
base_estimator = list_str ; DecisionTreeClassifier

[adaboost_pregen]
n_estimators = list_int ; 50
base_estimator = list_str ; DecisionTreeClassifier
n_stumps = list_int ; 1

[adaboost_graalpy]
n_iterations = list_int ; 50
n_stumps = list_int ; 1

[decision_tree]
max_depth = list_int ; 10
criterion = list_str ; gini
splitter = list_str ; best

[decision_tree_pregen]
max_depth = list_int ; 10
criterion = list_str ; gini
splitter = list_str ; best
n_stumps = list_int ; 1

[sgd]
loss = list_str ; hinge
penalty = list_str ; l2
alpha = list_float ; 0.0001

[knn]
n_neighbors = list_int ; 5
weights = list_str ; uniform
algorithm = list_str ; auto

[scm]
model_type = list_str ; conjunction
max_rules = list_int ; 10
p = list_float ; 0.1

[scm_pregen]
model_type = list_str ; conjunction
max_rules = list_int ; 10
p = list_float ; 0.1
n_stumps = list_int ; 1

[cq_boost]
mu = list_float ; 0.01
epsilon = list_float ; 1e-06
n_max_iterations = list_int ; 5
n_stumps = list_int ; 1

[cg_desc]
n_max_iterations = list_int ; 10
n_stumps = list_int ; 1

[cb_boost]
n_max_iterations = list_int ; 10
n_stumps = list_int ; 1

[min_cq_graalpy]
mu = list_float ; 0.01
n_stumps_per_attribute = list_int ; 1

[min_cq_graalpy_tree]
mu = list_float ; 0.01
n_stumps_per_attribute = list_int ; 1
max_depth = list_int ; 2

[lasso]
alpha = list_float ; 1
max_iter = list_int ; 2

[gradient_boosting]
n_estimators = list_int ; 2

[min_cq]
mu = list_float ; 0.01
n_stumps_per_attribute = list_int ; 1


######################################
# The Multiview Classifier arguments #
######################################

[weighted_linear_early_fusion]
view_weights = list_str ; None
monoview_classifier = list_str ; decision_tree

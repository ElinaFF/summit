{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Imports </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os as os        # for iteration throug directories\n",
    "import pandas as pd # for Series and DataFrames\n",
    "import cv2          # for OpenCV \n",
    "import numpy as np  # for arrays\n",
    "import time       # for time calculations\n",
    "from feature_extraction_try import imgCrawl, getClassLabels #for fetching images\n",
    "from skimage.feature import hog #calculates HOGs \n",
    "from sklearn.cluster import MiniBatchKMeans #for clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>HOG computation :</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this file, we aim to compute a HOG descriptor thas has the same dimension for each image. So we used a bag of word approach : \n",
    "<ul>\n",
    "    <li>Resizing images to a 0mod5 height and width</li>\n",
    "    <li>Sequencing each image in 5*5 cells</li>\n",
    "    <li>Computing local histograms on each cell</li>\n",
    "    <li>Clustering the local histograms</li>\n",
    "    <li>Binning the local histograms to create our feature</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Resizing images : </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reSize(image, CELL_DIMENSION):\n",
    "  height, width, channels = image.shape\n",
    "  if height%CELL_DIMENSION==0 and width%CELL_DIMENSION==0:\n",
    "    resizedImage = image\n",
    "  elif width%CELL_DIMENSION==0:\n",
    "    missingPixels = CELL_DIMENSION-height%CELL_DIMENSION\n",
    "    resizedImage = cv2.copyMakeBorder(image,0,missingPixels,0,0,cv2.BORDER_REPLICATE)\n",
    "  elif height%CELL_DIMENSION==0:\n",
    "    missingPixels = CELL_DIMENSION-width%CELL_DIMENSION\n",
    "    resizedImage = cv2.copyMakeBorder(image,0,0,0,missingPixels,cv2.BORDER_REPLICATE)\n",
    "  else:\n",
    "    missingWidthPixels = CELL_DIMENSION-width%CELL_DIMENSION\n",
    "    missingHeightPixels = CELL_DIMENSION-height%CELL_DIMENSION\n",
    "    resizedImage = cv2.copyMakeBorder(image,0,missingHeightPixels,0,missingWidthPixels,cv2.BORDER_REPLICATE)\n",
    "  return resizedImage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Sequencing images : </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def imageSequencing(npImages, CELL_DIMENSION):\n",
    "  blocks=[]\n",
    "  for k in range(len(npImages)):\n",
    "    image = cv2.imread(npImages[k][1])\n",
    "    resizedImage = reSize(image, CELL_DIMENSION)\n",
    "    height, width, channels = resizedImage.shape\n",
    "    blocks.append(\\\n",
    "      np.array([\\\n",
    "        resizedImage[\\\n",
    "          j*CELL_DIMENSION:j*CELL_DIMENSION+CELL_DIMENSION,\\\n",
    "          i*CELL_DIMENSION:i*CELL_DIMENSION+CELL_DIMENSION] \\\n",
    "        for i in range(width/CELL_DIMENSION) \\\n",
    "        for j in range(height/CELL_DIMENSION)\\\n",
    "      ])\\\n",
    "    )\n",
    "  return np.array(blocks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Compute HOG descriptor on each cell : </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hogAllBlocks(blocks):\n",
    "  print blocks[0][0].shape\n",
    "  gradients = np.array([np.array([hog(cv2.cvtColor(block, cv2.COLOR_BGR2GRAY), orientations=8, pixels_per_cell=(5,5), cells_per_block=(1,1)) for block in image]) for image in blocks])\n",
    "  print gradients.shape\n",
    "  return gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Clustering local HOGs : </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clusterGradients(gradients, NB_CLUSTERS, MAXITER):\n",
    "  sizes = np.array([len(gradient) for gradient in gradients])\n",
    "  nbImages =  len(gradients)\n",
    "  flattenedHogs = np.array([block for image in gradients for block in image])\n",
    "  miniBatchKMeans = MiniBatchKMeans(n_clusters=NB_CLUSTERS, max_iter=MAXITER, compute_labels=True)\n",
    "  hogsLabels = miniBatchKMeans.fit_predict(flattenedHogs)\n",
    "  return hogsLabels, sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Binning local HOGs : </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def makeHistograms(labels, NB_CLUSTERS, sizes):\n",
    "  indiceInLabels = 0\n",
    "  hogs = []\n",
    "  for image in sizes:\n",
    "    histogram = np.zeros(NB_CLUSTERS)\n",
    "    for i in range(image):\n",
    "      histogram[labels[indiceInLabels+i]] += 1\n",
    "    hogs.append(histogram)\n",
    "    indiceInLabels+=i \n",
    "  return np.array(hogs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Test zone</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "\n",
    "  start = time.time()\n",
    "  path ='../../03-jeux-de-donnees/101_ObjectCategories'\n",
    "  testNpImages = [ [1,'testImage.jpg'] ]\n",
    "  NB_CLUSTERS = 12\n",
    "  MAXITER = 100\n",
    "  print testNpImages[0][1]\n",
    "  print \"Fetching Images in \" + path\n",
    "\n",
    "  # get dictionary to link classLabels Text to Integers\n",
    "  # sClassLabels = getClassLabels(path)\n",
    "\n",
    "  # Get all path from all images inclusive classLabel as Integer\n",
    "  # dfImages = imgCrawl(path, sClassLabels)\n",
    "  # npImages = dfImages.values\n",
    "  extractedTime = time.time()\n",
    "  print \"Extracted images in \" + str(extractedTime-start) +'sec'\n",
    "  print \"Sequencing Images ...\"\n",
    "  blocks = imageSequencing(testNpImages, 5)\n",
    "  sequencedTime = time.time()\n",
    "  print \"Sequenced images in \" + str(sequencedTime-extractedTime) +'sec'\n",
    "  print \"Computing gradient on each block ...\"\n",
    "  gradients = hogAllBlocks(blocks)\n",
    "  hogedTime = time.time()\n",
    "  print \"Computed gradients in \" + str(hogedTime - sequencedTime) + 'sec'\n",
    "  print \"Clustering gradients ...\"\n",
    "  gradientLabels, sizes = clusterGradients(gradients, NB_CLUSTERS, MAXITER)\n",
    "  clusteredItme = time.time()\n",
    "  print \"Clustered gradients in \" + str(hogedTime - sequencedTime) + 'sec'\n",
    "  print \"Computing histograms ...\"\n",
    "  histograms = makeHistograms(gradientLabels, NB_CLUSTERS, sizes)\n",
    "  end = time.time()\n",
    "  print \"Computed histograms in \" + str(int(end - hogedTime)) + 'sec'\n",
    "  print \"Total time : \" + str(end-start) + 'sec'\n",
    "  print \"Histogram shape : \" +str(histograms.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

2017-09-22 14:54:08,064 DEBUG: Info:	 Enough copies of the dataset are already available
2017-09-22 14:54:08,067 INFO: Start:	 Finding all available mono- & multiview algorithms
2017-09-22 14:54:08,142 DEBUG: Start:	 Loading data
2017-09-22 14:54:08,142 DEBUG: Start:	 Loading data
2017-09-22 14:54:08,155 DEBUG: Done:	 Loading data
2017-09-22 14:54:08,155 DEBUG: Done:	 Loading data
2017-09-22 14:54:08,155 DEBUG: Info:	 Classification - Database:awaexp Feature:cq-hist train_size:0.7, CrossValidation k-folds:2, cores:1, algorithm : Adaboost
2017-09-22 14:54:08,155 DEBUG: Info:	 Classification - Database:awaexp Feature:cq-hist train_size:0.7, CrossValidation k-folds:2, cores:1, algorithm : DecisionTree
2017-09-22 14:54:08,156 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 14:54:08,156 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 14:54:08,186 DEBUG: Info:	 Shape X_train:(766, 2688), Length of y_train:766
2017-09-22 14:54:08,186 DEBUG: Info:	 Shape X_train:(766, 2688), Length of y_train:766
2017-09-22 14:54:08,186 DEBUG: Info:	 Shape X_test:(326, 2688), Length of y_test:326
2017-09-22 14:54:08,186 DEBUG: Info:	 Shape X_test:(326, 2688), Length of y_test:326
2017-09-22 14:54:08,187 DEBUG: Done:	 Determine Train/Test split
2017-09-22 14:54:08,187 DEBUG: Done:	 Determine Train/Test split
2017-09-22 14:54:08,187 DEBUG: Start:	 RandomSearch best settings with 2 iterations for DecisionTree
2017-09-22 14:54:08,187 DEBUG: Start:	 RandomSearch best settings with 2 iterations for Adaboost
2017-09-22 14:54:11,193 DEBUG: Done:	 RandomSearch best settings
2017-09-22 14:54:11,193 DEBUG: Start:	 Training
2017-09-22 14:54:11,406 DEBUG: Done:	 RandomSearch best settings
2017-09-22 14:54:11,406 DEBUG: Start:	 Training
2017-09-22 14:54:12,138 DEBUG: Done:	 Training
2017-09-22 14:54:12,138 DEBUG: Start:	 Predicting
2017-09-22 14:54:12,155 DEBUG: Done:	 Predicting
2017-09-22 14:54:12,155 DEBUG: Info:	 Time for training and predicting: 4.01276493073[s]
2017-09-22 14:54:12,155 DEBUG: Start:	 Getting Results
2017-09-22 14:54:12,185 DEBUG: Done:	 Getting Results
2017-09-22 14:54:12,185 INFO: Classification on awaexp database for cq-hist with DecisionTree, and 2 statistical iterations

accuracy_score on train : 1.0, with STD : 0.0
accuracy_score on test : 0.677914110429, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : cq-hist	 View shape : (1092, 2688)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 2

Classifier configuration : 
	- Decision Tree with max_depth : 28
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 2 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.677914110429
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.672897196262
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.672897196262
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.0
		- Score on test : 0.322085889571
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.677914110429
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.355995746702
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.683544303797
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.662576687117
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.677914110429
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.0
		- Score on test : 0.322085889571


 Classification took 0:00:04
2017-09-22 14:54:12,185 INFO: Done:	 Result Analysis
2017-09-22 14:54:12,288 DEBUG: Done:	 Training
2017-09-22 14:54:12,289 DEBUG: Start:	 Predicting
2017-09-22 14:54:12,308 DEBUG: Done:	 Predicting
2017-09-22 14:54:12,308 DEBUG: Info:	 Time for training and predicting: 4.16530394554[s]
2017-09-22 14:54:12,308 DEBUG: Start:	 Getting Results
2017-09-22 14:54:12,335 DEBUG: Done:	 Getting Results
2017-09-22 14:54:12,335 INFO: Classification on awaexp database for cq-hist with Adaboost, and 2 statistical iterations

accuracy_score on train : 1.0, with STD : 0.0
accuracy_score on test : 0.628834355828, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : cq-hist	 View shape : (1092, 2688)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 2

Classifier configuration : 
	- Adaboost with num_esimators : 6, base_estimators : DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best')
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 2 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.628834355828
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.618296529968
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.618296529968
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.0
		- Score on test : 0.371165644172
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.628834355828
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.258062384906
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.636363636364
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.601226993865
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.628834355828
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.0
		- Score on test : 0.371165644172


 Classification took 0:00:04
2017-09-22 14:54:12,336 INFO: Done:	 Result Analysis
2017-09-22 14:54:12,406 DEBUG: Start:	 Loading data
2017-09-22 14:54:12,406 DEBUG: Start:	 Loading data
2017-09-22 14:54:12,419 DEBUG: Done:	 Loading data
2017-09-22 14:54:12,419 DEBUG: Done:	 Loading data
2017-09-22 14:54:12,420 DEBUG: Info:	 Classification - Database:awaexp Feature:cq-hist train_size:0.7, CrossValidation k-folds:2, cores:1, algorithm : KNN
2017-09-22 14:54:12,420 DEBUG: Info:	 Classification - Database:awaexp Feature:cq-hist train_size:0.7, CrossValidation k-folds:2, cores:1, algorithm : RandomForest
2017-09-22 14:54:12,420 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 14:54:12,420 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 14:54:12,451 DEBUG: Info:	 Shape X_train:(766, 2688), Length of y_train:766
2017-09-22 14:54:12,451 DEBUG: Info:	 Shape X_train:(766, 2688), Length of y_train:766
2017-09-22 14:54:12,451 DEBUG: Info:	 Shape X_test:(326, 2688), Length of y_test:326
2017-09-22 14:54:12,451 DEBUG: Info:	 Shape X_test:(326, 2688), Length of y_test:326
2017-09-22 14:54:12,451 DEBUG: Done:	 Determine Train/Test split
2017-09-22 14:54:12,451 DEBUG: Done:	 Determine Train/Test split
2017-09-22 14:54:12,451 DEBUG: Start:	 RandomSearch best settings with 2 iterations for RandomForest
2017-09-22 14:54:12,451 DEBUG: Start:	 RandomSearch best settings with 2 iterations for KNN
2017-09-22 14:54:12,672 DEBUG: Done:	 RandomSearch best settings
2017-09-22 14:54:12,672 DEBUG: Start:	 Training
2017-09-22 14:54:12,696 DEBUG: Done:	 Training
2017-09-22 14:54:12,696 DEBUG: Start:	 Predicting
2017-09-22 14:54:12,719 DEBUG: Done:	 Predicting
2017-09-22 14:54:12,719 DEBUG: Info:	 Time for training and predicting: 0.312060832977[s]
2017-09-22 14:54:12,719 DEBUG: Start:	 Getting Results
2017-09-22 14:54:12,762 DEBUG: Done:	 Getting Results
2017-09-22 14:54:12,762 INFO: Classification on awaexp database for cq-hist with RandomForest, and 2 statistical iterations

accuracy_score on train : 0.791122715405, with STD : 0.0
accuracy_score on test : 0.687116564417, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : cq-hist	 View shape : (1092, 2688)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 2

Classifier configuration : 
	- Random Forest with num_esimators : 1, max_depth : 6
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 2 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 0.791122715405
		- Score on test : 0.687116564417
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.780821917808
		- Score on test : 0.677215189873
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 0.780821917808
		- Score on test : 0.677215189873
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.208877284595
		- Score on test : 0.312883435583
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 0.791122715405
		- Score on test : 0.687116564417
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 0.584834675032
		- Score on test : 0.374939389614
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.821325648415
		- Score on test : 0.699346405229
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.744125326371
		- Score on test : 0.656441717791
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 0.791122715405
		- Score on test : 0.687116564417
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.208877284595
		- Score on test : 0.312883435583


 Classification took 0:00:00
2017-09-22 14:54:12,763 INFO: Done:	 Result Analysis
2017-09-22 14:54:15,117 DEBUG: Done:	 RandomSearch best settings
2017-09-22 14:54:15,117 DEBUG: Start:	 Training
2017-09-22 14:54:15,167 DEBUG: Done:	 Training
2017-09-22 14:54:15,167 DEBUG: Start:	 Predicting
2017-09-22 14:54:18,032 DEBUG: Done:	 Predicting
2017-09-22 14:54:18,032 DEBUG: Info:	 Time for training and predicting: 5.62530589104[s]
2017-09-22 14:54:18,033 DEBUG: Start:	 Getting Results
2017-09-22 14:54:18,067 DEBUG: Done:	 Getting Results
2017-09-22 14:54:18,067 INFO: Classification on awaexp database for cq-hist with KNN, and 2 statistical iterations

accuracy_score on train : 1.0, with STD : 0.0
accuracy_score on test : 0.610429447853, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : cq-hist	 View shape : (1092, 2688)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 2

Classifier configuration : 
	- K nearest Neighbors with  n_neighbors: 1
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 2 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.610429447853
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.609230769231
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.609230769231
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.0
		- Score on test : 0.389570552147
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.610429447853
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.22086305215
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.611111111111
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.60736196319
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.610429447853
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.0
		- Score on test : 0.389570552147


 Classification took 0:00:05
2017-09-22 14:54:18,067 INFO: Done:	 Result Analysis
2017-09-22 14:54:18,182 DEBUG: Start:	 Loading data
2017-09-22 14:54:18,182 DEBUG: Start:	 Loading data
2017-09-22 14:54:18,196 DEBUG: Done:	 Loading data
2017-09-22 14:54:18,196 DEBUG: Done:	 Loading data
2017-09-22 14:54:18,196 DEBUG: Info:	 Classification - Database:awaexp Feature:cq-hist train_size:0.7, CrossValidation k-folds:2, cores:1, algorithm : SGD
2017-09-22 14:54:18,196 DEBUG: Info:	 Classification - Database:awaexp Feature:cq-hist train_size:0.7, CrossValidation k-folds:2, cores:1, algorithm : SVMLinear
2017-09-22 14:54:18,196 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 14:54:18,196 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 14:54:18,226 DEBUG: Info:	 Shape X_train:(766, 2688), Length of y_train:766
2017-09-22 14:54:18,226 DEBUG: Info:	 Shape X_train:(766, 2688), Length of y_train:766
2017-09-22 14:54:18,226 DEBUG: Info:	 Shape X_test:(326, 2688), Length of y_test:326
2017-09-22 14:54:18,226 DEBUG: Info:	 Shape X_test:(326, 2688), Length of y_test:326
2017-09-22 14:54:18,226 DEBUG: Done:	 Determine Train/Test split
2017-09-22 14:54:18,226 DEBUG: Done:	 Determine Train/Test split
2017-09-22 14:54:18,226 DEBUG: Start:	 RandomSearch best settings with 2 iterations for SGD
2017-09-22 14:54:18,226 DEBUG: Start:	 RandomSearch best settings with 2 iterations for SVMLinear
2017-09-22 14:54:18,808 DEBUG: Done:	 RandomSearch best settings
2017-09-22 14:54:18,808 DEBUG: Start:	 Training
2017-09-22 14:54:18,950 DEBUG: Done:	 Training
2017-09-22 14:54:18,951 DEBUG: Start:	 Predicting
2017-09-22 14:54:18,961 DEBUG: Done:	 Predicting
2017-09-22 14:54:18,961 DEBUG: Info:	 Time for training and predicting: 0.778836965561[s]
2017-09-22 14:54:18,961 DEBUG: Start:	 Getting Results
2017-09-22 14:54:18,993 DEBUG: Done:	 Getting Results
2017-09-22 14:54:18,993 INFO: Classification on awaexp database for cq-hist with SGD, and 2 statistical iterations

accuracy_score on train : 0.569190600522, with STD : 0.0
accuracy_score on test : 0.552147239264, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : cq-hist	 View shape : (1092, 2688)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 2

Classifier configuration : 
	- SGDClassifier with loss : modified_huber, penalty : elasticnet
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 2 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 0.569190600522
		- Score on test : 0.552147239264
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.663265306122
		- Score on test : 0.657276995305
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 0.663265306122
		- Score on test : 0.657276995305
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.430809399478
		- Score on test : 0.447852760736
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 0.569190600522
		- Score on test : 0.552147239264
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 0.166857353772
		- Score on test : 0.132068964403
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.544388609715
		- Score on test : 0.532319391635
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.848563968668
		- Score on test : 0.858895705521
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 0.569190600522
		- Score on test : 0.552147239264
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.430809399478
		- Score on test : 0.447852760736


 Classification took 0:00:00
2017-09-22 14:54:18,994 INFO: Done:	 Result Analysis
2017-09-22 14:54:21,791 DEBUG: Done:	 RandomSearch best settings
2017-09-22 14:54:21,791 DEBUG: Start:	 Training
2017-09-22 14:54:27,205 DEBUG: Done:	 Training
2017-09-22 14:54:27,205 DEBUG: Start:	 Predicting
2017-09-22 14:54:29,979 DEBUG: Done:	 Predicting
2017-09-22 14:54:29,979 DEBUG: Info:	 Time for training and predicting: 11.7960519791[s]
2017-09-22 14:54:29,979 DEBUG: Start:	 Getting Results
2017-09-22 14:54:30,006 DEBUG: Done:	 Getting Results
2017-09-22 14:54:30,006 INFO: Classification on awaexp database for cq-hist with SVMLinear, and 2 statistical iterations

accuracy_score on train : 1.0, with STD : 0.0
accuracy_score on test : 0.601226993865, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : cq-hist	 View shape : (1092, 2688)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 2

Classifier configuration : 
	- SVM Linear with C : 8934
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 2 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.601226993865
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.606060606061
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.606060606061
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.0
		- Score on test : 0.398773006135
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.601226993865
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.202514974737
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.59880239521
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.613496932515
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.601226993865
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.0
		- Score on test : 0.398773006135


 Classification took 0:00:11
2017-09-22 14:54:30,006 INFO: Done:	 Result Analysis
2017-09-22 14:54:30,168 DEBUG: Start:	 Loading data
2017-09-22 14:54:30,168 DEBUG: Start:	 Loading data
2017-09-22 14:54:30,181 DEBUG: Done:	 Loading data
2017-09-22 14:54:30,181 DEBUG: Info:	 Classification - Database:awaexp Feature:cq-hist train_size:0.7, CrossValidation k-folds:2, cores:1, algorithm : SVMPoly
2017-09-22 14:54:30,181 DEBUG: Done:	 Loading data
2017-09-22 14:54:30,181 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 14:54:30,181 DEBUG: Info:	 Classification - Database:awaexp Feature:cq-hist train_size:0.7, CrossValidation k-folds:2, cores:1, algorithm : SVMRBF
2017-09-22 14:54:30,181 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 14:54:30,212 DEBUG: Info:	 Shape X_train:(766, 2688), Length of y_train:766
2017-09-22 14:54:30,212 DEBUG: Info:	 Shape X_train:(766, 2688), Length of y_train:766
2017-09-22 14:54:30,212 DEBUG: Info:	 Shape X_test:(326, 2688), Length of y_test:326
2017-09-22 14:54:30,212 DEBUG: Info:	 Shape X_test:(326, 2688), Length of y_test:326
2017-09-22 14:54:30,212 DEBUG: Done:	 Determine Train/Test split
2017-09-22 14:54:30,212 DEBUG: Done:	 Determine Train/Test split
2017-09-22 14:54:30,212 DEBUG: Start:	 RandomSearch best settings with 2 iterations for SVMPoly
2017-09-22 14:54:30,212 DEBUG: Start:	 RandomSearch best settings with 2 iterations for SVMRBF
2017-09-22 14:54:34,657 DEBUG: Done:	 RandomSearch best settings
2017-09-22 14:54:34,657 DEBUG: Start:	 Training
2017-09-22 14:54:35,136 DEBUG: Done:	 RandomSearch best settings
2017-09-22 14:54:35,136 DEBUG: Start:	 Training
2017-09-22 14:54:41,935 DEBUG: Done:	 Training
2017-09-22 14:54:41,935 DEBUG: Start:	 Predicting
2017-09-22 14:54:42,389 DEBUG: Done:	 Training
2017-09-22 14:54:42,389 DEBUG: Start:	 Predicting
2017-09-22 14:54:45,803 DEBUG: Done:	 Predicting
2017-09-22 14:54:45,803 DEBUG: Info:	 Time for training and predicting: 15.6344819069[s]
2017-09-22 14:54:45,803 DEBUG: Start:	 Getting Results
2017-09-22 14:54:45,834 DEBUG: Done:	 Getting Results
2017-09-22 14:54:45,834 INFO: Classification on awaexp database for cq-hist with SVMRBF, and 2 statistical iterations

accuracy_score on train : 0.966057441253, with STD : 0.0
accuracy_score on test : 0.696319018405, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : cq-hist	 View shape : (1092, 2688)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 2

Classifier configuration : 
	- SVM RBF with C : 7097
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 2 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 0.966057441253
		- Score on test : 0.696319018405
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.966145833333
		- Score on test : 0.702702702703
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 0.966145833333
		- Score on test : 0.702702702703
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.0339425587467
		- Score on test : 0.303680981595
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 0.966057441253
		- Score on test : 0.696319018405
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 0.932127591489
		- Score on test : 0.393000600631
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.963636363636
		- Score on test : 0.688235294118
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.968668407311
		- Score on test : 0.717791411043
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 0.966057441253
		- Score on test : 0.696319018405
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.0339425587467
		- Score on test : 0.303680981595


 Classification took 0:00:15
2017-09-22 14:54:45,834 INFO: Done:	 Result Analysis
2017-09-22 14:54:46,169 DEBUG: Done:	 Predicting
2017-09-22 14:54:46,170 DEBUG: Info:	 Time for training and predicting: 16.0016198158[s]
2017-09-22 14:54:46,170 DEBUG: Start:	 Getting Results
2017-09-22 14:54:46,197 DEBUG: Done:	 Getting Results
2017-09-22 14:54:46,198 INFO: Classification on awaexp database for cq-hist with SVMPoly, and 2 statistical iterations

accuracy_score on train : 0.946475195822, with STD : 0.0
accuracy_score on test : 0.662576687117, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : cq-hist	 View shape : (1092, 2688)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 2

Classifier configuration : 
	- SVM Poly with C : 8934
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 2 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 0.946475195822
		- Score on test : 0.662576687117
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.94626474443
		- Score on test : 0.668674698795
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 0.94626474443
		- Score on test : 0.668674698795
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.0535248041775
		- Score on test : 0.337423312883
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 0.946475195822
		- Score on test : 0.662576687117
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 0.892977786076
		- Score on test : 0.325373883668
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.95
		- Score on test : 0.656804733728
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.942558746736
		- Score on test : 0.680981595092
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 0.946475195822
		- Score on test : 0.662576687117
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.0535248041775
		- Score on test : 0.337423312883


 Classification took 0:00:16
2017-09-22 14:54:46,198 INFO: Done:	 Result Analysis
2017-09-22 14:54:46,350 DEBUG: Start:	 Loading data
2017-09-22 14:54:46,350 DEBUG: Start:	 Loading data
2017-09-22 14:54:46,366 DEBUG: Done:	 Loading data
2017-09-22 14:54:46,366 DEBUG: Done:	 Loading data
2017-09-22 14:54:46,366 DEBUG: Info:	 Classification - Database:awaexp Feature:lss-hist train_size:0.7, CrossValidation k-folds:2, cores:1, algorithm : Adaboost
2017-09-22 14:54:46,366 DEBUG: Info:	 Classification - Database:awaexp Feature:lss-hist train_size:0.7, CrossValidation k-folds:2, cores:1, algorithm : DecisionTree
2017-09-22 14:54:46,366 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 14:54:46,366 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 14:54:46,393 DEBUG: Info:	 Shape X_train:(766, 2000), Length of y_train:766
2017-09-22 14:54:46,393 DEBUG: Info:	 Shape X_train:(766, 2000), Length of y_train:766
2017-09-22 14:54:46,393 DEBUG: Info:	 Shape X_test:(326, 2000), Length of y_test:326
2017-09-22 14:54:46,393 DEBUG: Info:	 Shape X_test:(326, 2000), Length of y_test:326
2017-09-22 14:54:46,393 DEBUG: Done:	 Determine Train/Test split
2017-09-22 14:54:46,393 DEBUG: Done:	 Determine Train/Test split
2017-09-22 14:54:46,394 DEBUG: Start:	 RandomSearch best settings with 2 iterations for Adaboost
2017-09-22 14:54:46,394 DEBUG: Start:	 RandomSearch best settings with 2 iterations for DecisionTree
2017-09-22 14:54:47,827 DEBUG: Done:	 RandomSearch best settings
2017-09-22 14:54:47,828 DEBUG: Start:	 Training
2017-09-22 14:54:48,105 DEBUG: Done:	 RandomSearch best settings
2017-09-22 14:54:48,105 DEBUG: Start:	 Training
2017-09-22 14:54:48,166 DEBUG: Done:	 Training
2017-09-22 14:54:48,166 DEBUG: Start:	 Predicting
2017-09-22 14:54:48,177 DEBUG: Done:	 Predicting
2017-09-22 14:54:48,177 DEBUG: Info:	 Time for training and predicting: 1.82623195648[s]
2017-09-22 14:54:48,177 DEBUG: Start:	 Getting Results
2017-09-22 14:54:48,207 DEBUG: Done:	 Getting Results
2017-09-22 14:54:48,207 INFO: Classification on awaexp database for lss-hist with DecisionTree, and 2 statistical iterations

accuracy_score on train : 0.929503916449, with STD : 0.0
accuracy_score on test : 0.70245398773, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : lss-hist	 View shape : (1092, 2000)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 2

Classifier configuration : 
	- Decision Tree with max_depth : 6
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 2 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 0.929503916449
		- Score on test : 0.70245398773
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.926430517711
		- Score on test : 0.681967213115
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 0.926430517711
		- Score on test : 0.681967213115
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.0704960835509
		- Score on test : 0.29754601227
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 0.929503916449
		- Score on test : 0.70245398773
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 0.862021884075
		- Score on test : 0.408310785419
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.968660968661
		- Score on test : 0.732394366197
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.88772845953
		- Score on test : 0.638036809816
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 0.929503916449
		- Score on test : 0.70245398773
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.0704960835509
		- Score on test : 0.29754601227


 Classification took 0:00:01
2017-09-22 14:54:48,207 INFO: Done:	 Result Analysis
2017-09-22 14:54:48,586 DEBUG: Done:	 Training
2017-09-22 14:54:48,586 DEBUG: Start:	 Predicting
2017-09-22 14:54:48,600 DEBUG: Done:	 Predicting
2017-09-22 14:54:48,600 DEBUG: Info:	 Time for training and predicting: 2.2490208149[s]
2017-09-22 14:54:48,600 DEBUG: Start:	 Getting Results
2017-09-22 14:54:48,628 DEBUG: Done:	 Getting Results
2017-09-22 14:54:48,628 INFO: Classification on awaexp database for lss-hist with Adaboost, and 2 statistical iterations

accuracy_score on train : 1.0, with STD : 0.0
accuracy_score on test : 0.656441717791, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : lss-hist	 View shape : (1092, 2000)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 2

Classifier configuration : 
	- Adaboost with num_esimators : 12, base_estimators : DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best')
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 2 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.656441717791
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.645569620253
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.645569620253
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.0
		- Score on test : 0.343558282209
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.656441717791
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.313473915907
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.666666666667
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.625766871166
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.656441717791
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.0
		- Score on test : 0.343558282209


 Classification took 0:00:02
2017-09-22 14:54:48,628 INFO: Done:	 Result Analysis
2017-09-22 14:54:48,714 DEBUG: Start:	 Loading data
2017-09-22 14:54:48,715 DEBUG: Start:	 Loading data
2017-09-22 14:54:48,726 DEBUG: Done:	 Loading data
2017-09-22 14:54:48,726 DEBUG: Done:	 Loading data
2017-09-22 14:54:48,726 DEBUG: Info:	 Classification - Database:awaexp Feature:lss-hist train_size:0.7, CrossValidation k-folds:2, cores:1, algorithm : KNN
2017-09-22 14:54:48,726 DEBUG: Info:	 Classification - Database:awaexp Feature:lss-hist train_size:0.7, CrossValidation k-folds:2, cores:1, algorithm : RandomForest
2017-09-22 14:54:48,726 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 14:54:48,726 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 14:54:48,752 DEBUG: Info:	 Shape X_train:(766, 2000), Length of y_train:766
2017-09-22 14:54:48,752 DEBUG: Info:	 Shape X_test:(326, 2000), Length of y_test:326
2017-09-22 14:54:48,752 DEBUG: Done:	 Determine Train/Test split
2017-09-22 14:54:48,752 DEBUG: Info:	 Shape X_train:(766, 2000), Length of y_train:766
2017-09-22 14:54:48,752 DEBUG: Start:	 RandomSearch best settings with 2 iterations for RandomForest
2017-09-22 14:54:48,752 DEBUG: Info:	 Shape X_test:(326, 2000), Length of y_test:326
2017-09-22 14:54:48,753 DEBUG: Done:	 Determine Train/Test split
2017-09-22 14:54:48,753 DEBUG: Start:	 RandomSearch best settings with 2 iterations for KNN
2017-09-22 14:54:48,896 DEBUG: Done:	 RandomSearch best settings
2017-09-22 14:54:48,896 DEBUG: Start:	 Training
2017-09-22 14:54:48,923 DEBUG: Done:	 Training
2017-09-22 14:54:48,923 DEBUG: Start:	 Predicting
2017-09-22 14:54:48,941 DEBUG: Done:	 Predicting
2017-09-22 14:54:48,941 DEBUG: Info:	 Time for training and predicting: 0.225959062576[s]
2017-09-22 14:54:48,941 DEBUG: Start:	 Getting Results
2017-09-22 14:54:48,970 DEBUG: Done:	 Getting Results
2017-09-22 14:54:48,970 INFO: Classification on awaexp database for lss-hist with RandomForest, and 2 statistical iterations

accuracy_score on train : 0.860313315927, with STD : 0.0
accuracy_score on test : 0.60736196319, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : lss-hist	 View shape : (1092, 2000)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 2

Classifier configuration : 
	- Random Forest with num_esimators : 2, max_depth : 25
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 2 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 0.860313315927
		- Score on test : 0.60736196319
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.841949778434
		- Score on test : 0.511450381679
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 0.841949778434
		- Score on test : 0.511450381679
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.139686684073
		- Score on test : 0.39263803681
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 0.860313315927
		- Score on test : 0.60736196319
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 0.740908227603
		- Score on test : 0.233473459459
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.969387755102
		- Score on test : 0.676767676768
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.744125326371
		- Score on test : 0.411042944785
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 0.860313315927
		- Score on test : 0.60736196319
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.139686684073
		- Score on test : 0.39263803681


 Classification took 0:00:00
2017-09-22 14:54:48,970 INFO: Done:	 Result Analysis
2017-09-22 14:54:50,572 DEBUG: Done:	 RandomSearch best settings
2017-09-22 14:54:50,572 DEBUG: Start:	 Training
2017-09-22 14:54:50,604 DEBUG: Done:	 Training
2017-09-22 14:54:50,605 DEBUG: Start:	 Predicting
2017-09-22 14:54:55,867 DEBUG: Done:	 Predicting
2017-09-22 14:54:55,867 DEBUG: Info:	 Time for training and predicting: 7.15247702599[s]
2017-09-22 14:54:55,868 DEBUG: Start:	 Getting Results
2017-09-22 14:54:55,895 DEBUG: Done:	 Getting Results
2017-09-22 14:54:55,896 INFO: Classification on awaexp database for lss-hist with KNN, and 2 statistical iterations

accuracy_score on train : 0.656657963446, with STD : 0.0
accuracy_score on test : 0.680981595092, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : lss-hist	 View shape : (1092, 2000)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 2

Classifier configuration : 
	- K nearest Neighbors with  n_neighbors: 38
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 2 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 0.656657963446
		- Score on test : 0.680981595092
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.594761171032
		- Score on test : 0.631205673759
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 0.594761171032
		- Score on test : 0.631205673759
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.343342036554
		- Score on test : 0.319018404908
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 0.656657963446
		- Score on test : 0.680981595092
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 0.329045098264
		- Score on test : 0.375918204951
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.725563909774
		- Score on test : 0.747899159664
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.503916449086
		- Score on test : 0.546012269939
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 0.656657963446
		- Score on test : 0.680981595092
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.343342036554
		- Score on test : 0.319018404908


 Classification took 0:00:07
2017-09-22 14:54:55,896 INFO: Done:	 Result Analysis
2017-09-22 14:54:55,990 DEBUG: Start:	 Loading data
2017-09-22 14:54:55,991 DEBUG: Start:	 Loading data
2017-09-22 14:54:56,000 DEBUG: Done:	 Loading data
2017-09-22 14:54:56,000 DEBUG: Done:	 Loading data
2017-09-22 14:54:56,001 DEBUG: Info:	 Classification - Database:awaexp Feature:lss-hist train_size:0.7, CrossValidation k-folds:2, cores:1, algorithm : SGD
2017-09-22 14:54:56,001 DEBUG: Info:	 Classification - Database:awaexp Feature:lss-hist train_size:0.7, CrossValidation k-folds:2, cores:1, algorithm : SVMLinear
2017-09-22 14:54:56,001 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 14:54:56,001 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 14:54:56,020 DEBUG: Info:	 Shape X_train:(766, 2000), Length of y_train:766
2017-09-22 14:54:56,021 DEBUG: Info:	 Shape X_test:(326, 2000), Length of y_test:326
2017-09-22 14:54:56,021 DEBUG: Info:	 Shape X_train:(766, 2000), Length of y_train:766
2017-09-22 14:54:56,021 DEBUG: Done:	 Determine Train/Test split
2017-09-22 14:54:56,021 DEBUG: Info:	 Shape X_test:(326, 2000), Length of y_test:326
2017-09-22 14:54:56,021 DEBUG: Start:	 RandomSearch best settings with 2 iterations for SGD
2017-09-22 14:54:56,021 DEBUG: Done:	 Determine Train/Test split
2017-09-22 14:54:56,021 DEBUG: Start:	 RandomSearch best settings with 2 iterations for SVMLinear
2017-09-22 14:54:56,478 DEBUG: Done:	 RandomSearch best settings
2017-09-22 14:54:56,478 DEBUG: Start:	 Training
2017-09-22 14:54:56,579 DEBUG: Done:	 Training
2017-09-22 14:54:56,579 DEBUG: Start:	 Predicting
2017-09-22 14:54:56,587 DEBUG: Done:	 Predicting
2017-09-22 14:54:56,587 DEBUG: Info:	 Time for training and predicting: 0.596174955368[s]
2017-09-22 14:54:56,587 DEBUG: Start:	 Getting Results
2017-09-22 14:54:56,622 DEBUG: Done:	 Getting Results
2017-09-22 14:54:56,622 INFO: Classification on awaexp database for lss-hist with SGD, and 2 statistical iterations

accuracy_score on train : 0.930809399478, with STD : 0.0
accuracy_score on test : 0.751533742331, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : lss-hist	 View shape : (1092, 2000)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 2

Classifier configuration : 
	- SGDClassifier with loss : modified_huber, penalty : elasticnet
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 2 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 0.930809399478
		- Score on test : 0.751533742331
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.926490984743
		- Score on test : 0.744479495268
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 0.926490984743
		- Score on test : 0.744479495268
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.0691906005222
		- Score on test : 0.248466257669
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 0.930809399478
		- Score on test : 0.751533742331
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 0.867628291993
		- Score on test : 0.503836084816
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.988165680473
		- Score on test : 0.766233766234
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.872062663185
		- Score on test : 0.723926380368
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 0.930809399478
		- Score on test : 0.751533742331
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.0691906005222
		- Score on test : 0.248466257669


 Classification took 0:00:00
2017-09-22 14:54:56,623 INFO: Done:	 Result Analysis
2017-09-22 14:54:58,556 DEBUG: Done:	 RandomSearch best settings
2017-09-22 14:54:58,557 DEBUG: Start:	 Training
2017-09-22 14:55:02,569 DEBUG: Done:	 Training
2017-09-22 14:55:02,569 DEBUG: Start:	 Predicting
2017-09-22 14:55:04,416 DEBUG: Done:	 Predicting
2017-09-22 14:55:04,417 DEBUG: Info:	 Time for training and predicting: 8.42555618286[s]
2017-09-22 14:55:04,417 DEBUG: Start:	 Getting Results
2017-09-22 14:55:04,444 DEBUG: Done:	 Getting Results
2017-09-22 14:55:04,444 INFO: Classification on awaexp database for lss-hist with SVMLinear, and 2 statistical iterations

accuracy_score on train : 0.998694516971, with STD : 0.0
accuracy_score on test : 0.834355828221, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : lss-hist	 View shape : (1092, 2000)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 2

Classifier configuration : 
	- SVM Linear with C : 8934
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 2 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 0.998694516971
		- Score on test : 0.834355828221
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.998692810458
		- Score on test : 0.835365853659
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 0.998692810458
		- Score on test : 0.835365853659
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.00130548302872
		- Score on test : 0.165644171779
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 0.998694516971
		- Score on test : 0.834355828221
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 0.997392433632
		- Score on test : 0.668761999862
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.830303030303
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.997389033943
		- Score on test : 0.840490797546
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 0.998694516971
		- Score on test : 0.834355828221
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.00130548302872
		- Score on test : 0.165644171779


 Classification took 0:00:08
2017-09-22 14:55:04,444 INFO: Done:	 Result Analysis
2017-09-22 14:55:04,565 DEBUG: Start:	 Loading data
2017-09-22 14:55:04,566 DEBUG: Start:	 Loading data
2017-09-22 14:55:04,576 DEBUG: Done:	 Loading data
2017-09-22 14:55:04,576 DEBUG: Info:	 Classification - Database:awaexp Feature:lss-hist train_size:0.7, CrossValidation k-folds:2, cores:1, algorithm : SVMPoly
2017-09-22 14:55:04,576 DEBUG: Done:	 Loading data
2017-09-22 14:55:04,576 DEBUG: Info:	 Classification - Database:awaexp Feature:lss-hist train_size:0.7, CrossValidation k-folds:2, cores:1, algorithm : SVMRBF
2017-09-22 14:55:04,576 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 14:55:04,577 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 14:55:04,604 DEBUG: Info:	 Shape X_train:(766, 2000), Length of y_train:766
2017-09-22 14:55:04,604 DEBUG: Info:	 Shape X_train:(766, 2000), Length of y_train:766
2017-09-22 14:55:04,604 DEBUG: Info:	 Shape X_test:(326, 2000), Length of y_test:326
2017-09-22 14:55:04,604 DEBUG: Info:	 Shape X_test:(326, 2000), Length of y_test:326
2017-09-22 14:55:04,604 DEBUG: Done:	 Determine Train/Test split
2017-09-22 14:55:04,604 DEBUG: Done:	 Determine Train/Test split
2017-09-22 14:55:04,604 DEBUG: Start:	 RandomSearch best settings with 2 iterations for SVMRBF
2017-09-22 14:55:04,604 DEBUG: Start:	 RandomSearch best settings with 2 iterations for SVMPoly
2017-09-22 14:55:07,929 DEBUG: Done:	 RandomSearch best settings
2017-09-22 14:55:07,929 DEBUG: Start:	 Training
2017-09-22 14:55:09,576 DEBUG: Done:	 RandomSearch best settings
2017-09-22 14:55:09,576 DEBUG: Start:	 Training
2017-09-22 14:55:12,730 DEBUG: Done:	 Training
2017-09-22 14:55:12,731 DEBUG: Start:	 Predicting
2017-09-22 14:55:15,040 DEBUG: Done:	 Predicting
2017-09-22 14:55:15,040 DEBUG: Info:	 Time for training and predicting: 10.4746248722[s]
2017-09-22 14:55:15,040 DEBUG: Start:	 Getting Results
2017-09-22 14:55:15,070 DEBUG: Done:	 Getting Results
2017-09-22 14:55:15,070 INFO: Classification on awaexp database for lss-hist with SVMPoly, and 2 statistical iterations

accuracy_score on train : 1.0, with STD : 0.0
accuracy_score on test : 0.800613496933, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : lss-hist	 View shape : (1092, 2000)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 2

Classifier configuration : 
	- SVM Poly with C : 8934
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 2 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.800613496933
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.798761609907
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.798761609907
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.0
		- Score on test : 0.199386503067
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.800613496933
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.60132884975
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.80625
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.791411042945
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.800613496933
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.0
		- Score on test : 0.199386503067


 Classification took 0:00:10
2017-09-22 14:55:15,071 INFO: Done:	 Result Analysis
2017-09-22 14:55:16,852 DEBUG: Done:	 Training
2017-09-22 14:55:16,852 DEBUG: Start:	 Predicting
2017-09-22 14:55:20,363 DEBUG: Done:	 Predicting
2017-09-22 14:55:20,364 DEBUG: Info:	 Time for training and predicting: 15.797577858[s]
2017-09-22 14:55:20,364 DEBUG: Start:	 Getting Results
2017-09-22 14:55:20,390 DEBUG: Done:	 Getting Results
2017-09-22 14:55:20,391 INFO: Classification on awaexp database for lss-hist with SVMRBF, and 2 statistical iterations

accuracy_score on train : 1.0, with STD : 0.0
accuracy_score on test : 0.527607361963, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : lss-hist	 View shape : (1092, 2000)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 2

Classifier configuration : 
	- SVM RBF with C : 8934
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 2 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.527607361963
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.669527896996
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.669527896996
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.0
		- Score on test : 0.472392638037
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.527607361963
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.107809560896
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.514851485149
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.957055214724
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.527607361963
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.0
		- Score on test : 0.472392638037


 Classification took 0:00:15
2017-09-22 14:55:20,391 INFO: Done:	 Result Analysis
2017-09-22 14:55:20,560 INFO: ### Main Programm for Multiview Classification
2017-09-22 14:55:20,560 INFO: ### Main Programm for Multiview Classification
2017-09-22 14:55:20,560 INFO: ### Classification - Database : awaexp ; Views : cq-hist, lss-hist ; Algorithm : Fusion ; Cores : 1
2017-09-22 14:55:20,561 INFO: ### Classification - Database : awaexp ; Views : cq-hist, lss-hist ; Algorithm : Fusion ; Cores : 1
2017-09-22 14:55:20,563 INFO: Info:	 Shape of cq-hist :(1092, 2688)
2017-09-22 14:55:20,563 INFO: Info:	 Shape of cq-hist :(1092, 2688)
2017-09-22 14:55:20,565 INFO: Info:	 Shape of lss-hist :(1092, 2000)
2017-09-22 14:55:20,565 INFO: Info:	 Shape of lss-hist :(1092, 2000)
2017-09-22 14:55:20,565 INFO: Done:	 Read Database Files
2017-09-22 14:55:20,565 INFO: Done:	 Read Database Files
2017-09-22 14:55:20,566 INFO: Start:	 Determine validation split for ratio 0.7
2017-09-22 14:55:20,566 INFO: Start:	 Determine validation split for ratio 0.7

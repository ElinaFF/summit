2017-09-22 15:42:59,585 DEBUG: Start:	 Creating 2 temporary datasets for multiprocessing
2017-09-22 15:42:59,585 WARNING:  WARNING : /!\ This may use a lot of HDD storage space : 0.084322 Gbytes /!\ 
2017-09-22 15:43:03,867 DEBUG: Start:	 Creating datasets for multiprocessing
2017-09-22 15:43:03,870 INFO: Start:	 Finding all available mono- & multiview algorithms
2017-09-22 15:43:03,948 DEBUG: Start:	 Loading data
2017-09-22 15:43:03,948 DEBUG: Start:	 Loading data
2017-09-22 15:43:03,963 DEBUG: Done:	 Loading data
2017-09-22 15:43:03,963 DEBUG: Done:	 Loading data
2017-09-22 15:43:03,964 DEBUG: Info:	 Classification - Database:awaexp Feature:cq-hist train_size:0.7, CrossValidation k-folds:5, cores:1, algorithm : DecisionTree
2017-09-22 15:43:03,964 DEBUG: Info:	 Classification - Database:awaexp Feature:cq-hist train_size:0.7, CrossValidation k-folds:5, cores:1, algorithm : Adaboost
2017-09-22 15:43:03,964 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 15:43:03,964 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 15:43:03,995 DEBUG: Info:	 Shape X_train:(766, 2688), Length of y_train:766
2017-09-22 15:43:03,995 DEBUG: Info:	 Shape X_train:(766, 2688), Length of y_train:766
2017-09-22 15:43:03,995 DEBUG: Info:	 Shape X_test:(326, 2688), Length of y_test:326
2017-09-22 15:43:03,995 DEBUG: Info:	 Shape X_test:(326, 2688), Length of y_test:326
2017-09-22 15:43:03,995 DEBUG: Done:	 Determine Train/Test split
2017-09-22 15:43:03,995 DEBUG: Done:	 Determine Train/Test split
2017-09-22 15:43:03,995 DEBUG: Start:	 RandomSearch best settings with 20 iterations for Adaboost
2017-09-22 15:43:03,995 DEBUG: Start:	 RandomSearch best settings with 20 iterations for DecisionTree
2017-09-22 15:43:56,722 DEBUG: Done:	 RandomSearch best settings
2017-09-22 15:43:56,723 DEBUG: Start:	 Training
2017-09-22 15:43:57,025 DEBUG: Done:	 Training
2017-09-22 15:43:57,025 DEBUG: Start:	 Predicting
2017-09-22 15:43:57,038 DEBUG: Done:	 Predicting
2017-09-22 15:43:57,038 DEBUG: Info:	 Time for training and predicting: 53.0896990299[s]
2017-09-22 15:43:57,038 DEBUG: Start:	 Getting Results
2017-09-22 15:43:57,066 DEBUG: Done:	 Getting Results
2017-09-22 15:43:57,067 INFO: Classification on awaexp database for cq-hist with DecisionTree, and 5 statistical iterations

accuracy_score on train : 0.779373368146, with STD : 0.0
accuracy_score on test : 0.647239263804, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : cq-hist	 View shape : (1092, 2688)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 5

Classifier configuration : 
	- Decision Tree with max_depth : 3
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 20 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 0.779373368146
		- Score on test : 0.647239263804
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.784713375796
		- Score on test : 0.66275659824
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 0.784713375796
		- Score on test : 0.66275659824
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.220626631854
		- Score on test : 0.352760736196
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 0.779373368146
		- Score on test : 0.647239263804
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 0.559435542669
		- Score on test : 0.295733401498
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.766169154229
		- Score on test : 0.634831460674
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.804177545692
		- Score on test : 0.693251533742
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 0.779373368146
		- Score on test : 0.647239263804
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.220626631854
		- Score on test : 0.352760736196


 Classification took 0:00:53
2017-09-22 15:43:57,067 INFO: Done:	 Result Analysis
2017-09-22 15:44:05,595 DEBUG: Done:	 RandomSearch best settings
2017-09-22 15:44:05,596 DEBUG: Start:	 Training
2017-09-22 15:44:06,345 DEBUG: Done:	 Training
2017-09-22 15:44:06,345 DEBUG: Start:	 Predicting
2017-09-22 15:44:06,361 DEBUG: Done:	 Predicting
2017-09-22 15:44:06,361 DEBUG: Info:	 Time for training and predicting: 62.412541151[s]
2017-09-22 15:44:06,361 DEBUG: Start:	 Getting Results
2017-09-22 15:44:06,388 DEBUG: Done:	 Getting Results
2017-09-22 15:44:06,388 INFO: Classification on awaexp database for cq-hist with Adaboost, and 5 statistical iterations

accuracy_score on train : 1.0, with STD : 0.0
accuracy_score on test : 0.644171779141, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : cq-hist	 View shape : (1092, 2688)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 5

Classifier configuration : 
	- Adaboost with num_esimators : 5, base_estimators : DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best')
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 20 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.644171779141
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.652694610778
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.652694610778
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.0
		- Score on test : 0.355828220859
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.644171779141
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.288691471152
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.637426900585
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.668711656442
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.644171779141
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.0
		- Score on test : 0.355828220859


 Classification took 0:01:02
2017-09-22 15:44:06,389 INFO: Done:	 Result Analysis
2017-09-22 15:44:06,544 DEBUG: Start:	 Loading data
2017-09-22 15:44:06,544 DEBUG: Start:	 Loading data
2017-09-22 15:44:06,560 DEBUG: Done:	 Loading data
2017-09-22 15:44:06,560 DEBUG: Done:	 Loading data
2017-09-22 15:44:06,561 DEBUG: Info:	 Classification - Database:awaexp Feature:cq-hist train_size:0.7, CrossValidation k-folds:5, cores:1, algorithm : RandomForest
2017-09-22 15:44:06,561 DEBUG: Info:	 Classification - Database:awaexp Feature:cq-hist train_size:0.7, CrossValidation k-folds:5, cores:1, algorithm : KNN
2017-09-22 15:44:06,561 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 15:44:06,561 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 15:44:06,590 DEBUG: Info:	 Shape X_train:(766, 2688), Length of y_train:766
2017-09-22 15:44:06,590 DEBUG: Info:	 Shape X_train:(766, 2688), Length of y_train:766
2017-09-22 15:44:06,591 DEBUG: Info:	 Shape X_test:(326, 2688), Length of y_test:326
2017-09-22 15:44:06,591 DEBUG: Info:	 Shape X_test:(326, 2688), Length of y_test:326
2017-09-22 15:44:06,591 DEBUG: Done:	 Determine Train/Test split
2017-09-22 15:44:06,591 DEBUG: Done:	 Determine Train/Test split
2017-09-22 15:44:06,591 DEBUG: Start:	 RandomSearch best settings with 20 iterations for RandomForest
2017-09-22 15:44:06,591 DEBUG: Start:	 RandomSearch best settings with 20 iterations for KNN
2017-09-22 15:44:28,388 DEBUG: Done:	 RandomSearch best settings
2017-09-22 15:44:28,388 DEBUG: Start:	 Training
2017-09-22 15:44:28,716 DEBUG: Done:	 Training
2017-09-22 15:44:28,716 DEBUG: Start:	 Predicting
2017-09-22 15:44:28,789 DEBUG: Done:	 Predicting
2017-09-22 15:44:28,789 DEBUG: Info:	 Time for training and predicting: 22.2440979481[s]
2017-09-22 15:44:28,789 DEBUG: Start:	 Getting Results
2017-09-22 15:44:28,818 DEBUG: Done:	 Getting Results
2017-09-22 15:44:28,818 INFO: Classification on awaexp database for cq-hist with RandomForest, and 5 statistical iterations

accuracy_score on train : 0.993472584856, with STD : 0.0
accuracy_score on test : 0.766871165644, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : cq-hist	 View shape : (1092, 2688)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 5

Classifier configuration : 
	- Random Forest with num_esimators : 20, max_depth : 24
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 20 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 0.993472584856
		- Score on test : 0.766871165644
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.993429697766
		- Score on test : 0.748344370861
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 0.993429697766
		- Score on test : 0.748344370861
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.0065274151436
		- Score on test : 0.233128834356
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 0.993472584856
		- Score on test : 0.766871165644
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 0.987029282303
		- Score on test : 0.539623742011
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.812949640288
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.986945169713
		- Score on test : 0.693251533742
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 0.993472584856
		- Score on test : 0.766871165644
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.0065274151436
		- Score on test : 0.233128834356


 Classification took 0:00:22
2017-09-22 15:44:28,818 INFO: Done:	 Result Analysis
2017-09-22 15:44:57,971 DEBUG: Done:	 RandomSearch best settings
2017-09-22 15:44:57,971 DEBUG: Start:	 Training
2017-09-22 15:44:58,019 DEBUG: Done:	 Training
2017-09-22 15:44:58,019 DEBUG: Start:	 Predicting
2017-09-22 15:45:05,408 DEBUG: Done:	 Predicting
2017-09-22 15:45:05,408 DEBUG: Info:	 Time for training and predicting: 58.8636100292[s]
2017-09-22 15:45:05,408 DEBUG: Start:	 Getting Results
2017-09-22 15:45:05,436 DEBUG: Done:	 Getting Results
2017-09-22 15:45:05,436 INFO: Classification on awaexp database for cq-hist with KNN, and 5 statistical iterations

accuracy_score on train : 0.668407310705, with STD : 0.0
accuracy_score on test : 0.622699386503, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : cq-hist	 View shape : (1092, 2688)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 5

Classifier configuration : 
	- K nearest Neighbors with  n_neighbors: 38
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 20 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 0.668407310705
		- Score on test : 0.622699386503
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.700471698113
		- Score on test : 0.672
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 0.700471698113
		- Score on test : 0.672
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.331592689295
		- Score on test : 0.377300613497
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 0.668407310705
		- Score on test : 0.622699386503
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 0.344810106024
		- Score on test : 0.25729991053
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.638709677419
		- Score on test : 0.594339622642
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.77545691906
		- Score on test : 0.773006134969
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 0.668407310705
		- Score on test : 0.622699386503
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.331592689295
		- Score on test : 0.377300613497


 Classification took 0:00:58
2017-09-22 15:45:05,436 INFO: Done:	 Result Analysis
2017-09-22 15:45:05,529 DEBUG: Start:	 Loading data
2017-09-22 15:45:05,529 DEBUG: Start:	 Loading data
2017-09-22 15:45:05,541 DEBUG: Done:	 Loading data
2017-09-22 15:45:05,542 DEBUG: Info:	 Classification - Database:awaexp Feature:cq-hist train_size:0.7, CrossValidation k-folds:5, cores:1, algorithm : SVMLinear
2017-09-22 15:45:05,542 DEBUG: Done:	 Loading data
2017-09-22 15:45:05,542 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 15:45:05,542 DEBUG: Info:	 Classification - Database:awaexp Feature:cq-hist train_size:0.7, CrossValidation k-folds:5, cores:1, algorithm : SGD
2017-09-22 15:45:05,542 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 15:45:05,562 DEBUG: Info:	 Shape X_train:(766, 2688), Length of y_train:766
2017-09-22 15:45:05,562 DEBUG: Info:	 Shape X_test:(326, 2688), Length of y_test:326
2017-09-22 15:45:05,562 DEBUG: Done:	 Determine Train/Test split
2017-09-22 15:45:05,563 DEBUG: Start:	 RandomSearch best settings with 20 iterations for SVMLinear
2017-09-22 15:45:05,563 DEBUG: Info:	 Shape X_train:(766, 2688), Length of y_train:766
2017-09-22 15:45:05,563 DEBUG: Info:	 Shape X_test:(326, 2688), Length of y_test:326
2017-09-22 15:45:05,563 DEBUG: Done:	 Determine Train/Test split
2017-09-22 15:45:05,563 DEBUG: Start:	 RandomSearch best settings with 20 iterations for SGD
2017-09-22 15:45:16,351 DEBUG: Done:	 RandomSearch best settings
2017-09-22 15:45:16,352 DEBUG: Start:	 Training
2017-09-22 15:45:16,406 DEBUG: Done:	 Training
2017-09-22 15:45:16,406 DEBUG: Start:	 Predicting
2017-09-22 15:45:16,416 DEBUG: Done:	 Predicting
2017-09-22 15:45:16,416 DEBUG: Info:	 Time for training and predicting: 10.8862061501[s]
2017-09-22 15:45:16,416 DEBUG: Start:	 Getting Results
2017-09-22 15:45:16,448 DEBUG: Done:	 Getting Results
2017-09-22 15:45:16,449 INFO: Classification on awaexp database for cq-hist with SGD, and 5 statistical iterations

accuracy_score on train : 0.697127937337, with STD : 0.0
accuracy_score on test : 0.644171779141, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : cq-hist	 View shape : (1092, 2688)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 5

Classifier configuration : 
	- SGDClassifier with loss : log, penalty : l2
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 20 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 0.697127937337
		- Score on test : 0.644171779141
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.693121693122
		- Score on test : 0.656804733728
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 0.693121693122
		- Score on test : 0.656804733728
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.302872062663
		- Score on test : 0.355828220859
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 0.697127937337
		- Score on test : 0.644171779141
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 0.39439032837
		- Score on test : 0.289128138403
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.702412868633
		- Score on test : 0.634285714286
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.68407310705
		- Score on test : 0.680981595092
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 0.697127937337
		- Score on test : 0.644171779141
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.302872062663
		- Score on test : 0.355828220859


 Classification took 0:00:10
2017-09-22 15:45:16,449 INFO: Done:	 Result Analysis
2017-09-22 15:46:38,006 DEBUG: Done:	 RandomSearch best settings
2017-09-22 15:46:38,006 DEBUG: Start:	 Training
2017-09-22 15:46:43,548 DEBUG: Done:	 Training
2017-09-22 15:46:43,549 DEBUG: Start:	 Predicting
2017-09-22 15:46:46,457 DEBUG: Done:	 Predicting
2017-09-22 15:46:46,457 DEBUG: Info:	 Time for training and predicting: 100.927749872[s]
2017-09-22 15:46:46,457 DEBUG: Start:	 Getting Results
2017-09-22 15:46:46,485 DEBUG: Done:	 Getting Results
2017-09-22 15:46:46,485 INFO: Classification on awaexp database for cq-hist with SVMLinear, and 5 statistical iterations

accuracy_score on train : 0.997389033943, with STD : 0.0
accuracy_score on test : 0.604294478528, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : cq-hist	 View shape : (1092, 2688)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 5

Classifier configuration : 
	- SVM Linear with C : 3750
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 20 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 0.997389033943
		- Score on test : 0.604294478528
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.997382198953
		- Score on test : 0.605504587156
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 0.997382198953
		- Score on test : 0.605504587156
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.00261096605744
		- Score on test : 0.395705521472
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 0.997389033943
		- Score on test : 0.604294478528
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 0.994791631253
		- Score on test : 0.208592882586
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.603658536585
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.994778067885
		- Score on test : 0.60736196319
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 0.997389033943
		- Score on test : 0.604294478528
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.00261096605744
		- Score on test : 0.395705521472


 Classification took 0:01:40
2017-09-22 15:46:46,485 INFO: Done:	 Result Analysis
2017-09-22 15:46:46,613 DEBUG: Start:	 Loading data
2017-09-22 15:46:46,613 DEBUG: Start:	 Loading data
2017-09-22 15:46:46,629 DEBUG: Done:	 Loading data
2017-09-22 15:46:46,629 DEBUG: Done:	 Loading data
2017-09-22 15:46:46,629 DEBUG: Info:	 Classification - Database:awaexp Feature:cq-hist train_size:0.7, CrossValidation k-folds:5, cores:1, algorithm : SVMPoly
2017-09-22 15:46:46,629 DEBUG: Info:	 Classification - Database:awaexp Feature:cq-hist train_size:0.7, CrossValidation k-folds:5, cores:1, algorithm : SVMRBF
2017-09-22 15:46:46,630 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 15:46:46,630 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 15:46:46,663 DEBUG: Info:	 Shape X_train:(766, 2688), Length of y_train:766
2017-09-22 15:46:46,663 DEBUG: Info:	 Shape X_train:(766, 2688), Length of y_train:766
2017-09-22 15:46:46,663 DEBUG: Info:	 Shape X_test:(326, 2688), Length of y_test:326
2017-09-22 15:46:46,663 DEBUG: Info:	 Shape X_test:(326, 2688), Length of y_test:326
2017-09-22 15:46:46,663 DEBUG: Done:	 Determine Train/Test split
2017-09-22 15:46:46,663 DEBUG: Done:	 Determine Train/Test split
2017-09-22 15:46:46,663 DEBUG: Start:	 RandomSearch best settings with 20 iterations for SVMRBF
2017-09-22 15:46:46,664 DEBUG: Start:	 RandomSearch best settings with 20 iterations for SVMPoly
2017-09-22 15:48:48,464 DEBUG: Done:	 RandomSearch best settings
2017-09-22 15:48:48,465 DEBUG: Start:	 Training
2017-09-22 15:48:56,540 DEBUG: Done:	 Training
2017-09-22 15:48:56,540 DEBUG: Start:	 Predicting
2017-09-22 15:49:00,828 DEBUG: Done:	 Predicting
2017-09-22 15:49:00,829 DEBUG: Info:	 Time for training and predicting: 134.21481204[s]
2017-09-22 15:49:00,829 DEBUG: Start:	 Getting Results
2017-09-22 15:49:00,858 DEBUG: Done:	 Getting Results
2017-09-22 15:49:00,858 INFO: Classification on awaexp database for cq-hist with SVMRBF, and 5 statistical iterations

accuracy_score on train : 0.83681462141, with STD : 0.0
accuracy_score on test : 0.656441717791, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : cq-hist	 View shape : (1092, 2688)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 5

Classifier configuration : 
	- SVM RBF with C : 633
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 20 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 0.83681462141
		- Score on test : 0.656441717791
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.835309617918
		- Score on test : 0.652173913043
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 0.835309617918
		- Score on test : 0.652173913043
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.16318537859
		- Score on test : 0.343558282209
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 0.83681462141
		- Score on test : 0.656441717791
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 0.673741780586
		- Score on test : 0.31297768823
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.843085106383
		- Score on test : 0.660377358491
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.827676240209
		- Score on test : 0.644171779141
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 0.83681462141
		- Score on test : 0.656441717791
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.16318537859
		- Score on test : 0.343558282209


 Classification took 0:02:14
2017-09-22 15:49:00,858 INFO: Done:	 Result Analysis
2017-09-22 15:49:19,904 DEBUG: Done:	 RandomSearch best settings
2017-09-22 15:49:19,904 DEBUG: Start:	 Training
2017-09-22 15:49:25,768 DEBUG: Done:	 Training
2017-09-22 15:49:25,769 DEBUG: Start:	 Predicting
2017-09-22 15:49:28,889 DEBUG: Done:	 Predicting
2017-09-22 15:49:28,890 DEBUG: Info:	 Time for training and predicting: 162.275981188[s]
2017-09-22 15:49:28,890 DEBUG: Start:	 Getting Results
2017-09-22 15:49:28,917 DEBUG: Done:	 Getting Results
2017-09-22 15:49:28,917 INFO: Classification on awaexp database for cq-hist with SVMPoly, and 5 statistical iterations

accuracy_score on train : 0.946475195822, with STD : 0.0
accuracy_score on test : 0.650306748466, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : cq-hist	 View shape : (1092, 2688)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 5

Classifier configuration : 
	- SVM Poly with C : 7894
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 20 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 0.946475195822
		- Score on test : 0.650306748466
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.945695364238
		- Score on test : 0.654545454545
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 0.945695364238
		- Score on test : 0.654545454545
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.0535248041775
		- Score on test : 0.349693251534
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 0.946475195822
		- Score on test : 0.650306748466
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 0.893318905601
		- Score on test : 0.300704053397
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.959677419355
		- Score on test : 0.646706586826
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.932114882507
		- Score on test : 0.662576687117
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 0.946475195822
		- Score on test : 0.650306748466
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.0535248041775
		- Score on test : 0.349693251534


 Classification took 0:02:42
2017-09-22 15:49:28,917 INFO: Done:	 Result Analysis
2017-09-22 15:49:29,086 DEBUG: Start:	 Loading data
2017-09-22 15:49:29,086 DEBUG: Start:	 Loading data
2017-09-22 15:49:29,099 DEBUG: Done:	 Loading data
2017-09-22 15:49:29,099 DEBUG: Done:	 Loading data
2017-09-22 15:49:29,099 DEBUG: Info:	 Classification - Database:awaexp Feature:lss-hist train_size:0.7, CrossValidation k-folds:5, cores:1, algorithm : DecisionTree
2017-09-22 15:49:29,099 DEBUG: Info:	 Classification - Database:awaexp Feature:lss-hist train_size:0.7, CrossValidation k-folds:5, cores:1, algorithm : Adaboost
2017-09-22 15:49:29,099 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 15:49:29,099 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 15:49:29,129 DEBUG: Info:	 Shape X_train:(766, 2000), Length of y_train:766
2017-09-22 15:49:29,129 DEBUG: Info:	 Shape X_train:(766, 2000), Length of y_train:766
2017-09-22 15:49:29,129 DEBUG: Info:	 Shape X_test:(326, 2000), Length of y_test:326
2017-09-22 15:49:29,129 DEBUG: Info:	 Shape X_test:(326, 2000), Length of y_test:326
2017-09-22 15:49:29,129 DEBUG: Done:	 Determine Train/Test split
2017-09-22 15:49:29,129 DEBUG: Done:	 Determine Train/Test split
2017-09-22 15:49:29,129 DEBUG: Start:	 RandomSearch best settings with 20 iterations for Adaboost
2017-09-22 15:49:29,129 DEBUG: Start:	 RandomSearch best settings with 20 iterations for DecisionTree
2017-09-22 15:50:02,008 DEBUG: Done:	 RandomSearch best settings
2017-09-22 15:50:02,008 DEBUG: Start:	 Training
2017-09-22 15:50:02,169 DEBUG: Done:	 Training
2017-09-22 15:50:02,169 DEBUG: Start:	 Predicting
2017-09-22 15:50:02,179 DEBUG: Done:	 Predicting
2017-09-22 15:50:02,179 DEBUG: Info:	 Time for training and predicting: 33.0920088291[s]
2017-09-22 15:50:02,179 DEBUG: Start:	 Getting Results
2017-09-22 15:50:02,208 DEBUG: Done:	 Getting Results
2017-09-22 15:50:02,208 INFO: Classification on awaexp database for lss-hist with DecisionTree, and 5 statistical iterations

accuracy_score on train : 0.793733681462, with STD : 0.0
accuracy_score on test : 0.711656441718, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : lss-hist	 View shape : (1092, 2000)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 5

Classifier configuration : 
	- Decision Tree with max_depth : 3
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 20 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 0.793733681462
		- Score on test : 0.711656441718
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.784741144414
		- Score on test : 0.686666666667
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 0.784741144414
		- Score on test : 0.686666666667
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.206266318538
		- Score on test : 0.288343558282
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 0.793733681462
		- Score on test : 0.711656441718
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 0.589528644124
		- Score on test : 0.42880308882
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.820512820513
		- Score on test : 0.751824817518
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.751958224543
		- Score on test : 0.631901840491
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 0.793733681462
		- Score on test : 0.711656441718
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.206266318538
		- Score on test : 0.288343558282


 Classification took 0:00:33
2017-09-22 15:50:02,208 INFO: Done:	 Result Analysis
2017-09-22 15:50:06,998 DEBUG: Done:	 RandomSearch best settings
2017-09-22 15:50:06,998 DEBUG: Start:	 Training
2017-09-22 15:50:07,412 DEBUG: Done:	 Training
2017-09-22 15:50:07,413 DEBUG: Start:	 Predicting
2017-09-22 15:50:07,424 DEBUG: Done:	 Predicting
2017-09-22 15:50:07,425 DEBUG: Info:	 Time for training and predicting: 38.3376348019[s]
2017-09-22 15:50:07,425 DEBUG: Start:	 Getting Results
2017-09-22 15:50:07,452 DEBUG: Done:	 Getting Results
2017-09-22 15:50:07,452 INFO: Classification on awaexp database for lss-hist with Adaboost, and 5 statistical iterations

accuracy_score on train : 1.0, with STD : 0.0
accuracy_score on test : 0.699386503067, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : lss-hist	 View shape : (1092, 2000)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 5

Classifier configuration : 
	- Adaboost with num_esimators : 3, base_estimators : DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best')
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 20 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.699386503067
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.706586826347
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.706586826347
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.0
		- Score on test : 0.300613496933
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.699386503067
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.399254162232
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.690058479532
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.723926380368
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.699386503067
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.0
		- Score on test : 0.300613496933


 Classification took 0:00:38
2017-09-22 15:50:07,453 INFO: Done:	 Result Analysis
2017-09-22 15:50:07,522 DEBUG: Start:	 Loading data
2017-09-22 15:50:07,522 DEBUG: Start:	 Loading data
2017-09-22 15:50:07,533 DEBUG: Done:	 Loading data
2017-09-22 15:50:07,533 DEBUG: Done:	 Loading data
2017-09-22 15:50:07,533 DEBUG: Info:	 Classification - Database:awaexp Feature:lss-hist train_size:0.7, CrossValidation k-folds:5, cores:1, algorithm : KNN
2017-09-22 15:50:07,533 DEBUG: Info:	 Classification - Database:awaexp Feature:lss-hist train_size:0.7, CrossValidation k-folds:5, cores:1, algorithm : RandomForest
2017-09-22 15:50:07,533 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 15:50:07,533 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 15:50:07,562 DEBUG: Info:	 Shape X_train:(766, 2000), Length of y_train:766
2017-09-22 15:50:07,562 DEBUG: Info:	 Shape X_train:(766, 2000), Length of y_train:766
2017-09-22 15:50:07,562 DEBUG: Info:	 Shape X_test:(326, 2000), Length of y_test:326
2017-09-22 15:50:07,562 DEBUG: Info:	 Shape X_test:(326, 2000), Length of y_test:326
2017-09-22 15:50:07,562 DEBUG: Done:	 Determine Train/Test split
2017-09-22 15:50:07,562 DEBUG: Done:	 Determine Train/Test split
2017-09-22 15:50:07,562 DEBUG: Start:	 RandomSearch best settings with 20 iterations for RandomForest
2017-09-22 15:50:07,562 DEBUG: Start:	 RandomSearch best settings with 20 iterations for KNN

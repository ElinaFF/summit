2017-09-22 15:42:59,585 DEBUG: Start:	 Creating 2 temporary datasets for multiprocessing
2017-09-22 15:42:59,585 WARNING:  WARNING : /!\ This may use a lot of HDD storage space : 0.084322 Gbytes /!\ 
2017-09-22 15:43:03,867 DEBUG: Start:	 Creating datasets for multiprocessing
2017-09-22 15:43:03,870 INFO: Start:	 Finding all available mono- & multiview algorithms
2017-09-22 15:43:03,948 DEBUG: Start:	 Loading data
2017-09-22 15:43:03,948 DEBUG: Start:	 Loading data
2017-09-22 15:43:03,963 DEBUG: Done:	 Loading data
2017-09-22 15:43:03,963 DEBUG: Done:	 Loading data
2017-09-22 15:43:03,964 DEBUG: Info:	 Classification - Database:awaexp Feature:cq-hist train_size:0.7, CrossValidation k-folds:5, cores:1, algorithm : DecisionTree
2017-09-22 15:43:03,964 DEBUG: Info:	 Classification - Database:awaexp Feature:cq-hist train_size:0.7, CrossValidation k-folds:5, cores:1, algorithm : Adaboost
2017-09-22 15:43:03,964 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 15:43:03,964 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 15:43:03,995 DEBUG: Info:	 Shape X_train:(766, 2688), Length of y_train:766
2017-09-22 15:43:03,995 DEBUG: Info:	 Shape X_train:(766, 2688), Length of y_train:766
2017-09-22 15:43:03,995 DEBUG: Info:	 Shape X_test:(326, 2688), Length of y_test:326
2017-09-22 15:43:03,995 DEBUG: Info:	 Shape X_test:(326, 2688), Length of y_test:326
2017-09-22 15:43:03,995 DEBUG: Done:	 Determine Train/Test split
2017-09-22 15:43:03,995 DEBUG: Done:	 Determine Train/Test split
2017-09-22 15:43:03,995 DEBUG: Start:	 RandomSearch best settings with 20 iterations for Adaboost
2017-09-22 15:43:03,995 DEBUG: Start:	 RandomSearch best settings with 20 iterations for DecisionTree
2017-09-22 15:43:56,722 DEBUG: Done:	 RandomSearch best settings
2017-09-22 15:43:56,723 DEBUG: Start:	 Training
2017-09-22 15:43:57,025 DEBUG: Done:	 Training
2017-09-22 15:43:57,025 DEBUG: Start:	 Predicting
2017-09-22 15:43:57,038 DEBUG: Done:	 Predicting
2017-09-22 15:43:57,038 DEBUG: Info:	 Time for training and predicting: 53.0896990299[s]
2017-09-22 15:43:57,038 DEBUG: Start:	 Getting Results
2017-09-22 15:43:57,066 DEBUG: Done:	 Getting Results
2017-09-22 15:43:57,067 INFO: Classification on awaexp database for cq-hist with DecisionTree, and 5 statistical iterations

accuracy_score on train : 0.779373368146, with STD : 0.0
accuracy_score on test : 0.647239263804, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : cq-hist	 View shape : (1092, 2688)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 5

Classifier configuration : 
	- Decision Tree with max_depth : 3
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 20 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 0.779373368146
		- Score on test : 0.647239263804
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.784713375796
		- Score on test : 0.66275659824
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 0.784713375796
		- Score on test : 0.66275659824
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.220626631854
		- Score on test : 0.352760736196
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 0.779373368146
		- Score on test : 0.647239263804
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 0.559435542669
		- Score on test : 0.295733401498
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.766169154229
		- Score on test : 0.634831460674
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.804177545692
		- Score on test : 0.693251533742
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 0.779373368146
		- Score on test : 0.647239263804
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.220626631854
		- Score on test : 0.352760736196


 Classification took 0:00:53
2017-09-22 15:43:57,067 INFO: Done:	 Result Analysis
2017-09-22 15:44:05,595 DEBUG: Done:	 RandomSearch best settings
2017-09-22 15:44:05,596 DEBUG: Start:	 Training
2017-09-22 15:44:06,345 DEBUG: Done:	 Training
2017-09-22 15:44:06,345 DEBUG: Start:	 Predicting
2017-09-22 15:44:06,361 DEBUG: Done:	 Predicting
2017-09-22 15:44:06,361 DEBUG: Info:	 Time for training and predicting: 62.412541151[s]
2017-09-22 15:44:06,361 DEBUG: Start:	 Getting Results
2017-09-22 15:44:06,388 DEBUG: Done:	 Getting Results
2017-09-22 15:44:06,388 INFO: Classification on awaexp database for cq-hist with Adaboost, and 5 statistical iterations

accuracy_score on train : 1.0, with STD : 0.0
accuracy_score on test : 0.644171779141, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : cq-hist	 View shape : (1092, 2688)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 5

Classifier configuration : 
	- Adaboost with num_esimators : 5, base_estimators : DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best')
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 20 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.644171779141
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.652694610778
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.652694610778
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.0
		- Score on test : 0.355828220859
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.644171779141
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.288691471152
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.637426900585
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.668711656442
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.644171779141
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.0
		- Score on test : 0.355828220859


 Classification took 0:01:02
2017-09-22 15:44:06,389 INFO: Done:	 Result Analysis
2017-09-22 15:44:06,544 DEBUG: Start:	 Loading data
2017-09-22 15:44:06,544 DEBUG: Start:	 Loading data
2017-09-22 15:44:06,560 DEBUG: Done:	 Loading data
2017-09-22 15:44:06,560 DEBUG: Done:	 Loading data
2017-09-22 15:44:06,561 DEBUG: Info:	 Classification - Database:awaexp Feature:cq-hist train_size:0.7, CrossValidation k-folds:5, cores:1, algorithm : RandomForest
2017-09-22 15:44:06,561 DEBUG: Info:	 Classification - Database:awaexp Feature:cq-hist train_size:0.7, CrossValidation k-folds:5, cores:1, algorithm : KNN
2017-09-22 15:44:06,561 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 15:44:06,561 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 15:44:06,590 DEBUG: Info:	 Shape X_train:(766, 2688), Length of y_train:766
2017-09-22 15:44:06,590 DEBUG: Info:	 Shape X_train:(766, 2688), Length of y_train:766
2017-09-22 15:44:06,591 DEBUG: Info:	 Shape X_test:(326, 2688), Length of y_test:326
2017-09-22 15:44:06,591 DEBUG: Info:	 Shape X_test:(326, 2688), Length of y_test:326
2017-09-22 15:44:06,591 DEBUG: Done:	 Determine Train/Test split
2017-09-22 15:44:06,591 DEBUG: Done:	 Determine Train/Test split
2017-09-22 15:44:06,591 DEBUG: Start:	 RandomSearch best settings with 20 iterations for RandomForest
2017-09-22 15:44:06,591 DEBUG: Start:	 RandomSearch best settings with 20 iterations for KNN
2017-09-22 15:44:28,388 DEBUG: Done:	 RandomSearch best settings
2017-09-22 15:44:28,388 DEBUG: Start:	 Training
2017-09-22 15:44:28,716 DEBUG: Done:	 Training
2017-09-22 15:44:28,716 DEBUG: Start:	 Predicting
2017-09-22 15:44:28,789 DEBUG: Done:	 Predicting
2017-09-22 15:44:28,789 DEBUG: Info:	 Time for training and predicting: 22.2440979481[s]
2017-09-22 15:44:28,789 DEBUG: Start:	 Getting Results
2017-09-22 15:44:28,818 DEBUG: Done:	 Getting Results
2017-09-22 15:44:28,818 INFO: Classification on awaexp database for cq-hist with RandomForest, and 5 statistical iterations

accuracy_score on train : 0.993472584856, with STD : 0.0
accuracy_score on test : 0.766871165644, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : cq-hist	 View shape : (1092, 2688)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 5

Classifier configuration : 
	- Random Forest with num_esimators : 20, max_depth : 24
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 20 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 0.993472584856
		- Score on test : 0.766871165644
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.993429697766
		- Score on test : 0.748344370861
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 0.993429697766
		- Score on test : 0.748344370861
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.0065274151436
		- Score on test : 0.233128834356
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 0.993472584856
		- Score on test : 0.766871165644
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 0.987029282303
		- Score on test : 0.539623742011
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.812949640288
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.986945169713
		- Score on test : 0.693251533742
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 0.993472584856
		- Score on test : 0.766871165644
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.0065274151436
		- Score on test : 0.233128834356


 Classification took 0:00:22
2017-09-22 15:44:28,818 INFO: Done:	 Result Analysis
2017-09-22 15:44:57,971 DEBUG: Done:	 RandomSearch best settings
2017-09-22 15:44:57,971 DEBUG: Start:	 Training
2017-09-22 15:44:58,019 DEBUG: Done:	 Training
2017-09-22 15:44:58,019 DEBUG: Start:	 Predicting
2017-09-22 15:45:05,408 DEBUG: Done:	 Predicting
2017-09-22 15:45:05,408 DEBUG: Info:	 Time for training and predicting: 58.8636100292[s]
2017-09-22 15:45:05,408 DEBUG: Start:	 Getting Results
2017-09-22 15:45:05,436 DEBUG: Done:	 Getting Results
2017-09-22 15:45:05,436 INFO: Classification on awaexp database for cq-hist with KNN, and 5 statistical iterations

accuracy_score on train : 0.668407310705, with STD : 0.0
accuracy_score on test : 0.622699386503, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : cq-hist	 View shape : (1092, 2688)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 5

Classifier configuration : 
	- K nearest Neighbors with  n_neighbors: 38
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 20 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 0.668407310705
		- Score on test : 0.622699386503
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.700471698113
		- Score on test : 0.672
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 0.700471698113
		- Score on test : 0.672
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.331592689295
		- Score on test : 0.377300613497
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 0.668407310705
		- Score on test : 0.622699386503
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 0.344810106024
		- Score on test : 0.25729991053
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.638709677419
		- Score on test : 0.594339622642
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.77545691906
		- Score on test : 0.773006134969
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 0.668407310705
		- Score on test : 0.622699386503
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.331592689295
		- Score on test : 0.377300613497


 Classification took 0:00:58
2017-09-22 15:45:05,436 INFO: Done:	 Result Analysis
2017-09-22 15:45:05,529 DEBUG: Start:	 Loading data
2017-09-22 15:45:05,529 DEBUG: Start:	 Loading data
2017-09-22 15:45:05,541 DEBUG: Done:	 Loading data
2017-09-22 15:45:05,542 DEBUG: Info:	 Classification - Database:awaexp Feature:cq-hist train_size:0.7, CrossValidation k-folds:5, cores:1, algorithm : SVMLinear
2017-09-22 15:45:05,542 DEBUG: Done:	 Loading data
2017-09-22 15:45:05,542 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 15:45:05,542 DEBUG: Info:	 Classification - Database:awaexp Feature:cq-hist train_size:0.7, CrossValidation k-folds:5, cores:1, algorithm : SGD
2017-09-22 15:45:05,542 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 15:45:05,562 DEBUG: Info:	 Shape X_train:(766, 2688), Length of y_train:766
2017-09-22 15:45:05,562 DEBUG: Info:	 Shape X_test:(326, 2688), Length of y_test:326
2017-09-22 15:45:05,562 DEBUG: Done:	 Determine Train/Test split
2017-09-22 15:45:05,563 DEBUG: Start:	 RandomSearch best settings with 20 iterations for SVMLinear
2017-09-22 15:45:05,563 DEBUG: Info:	 Shape X_train:(766, 2688), Length of y_train:766
2017-09-22 15:45:05,563 DEBUG: Info:	 Shape X_test:(326, 2688), Length of y_test:326
2017-09-22 15:45:05,563 DEBUG: Done:	 Determine Train/Test split
2017-09-22 15:45:05,563 DEBUG: Start:	 RandomSearch best settings with 20 iterations for SGD
2017-09-22 15:45:16,351 DEBUG: Done:	 RandomSearch best settings
2017-09-22 15:45:16,352 DEBUG: Start:	 Training
2017-09-22 15:45:16,406 DEBUG: Done:	 Training
2017-09-22 15:45:16,406 DEBUG: Start:	 Predicting
2017-09-22 15:45:16,416 DEBUG: Done:	 Predicting
2017-09-22 15:45:16,416 DEBUG: Info:	 Time for training and predicting: 10.8862061501[s]
2017-09-22 15:45:16,416 DEBUG: Start:	 Getting Results
2017-09-22 15:45:16,448 DEBUG: Done:	 Getting Results
2017-09-22 15:45:16,449 INFO: Classification on awaexp database for cq-hist with SGD, and 5 statistical iterations

accuracy_score on train : 0.697127937337, with STD : 0.0
accuracy_score on test : 0.644171779141, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : cq-hist	 View shape : (1092, 2688)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 5

Classifier configuration : 
	- SGDClassifier with loss : log, penalty : l2
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 20 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 0.697127937337
		- Score on test : 0.644171779141
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.693121693122
		- Score on test : 0.656804733728
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 0.693121693122
		- Score on test : 0.656804733728
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.302872062663
		- Score on test : 0.355828220859
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 0.697127937337
		- Score on test : 0.644171779141
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 0.39439032837
		- Score on test : 0.289128138403
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.702412868633
		- Score on test : 0.634285714286
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.68407310705
		- Score on test : 0.680981595092
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 0.697127937337
		- Score on test : 0.644171779141
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.302872062663
		- Score on test : 0.355828220859


 Classification took 0:00:10
2017-09-22 15:45:16,449 INFO: Done:	 Result Analysis
2017-09-22 15:46:38,006 DEBUG: Done:	 RandomSearch best settings
2017-09-22 15:46:38,006 DEBUG: Start:	 Training
2017-09-22 15:46:43,548 DEBUG: Done:	 Training
2017-09-22 15:46:43,549 DEBUG: Start:	 Predicting
2017-09-22 15:46:46,457 DEBUG: Done:	 Predicting
2017-09-22 15:46:46,457 DEBUG: Info:	 Time for training and predicting: 100.927749872[s]
2017-09-22 15:46:46,457 DEBUG: Start:	 Getting Results
2017-09-22 15:46:46,485 DEBUG: Done:	 Getting Results
2017-09-22 15:46:46,485 INFO: Classification on awaexp database for cq-hist with SVMLinear, and 5 statistical iterations

accuracy_score on train : 0.997389033943, with STD : 0.0
accuracy_score on test : 0.604294478528, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : cq-hist	 View shape : (1092, 2688)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 5

Classifier configuration : 
	- SVM Linear with C : 3750
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 20 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 0.997389033943
		- Score on test : 0.604294478528
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.997382198953
		- Score on test : 0.605504587156
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 0.997382198953
		- Score on test : 0.605504587156
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.00261096605744
		- Score on test : 0.395705521472
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 0.997389033943
		- Score on test : 0.604294478528
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 0.994791631253
		- Score on test : 0.208592882586
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.603658536585
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.994778067885
		- Score on test : 0.60736196319
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 0.997389033943
		- Score on test : 0.604294478528
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.00261096605744
		- Score on test : 0.395705521472


 Classification took 0:01:40
2017-09-22 15:46:46,485 INFO: Done:	 Result Analysis
2017-09-22 15:46:46,613 DEBUG: Start:	 Loading data
2017-09-22 15:46:46,613 DEBUG: Start:	 Loading data
2017-09-22 15:46:46,629 DEBUG: Done:	 Loading data
2017-09-22 15:46:46,629 DEBUG: Done:	 Loading data
2017-09-22 15:46:46,629 DEBUG: Info:	 Classification - Database:awaexp Feature:cq-hist train_size:0.7, CrossValidation k-folds:5, cores:1, algorithm : SVMPoly
2017-09-22 15:46:46,629 DEBUG: Info:	 Classification - Database:awaexp Feature:cq-hist train_size:0.7, CrossValidation k-folds:5, cores:1, algorithm : SVMRBF
2017-09-22 15:46:46,630 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 15:46:46,630 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 15:46:46,663 DEBUG: Info:	 Shape X_train:(766, 2688), Length of y_train:766
2017-09-22 15:46:46,663 DEBUG: Info:	 Shape X_train:(766, 2688), Length of y_train:766
2017-09-22 15:46:46,663 DEBUG: Info:	 Shape X_test:(326, 2688), Length of y_test:326
2017-09-22 15:46:46,663 DEBUG: Info:	 Shape X_test:(326, 2688), Length of y_test:326
2017-09-22 15:46:46,663 DEBUG: Done:	 Determine Train/Test split
2017-09-22 15:46:46,663 DEBUG: Done:	 Determine Train/Test split
2017-09-22 15:46:46,663 DEBUG: Start:	 RandomSearch best settings with 20 iterations for SVMRBF
2017-09-22 15:46:46,664 DEBUG: Start:	 RandomSearch best settings with 20 iterations for SVMPoly
2017-09-22 15:48:48,464 DEBUG: Done:	 RandomSearch best settings
2017-09-22 15:48:48,465 DEBUG: Start:	 Training
2017-09-22 15:48:56,540 DEBUG: Done:	 Training
2017-09-22 15:48:56,540 DEBUG: Start:	 Predicting
2017-09-22 15:49:00,828 DEBUG: Done:	 Predicting
2017-09-22 15:49:00,829 DEBUG: Info:	 Time for training and predicting: 134.21481204[s]
2017-09-22 15:49:00,829 DEBUG: Start:	 Getting Results
2017-09-22 15:49:00,858 DEBUG: Done:	 Getting Results
2017-09-22 15:49:00,858 INFO: Classification on awaexp database for cq-hist with SVMRBF, and 5 statistical iterations

accuracy_score on train : 0.83681462141, with STD : 0.0
accuracy_score on test : 0.656441717791, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : cq-hist	 View shape : (1092, 2688)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 5

Classifier configuration : 
	- SVM RBF with C : 633
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 20 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 0.83681462141
		- Score on test : 0.656441717791
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.835309617918
		- Score on test : 0.652173913043
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 0.835309617918
		- Score on test : 0.652173913043
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.16318537859
		- Score on test : 0.343558282209
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 0.83681462141
		- Score on test : 0.656441717791
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 0.673741780586
		- Score on test : 0.31297768823
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.843085106383
		- Score on test : 0.660377358491
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.827676240209
		- Score on test : 0.644171779141
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 0.83681462141
		- Score on test : 0.656441717791
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.16318537859
		- Score on test : 0.343558282209


 Classification took 0:02:14
2017-09-22 15:49:00,858 INFO: Done:	 Result Analysis
2017-09-22 15:49:19,904 DEBUG: Done:	 RandomSearch best settings
2017-09-22 15:49:19,904 DEBUG: Start:	 Training
2017-09-22 15:49:25,768 DEBUG: Done:	 Training
2017-09-22 15:49:25,769 DEBUG: Start:	 Predicting
2017-09-22 15:49:28,889 DEBUG: Done:	 Predicting
2017-09-22 15:49:28,890 DEBUG: Info:	 Time for training and predicting: 162.275981188[s]
2017-09-22 15:49:28,890 DEBUG: Start:	 Getting Results
2017-09-22 15:49:28,917 DEBUG: Done:	 Getting Results
2017-09-22 15:49:28,917 INFO: Classification on awaexp database for cq-hist with SVMPoly, and 5 statistical iterations

accuracy_score on train : 0.946475195822, with STD : 0.0
accuracy_score on test : 0.650306748466, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : cq-hist	 View shape : (1092, 2688)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 5

Classifier configuration : 
	- SVM Poly with C : 7894
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 20 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 0.946475195822
		- Score on test : 0.650306748466
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.945695364238
		- Score on test : 0.654545454545
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 0.945695364238
		- Score on test : 0.654545454545
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.0535248041775
		- Score on test : 0.349693251534
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 0.946475195822
		- Score on test : 0.650306748466
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 0.893318905601
		- Score on test : 0.300704053397
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.959677419355
		- Score on test : 0.646706586826
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.932114882507
		- Score on test : 0.662576687117
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 0.946475195822
		- Score on test : 0.650306748466
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.0535248041775
		- Score on test : 0.349693251534


 Classification took 0:02:42
2017-09-22 15:49:28,917 INFO: Done:	 Result Analysis
2017-09-22 15:49:29,086 DEBUG: Start:	 Loading data
2017-09-22 15:49:29,086 DEBUG: Start:	 Loading data
2017-09-22 15:49:29,099 DEBUG: Done:	 Loading data
2017-09-22 15:49:29,099 DEBUG: Done:	 Loading data
2017-09-22 15:49:29,099 DEBUG: Info:	 Classification - Database:awaexp Feature:lss-hist train_size:0.7, CrossValidation k-folds:5, cores:1, algorithm : DecisionTree
2017-09-22 15:49:29,099 DEBUG: Info:	 Classification - Database:awaexp Feature:lss-hist train_size:0.7, CrossValidation k-folds:5, cores:1, algorithm : Adaboost
2017-09-22 15:49:29,099 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 15:49:29,099 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 15:49:29,129 DEBUG: Info:	 Shape X_train:(766, 2000), Length of y_train:766
2017-09-22 15:49:29,129 DEBUG: Info:	 Shape X_train:(766, 2000), Length of y_train:766
2017-09-22 15:49:29,129 DEBUG: Info:	 Shape X_test:(326, 2000), Length of y_test:326
2017-09-22 15:49:29,129 DEBUG: Info:	 Shape X_test:(326, 2000), Length of y_test:326
2017-09-22 15:49:29,129 DEBUG: Done:	 Determine Train/Test split
2017-09-22 15:49:29,129 DEBUG: Done:	 Determine Train/Test split
2017-09-22 15:49:29,129 DEBUG: Start:	 RandomSearch best settings with 20 iterations for Adaboost
2017-09-22 15:49:29,129 DEBUG: Start:	 RandomSearch best settings with 20 iterations for DecisionTree
2017-09-22 15:50:02,008 DEBUG: Done:	 RandomSearch best settings
2017-09-22 15:50:02,008 DEBUG: Start:	 Training
2017-09-22 15:50:02,169 DEBUG: Done:	 Training
2017-09-22 15:50:02,169 DEBUG: Start:	 Predicting
2017-09-22 15:50:02,179 DEBUG: Done:	 Predicting
2017-09-22 15:50:02,179 DEBUG: Info:	 Time for training and predicting: 33.0920088291[s]
2017-09-22 15:50:02,179 DEBUG: Start:	 Getting Results
2017-09-22 15:50:02,208 DEBUG: Done:	 Getting Results
2017-09-22 15:50:02,208 INFO: Classification on awaexp database for lss-hist with DecisionTree, and 5 statistical iterations

accuracy_score on train : 0.793733681462, with STD : 0.0
accuracy_score on test : 0.711656441718, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : lss-hist	 View shape : (1092, 2000)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 5

Classifier configuration : 
	- Decision Tree with max_depth : 3
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 20 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 0.793733681462
		- Score on test : 0.711656441718
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.784741144414
		- Score on test : 0.686666666667
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 0.784741144414
		- Score on test : 0.686666666667
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.206266318538
		- Score on test : 0.288343558282
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 0.793733681462
		- Score on test : 0.711656441718
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 0.589528644124
		- Score on test : 0.42880308882
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.820512820513
		- Score on test : 0.751824817518
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.751958224543
		- Score on test : 0.631901840491
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 0.793733681462
		- Score on test : 0.711656441718
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.206266318538
		- Score on test : 0.288343558282


 Classification took 0:00:33
2017-09-22 15:50:02,208 INFO: Done:	 Result Analysis
2017-09-22 15:50:06,998 DEBUG: Done:	 RandomSearch best settings
2017-09-22 15:50:06,998 DEBUG: Start:	 Training
2017-09-22 15:50:07,412 DEBUG: Done:	 Training
2017-09-22 15:50:07,413 DEBUG: Start:	 Predicting
2017-09-22 15:50:07,424 DEBUG: Done:	 Predicting
2017-09-22 15:50:07,425 DEBUG: Info:	 Time for training and predicting: 38.3376348019[s]
2017-09-22 15:50:07,425 DEBUG: Start:	 Getting Results
2017-09-22 15:50:07,452 DEBUG: Done:	 Getting Results
2017-09-22 15:50:07,452 INFO: Classification on awaexp database for lss-hist with Adaboost, and 5 statistical iterations

accuracy_score on train : 1.0, with STD : 0.0
accuracy_score on test : 0.699386503067, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : lss-hist	 View shape : (1092, 2000)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 5

Classifier configuration : 
	- Adaboost with num_esimators : 3, base_estimators : DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best')
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 20 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.699386503067
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.706586826347
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.706586826347
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.0
		- Score on test : 0.300613496933
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.699386503067
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.399254162232
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.690058479532
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.723926380368
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.699386503067
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.0
		- Score on test : 0.300613496933


 Classification took 0:00:38
2017-09-22 15:50:07,453 INFO: Done:	 Result Analysis
2017-09-22 15:50:07,522 DEBUG: Start:	 Loading data
2017-09-22 15:50:07,522 DEBUG: Start:	 Loading data
2017-09-22 15:50:07,533 DEBUG: Done:	 Loading data
2017-09-22 15:50:07,533 DEBUG: Done:	 Loading data
2017-09-22 15:50:07,533 DEBUG: Info:	 Classification - Database:awaexp Feature:lss-hist train_size:0.7, CrossValidation k-folds:5, cores:1, algorithm : KNN
2017-09-22 15:50:07,533 DEBUG: Info:	 Classification - Database:awaexp Feature:lss-hist train_size:0.7, CrossValidation k-folds:5, cores:1, algorithm : RandomForest
2017-09-22 15:50:07,533 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 15:50:07,533 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 15:50:07,562 DEBUG: Info:	 Shape X_train:(766, 2000), Length of y_train:766
2017-09-22 15:50:07,562 DEBUG: Info:	 Shape X_train:(766, 2000), Length of y_train:766
2017-09-22 15:50:07,562 DEBUG: Info:	 Shape X_test:(326, 2000), Length of y_test:326
2017-09-22 15:50:07,562 DEBUG: Info:	 Shape X_test:(326, 2000), Length of y_test:326
2017-09-22 15:50:07,562 DEBUG: Done:	 Determine Train/Test split
2017-09-22 15:50:07,562 DEBUG: Done:	 Determine Train/Test split
2017-09-22 15:50:07,562 DEBUG: Start:	 RandomSearch best settings with 20 iterations for RandomForest
2017-09-22 15:50:07,562 DEBUG: Start:	 RandomSearch best settings with 20 iterations for KNN
2017-09-22 15:50:24,063 DEBUG: Done:	 RandomSearch best settings
2017-09-22 15:50:24,063 DEBUG: Start:	 Training
2017-09-22 15:50:24,385 DEBUG: Done:	 Training
2017-09-22 15:50:24,385 DEBUG: Start:	 Predicting
2017-09-22 15:50:24,467 DEBUG: Done:	 Predicting
2017-09-22 15:50:24,467 DEBUG: Info:	 Time for training and predicting: 16.9445199966[s]
2017-09-22 15:50:24,467 DEBUG: Start:	 Getting Results
2017-09-22 15:50:24,495 DEBUG: Done:	 Getting Results
2017-09-22 15:50:24,495 INFO: Classification on awaexp database for lss-hist with RandomForest, and 5 statistical iterations

accuracy_score on train : 0.998694516971, with STD : 0.0
accuracy_score on test : 0.677914110429, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : lss-hist	 View shape : (1092, 2000)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 5

Classifier configuration : 
	- Random Forest with num_esimators : 28, max_depth : 12
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 20 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 0.998694516971
		- Score on test : 0.677914110429
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.998692810458
		- Score on test : 0.682779456193
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 0.998692810458
		- Score on test : 0.682779456193
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.00130548302872
		- Score on test : 0.322085889571
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 0.998694516971
		- Score on test : 0.677914110429
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 0.997392433632
		- Score on test : 0.355995746702
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.672619047619
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.997389033943
		- Score on test : 0.693251533742
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 0.998694516971
		- Score on test : 0.677914110429
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.00130548302872
		- Score on test : 0.322085889571


 Classification took 0:00:16
2017-09-22 15:50:24,496 INFO: Done:	 Result Analysis
2017-09-22 15:50:43,708 DEBUG: Done:	 RandomSearch best settings
2017-09-22 15:50:43,708 DEBUG: Start:	 Training
2017-09-22 15:50:43,739 DEBUG: Done:	 Training
2017-09-22 15:50:43,739 DEBUG: Start:	 Predicting
2017-09-22 15:50:49,339 DEBUG: Done:	 Predicting
2017-09-22 15:50:49,340 DEBUG: Info:	 Time for training and predicting: 41.8171880245[s]
2017-09-22 15:50:49,340 DEBUG: Start:	 Getting Results
2017-09-22 15:50:49,368 DEBUG: Done:	 Getting Results
2017-09-22 15:50:49,369 INFO: Classification on awaexp database for lss-hist with KNN, and 5 statistical iterations

accuracy_score on train : 0.711488250653, with STD : 0.0
accuracy_score on test : 0.59509202454, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : lss-hist	 View shape : (1092, 2000)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 5

Classifier configuration : 
	- K nearest Neighbors with  n_neighbors: 21
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 20 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 0.711488250653
		- Score on test : 0.59509202454
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.675477239354
		- Score on test : 0.551020408163
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 0.675477239354
		- Score on test : 0.551020408163
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.288511749347
		- Score on test : 0.40490797546
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 0.711488250653
		- Score on test : 0.59509202454
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 0.433794414692
		- Score on test : 0.19395846585
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.771812080537
		- Score on test : 0.618320610687
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.600522193211
		- Score on test : 0.496932515337
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 0.711488250653
		- Score on test : 0.59509202454
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.288511749347
		- Score on test : 0.40490797546


 Classification took 0:00:41
2017-09-22 15:50:49,369 INFO: Done:	 Result Analysis
2017-09-22 15:50:49,472 DEBUG: Start:	 Loading data
2017-09-22 15:50:49,472 DEBUG: Start:	 Loading data
2017-09-22 15:50:49,484 DEBUG: Done:	 Loading data
2017-09-22 15:50:49,484 DEBUG: Done:	 Loading data
2017-09-22 15:50:49,484 DEBUG: Info:	 Classification - Database:awaexp Feature:lss-hist train_size:0.7, CrossValidation k-folds:5, cores:1, algorithm : SGD
2017-09-22 15:50:49,484 DEBUG: Info:	 Classification - Database:awaexp Feature:lss-hist train_size:0.7, CrossValidation k-folds:5, cores:1, algorithm : SVMLinear
2017-09-22 15:50:49,485 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 15:50:49,485 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 15:50:49,514 DEBUG: Info:	 Shape X_train:(766, 2000), Length of y_train:766
2017-09-22 15:50:49,514 DEBUG: Info:	 Shape X_train:(766, 2000), Length of y_train:766
2017-09-22 15:50:49,515 DEBUG: Info:	 Shape X_test:(326, 2000), Length of y_test:326
2017-09-22 15:50:49,515 DEBUG: Info:	 Shape X_test:(326, 2000), Length of y_test:326
2017-09-22 15:50:49,515 DEBUG: Done:	 Determine Train/Test split
2017-09-22 15:50:49,515 DEBUG: Done:	 Determine Train/Test split
2017-09-22 15:50:49,515 DEBUG: Start:	 RandomSearch best settings with 20 iterations for SVMLinear
2017-09-22 15:50:49,515 DEBUG: Start:	 RandomSearch best settings with 20 iterations for SGD
2017-09-22 15:50:58,244 DEBUG: Done:	 RandomSearch best settings
2017-09-22 15:50:58,244 DEBUG: Start:	 Training
2017-09-22 15:50:58,287 DEBUG: Done:	 Training
2017-09-22 15:50:58,287 DEBUG: Start:	 Predicting
2017-09-22 15:50:58,294 DEBUG: Done:	 Predicting
2017-09-22 15:50:58,295 DEBUG: Info:	 Time for training and predicting: 8.82169294357[s]
2017-09-22 15:50:58,295 DEBUG: Start:	 Getting Results
2017-09-22 15:50:58,326 DEBUG: Done:	 Getting Results
2017-09-22 15:50:58,326 INFO: Classification on awaexp database for lss-hist with SGD, and 5 statistical iterations

accuracy_score on train : 0.955613577023, with STD : 0.0
accuracy_score on test : 0.791411042945, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : lss-hist	 View shape : (1092, 2000)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 5

Classifier configuration : 
	- SGDClassifier with loss : log, penalty : l2
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 20 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 0.955613577023
		- Score on test : 0.791411042945
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.956072351421
		- Score on test : 0.805714285714
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 0.956072351421
		- Score on test : 0.805714285714
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.0443864229765
		- Score on test : 0.208588957055
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 0.955613577023
		- Score on test : 0.791411042945
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 0.911426002045
		- Score on test : 0.589244315989
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.946291560102
		- Score on test : 0.754010695187
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.966057441253
		- Score on test : 0.865030674847
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 0.955613577023
		- Score on test : 0.791411042945
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.0443864229765
		- Score on test : 0.208588957055


 Classification took 0:00:08
2017-09-22 15:50:58,327 INFO: Done:	 Result Analysis
2017-09-22 15:51:55,058 DEBUG: Done:	 RandomSearch best settings
2017-09-22 15:51:55,058 DEBUG: Start:	 Training
2017-09-22 15:51:58,941 DEBUG: Done:	 Training
2017-09-22 15:51:58,941 DEBUG: Start:	 Predicting
2017-09-22 15:52:00,817 DEBUG: Done:	 Predicting
2017-09-22 15:52:00,817 DEBUG: Info:	 Time for training and predicting: 71.3445019722[s]
2017-09-22 15:52:00,818 DEBUG: Start:	 Getting Results
2017-09-22 15:52:00,845 DEBUG: Done:	 Getting Results
2017-09-22 15:52:00,845 INFO: Classification on awaexp database for lss-hist with SVMLinear, and 5 statistical iterations

accuracy_score on train : 1.0, with STD : 0.0
accuracy_score on test : 0.806748466258, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : lss-hist	 View shape : (1092, 2000)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 5

Classifier configuration : 
	- SVM Linear with C : 3750
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 20 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.806748466258
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.809667673716
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.809667673716
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.0
		- Score on test : 0.193251533742
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.806748466258
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.613785770175
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.797619047619
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.822085889571
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.806748466258
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.0
		- Score on test : 0.193251533742


 Classification took 0:01:11
2017-09-22 15:52:00,845 INFO: Done:	 Result Analysis
2017-09-22 15:52:00,999 DEBUG: Start:	 Loading data
2017-09-22 15:52:00,999 DEBUG: Start:	 Loading data
2017-09-22 15:52:01,011 DEBUG: Done:	 Loading data
2017-09-22 15:52:01,011 DEBUG: Done:	 Loading data
2017-09-22 15:52:01,011 DEBUG: Info:	 Classification - Database:awaexp Feature:lss-hist train_size:0.7, CrossValidation k-folds:5, cores:1, algorithm : SVMRBF
2017-09-22 15:52:01,011 DEBUG: Info:	 Classification - Database:awaexp Feature:lss-hist train_size:0.7, CrossValidation k-folds:5, cores:1, algorithm : SVMPoly
2017-09-22 15:52:01,011 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 15:52:01,011 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 15:52:01,040 DEBUG: Info:	 Shape X_train:(766, 2000), Length of y_train:766
2017-09-22 15:52:01,040 DEBUG: Info:	 Shape X_train:(766, 2000), Length of y_train:766
2017-09-22 15:52:01,040 DEBUG: Info:	 Shape X_test:(326, 2000), Length of y_test:326
2017-09-22 15:52:01,040 DEBUG: Info:	 Shape X_test:(326, 2000), Length of y_test:326
2017-09-22 15:52:01,041 DEBUG: Done:	 Determine Train/Test split
2017-09-22 15:52:01,041 DEBUG: Done:	 Determine Train/Test split
2017-09-22 15:52:01,041 DEBUG: Start:	 RandomSearch best settings with 20 iterations for SVMRBF
2017-09-22 15:52:01,041 DEBUG: Start:	 RandomSearch best settings with 20 iterations for SVMPoly
2017-09-22 15:53:09,464 DEBUG: Done:	 RandomSearch best settings
2017-09-22 15:53:09,465 DEBUG: Start:	 Training
2017-09-22 15:53:14,572 DEBUG: Done:	 Training
2017-09-22 15:53:14,573 DEBUG: Start:	 Predicting
2017-09-22 15:53:17,073 DEBUG: Done:	 Predicting
2017-09-22 15:53:17,074 DEBUG: Info:	 Time for training and predicting: 76.0741391182[s]
2017-09-22 15:53:17,074 DEBUG: Start:	 Getting Results
2017-09-22 15:53:17,103 DEBUG: Done:	 Getting Results
2017-09-22 15:53:17,104 INFO: Classification on awaexp database for lss-hist with SVMPoly, and 5 statistical iterations

accuracy_score on train : 1.0, with STD : 0.0
accuracy_score on test : 0.800613496933, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : lss-hist	 View shape : (1092, 2000)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 5

Classifier configuration : 
	- SVM Poly with C : 7894
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 20 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.800613496933
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.790996784566
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.790996784566
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.0
		- Score on test : 0.199386503067
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.800613496933
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.603789028059
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.831081081081
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.754601226994
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.800613496933
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.0
		- Score on test : 0.199386503067


 Classification took 0:01:16
2017-09-22 15:53:17,104 INFO: Done:	 Result Analysis
2017-09-22 15:54:06,512 DEBUG: Done:	 RandomSearch best settings
2017-09-22 15:54:06,513 DEBUG: Start:	 Training
2017-09-22 15:54:13,323 DEBUG: Done:	 Training
2017-09-22 15:54:13,324 DEBUG: Start:	 Predicting
2017-09-22 15:54:17,191 DEBUG: Done:	 Predicting
2017-09-22 15:54:17,191 DEBUG: Info:	 Time for training and predicting: 136.191291094[s]
2017-09-22 15:54:17,191 DEBUG: Start:	 Getting Results
2017-09-22 15:54:17,219 DEBUG: Done:	 Getting Results
2017-09-22 15:54:17,219 INFO: Classification on awaexp database for lss-hist with SVMRBF, and 5 statistical iterations

accuracy_score on train : 1.0, with STD : 0.0
accuracy_score on test : 0.530674846626, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : lss-hist	 View shape : (1092, 2000)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 5

Classifier configuration : 
	- SVM RBF with C : 3750
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 20 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.530674846626
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.673773987207
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.673773987207
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.0
		- Score on test : 0.469325153374
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.530674846626
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.127827498141
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.516339869281
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.969325153374
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.530674846626
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.0
		- Score on test : 0.469325153374


 Classification took 0:02:16
2017-09-22 15:54:17,219 INFO: Done:	 Result Analysis
2017-09-22 15:54:17,347 DEBUG: Start:	 Loading data
2017-09-22 15:54:17,347 DEBUG: Start:	 Loading data
2017-09-22 15:54:17,447 DEBUG: Done:	 Loading data
2017-09-22 15:54:17,447 DEBUG: Info:	 Classification - Database:awaexp Feature:phog-hist train_size:0.7, CrossValidation k-folds:5, cores:1, algorithm : DecisionTree
2017-09-22 15:54:17,448 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 15:54:17,453 DEBUG: Done:	 Loading data
2017-09-22 15:54:17,453 DEBUG: Info:	 Classification - Database:awaexp Feature:phog-hist train_size:0.7, CrossValidation k-folds:5, cores:1, algorithm : Adaboost
2017-09-22 15:54:17,454 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 15:54:17,460 DEBUG: Info:	 Shape X_train:(766, 252), Length of y_train:766
2017-09-22 15:54:17,461 DEBUG: Info:	 Shape X_test:(326, 252), Length of y_test:326
2017-09-22 15:54:17,461 DEBUG: Done:	 Determine Train/Test split
2017-09-22 15:54:17,461 DEBUG: Start:	 RandomSearch best settings with 20 iterations for DecisionTree
2017-09-22 15:54:17,466 DEBUG: Info:	 Shape X_train:(766, 252), Length of y_train:766
2017-09-22 15:54:17,466 DEBUG: Info:	 Shape X_test:(326, 252), Length of y_test:326
2017-09-22 15:54:17,467 DEBUG: Done:	 Determine Train/Test split
2017-09-22 15:54:17,467 DEBUG: Start:	 RandomSearch best settings with 20 iterations for Adaboost
2017-09-22 15:54:27,870 DEBUG: Done:	 RandomSearch best settings
2017-09-22 15:54:27,870 DEBUG: Start:	 Training
2017-09-22 15:54:27,990 DEBUG: Done:	 Training
2017-09-22 15:54:27,990 DEBUG: Start:	 Predicting
2017-09-22 15:54:27,992 DEBUG: Done:	 Predicting
2017-09-22 15:54:27,992 DEBUG: Info:	 Time for training and predicting: 10.644974947[s]
2017-09-22 15:54:27,992 DEBUG: Start:	 Getting Results
2017-09-22 15:54:28,021 DEBUG: Done:	 Getting Results
2017-09-22 15:54:28,022 INFO: Classification on awaexp database for phog-hist with DecisionTree, and 5 statistical iterations

accuracy_score on train : 0.936031331593, with STD : 0.0
accuracy_score on test : 0.61963190184, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : phog-hist	 View shape : (1092, 252)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 5

Classifier configuration : 
	- Decision Tree with max_depth : 7
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 20 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 0.936031331593
		- Score on test : 0.61963190184
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.935611038108
		- Score on test : 0.624242424242
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 0.935611038108
		- Score on test : 0.624242424242
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.0639686684073
		- Score on test : 0.38036809816
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 0.936031331593
		- Score on test : 0.61963190184
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 0.872136984892
		- Score on test : 0.239335879234
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.941798941799
		- Score on test : 0.616766467066
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.929503916449
		- Score on test : 0.631901840491
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 0.936031331593
		- Score on test : 0.61963190184
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.0639686684073
		- Score on test : 0.38036809816


 Classification took 0:00:10
2017-09-22 15:54:28,022 INFO: Done:	 Result Analysis
2017-09-22 15:54:29,890 DEBUG: Done:	 RandomSearch best settings
2017-09-22 15:54:29,890 DEBUG: Start:	 Training
2017-09-22 15:54:30,042 DEBUG: Done:	 Training
2017-09-22 15:54:30,042 DEBUG: Start:	 Predicting
2017-09-22 15:54:30,046 DEBUG: Done:	 Predicting
2017-09-22 15:54:30,046 DEBUG: Info:	 Time for training and predicting: 12.6987230778[s]
2017-09-22 15:54:30,046 DEBUG: Start:	 Getting Results
2017-09-22 15:54:30,074 DEBUG: Done:	 Getting Results
2017-09-22 15:54:30,074 INFO: Classification on awaexp database for phog-hist with Adaboost, and 5 statistical iterations

accuracy_score on train : 1.0, with STD : 0.0
accuracy_score on test : 0.592024539877, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : phog-hist	 View shape : (1092, 252)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 5

Classifier configuration : 
	- Adaboost with num_esimators : 5, base_estimators : DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best')
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 20 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.592024539877
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.605341246291
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.605341246291
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.0
		- Score on test : 0.407975460123
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.592024539877
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.184469612979
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.586206896552
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.625766871166
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.592024539877
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.0
		- Score on test : 0.407975460123


 Classification took 0:00:12
2017-09-22 15:54:30,075 INFO: Done:	 Result Analysis
2017-09-22 15:54:30,216 DEBUG: Start:	 Loading data
2017-09-22 15:54:30,217 DEBUG: Start:	 Loading data
2017-09-22 15:54:30,219 DEBUG: Done:	 Loading data
2017-09-22 15:54:30,219 DEBUG: Info:	 Classification - Database:awaexp Feature:phog-hist train_size:0.7, CrossValidation k-folds:5, cores:1, algorithm : KNN
2017-09-22 15:54:30,219 DEBUG: Done:	 Loading data
2017-09-22 15:54:30,219 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 15:54:30,220 DEBUG: Info:	 Classification - Database:awaexp Feature:phog-hist train_size:0.7, CrossValidation k-folds:5, cores:1, algorithm : RandomForest
2017-09-22 15:54:30,220 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 15:54:30,236 DEBUG: Info:	 Shape X_train:(766, 252), Length of y_train:766
2017-09-22 15:54:30,236 DEBUG: Info:	 Shape X_train:(766, 252), Length of y_train:766
2017-09-22 15:54:30,236 DEBUG: Info:	 Shape X_test:(326, 252), Length of y_test:326
2017-09-22 15:54:30,236 DEBUG: Info:	 Shape X_test:(326, 252), Length of y_test:326
2017-09-22 15:54:30,236 DEBUG: Done:	 Determine Train/Test split
2017-09-22 15:54:30,236 DEBUG: Done:	 Determine Train/Test split
2017-09-22 15:54:30,236 DEBUG: Start:	 RandomSearch best settings with 20 iterations for KNN
2017-09-22 15:54:30,236 DEBUG: Start:	 RandomSearch best settings with 20 iterations for RandomForest
2017-09-22 15:54:35,705 DEBUG: Done:	 RandomSearch best settings
2017-09-22 15:54:35,705 DEBUG: Start:	 Training
2017-09-22 15:54:35,710 DEBUG: Done:	 Training
2017-09-22 15:54:35,710 DEBUG: Start:	 Predicting
2017-09-22 15:54:36,430 DEBUG: Done:	 Predicting
2017-09-22 15:54:36,431 DEBUG: Info:	 Time for training and predicting: 6.21422100067[s]
2017-09-22 15:54:36,431 DEBUG: Start:	 Getting Results
2017-09-22 15:54:36,459 DEBUG: Done:	 Getting Results
2017-09-22 15:54:36,460 INFO: Classification on awaexp database for phog-hist with KNN, and 5 statistical iterations

accuracy_score on train : 0.648825065274, with STD : 0.0
accuracy_score on test : 0.58282208589, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : phog-hist	 View shape : (1092, 252)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 5

Classifier configuration : 
	- K nearest Neighbors with  n_neighbors: 25
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 20 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 0.648825065274
		- Score on test : 0.58282208589
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.601481481481
		- Score on test : 0.549668874172
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 0.601481481481
		- Score on test : 0.549668874172
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.351174934726
		- Score on test : 0.41717791411
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 0.648825065274
		- Score on test : 0.58282208589
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 0.306425042338
		- Score on test : 0.167469437176
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.695205479452
		- Score on test : 0.597122302158
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.530026109661
		- Score on test : 0.509202453988
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 0.648825065274
		- Score on test : 0.58282208589
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.351174934726
		- Score on test : 0.41717791411


 Classification took 0:00:06
2017-09-22 15:54:36,460 INFO: Done:	 Result Analysis
2017-09-22 15:54:44,234 DEBUG: Done:	 RandomSearch best settings
2017-09-22 15:54:44,234 DEBUG: Start:	 Training
2017-09-22 15:54:44,511 DEBUG: Done:	 Training
2017-09-22 15:54:44,511 DEBUG: Start:	 Predicting
2017-09-22 15:54:44,584 DEBUG: Done:	 Predicting
2017-09-22 15:54:44,585 DEBUG: Info:	 Time for training and predicting: 14.3676609993[s]
2017-09-22 15:54:44,585 DEBUG: Start:	 Getting Results
2017-09-22 15:54:44,617 DEBUG: Done:	 Getting Results
2017-09-22 15:54:44,617 INFO: Classification on awaexp database for phog-hist with RandomForest, and 5 statistical iterations

accuracy_score on train : 1.0, with STD : 0.0
accuracy_score on test : 0.680981595092, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : phog-hist	 View shape : (1092, 252)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 5

Classifier configuration : 
	- Random Forest with num_esimators : 28, max_depth : 12
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 20 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.680981595092
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.679012345679
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.679012345679
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.0
		- Score on test : 0.319018404908
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.680981595092
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.361990440293
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.683229813665
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.674846625767
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.680981595092
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.0
		- Score on test : 0.319018404908


 Classification took 0:00:14
2017-09-22 15:54:44,617 INFO: Done:	 Result Analysis
2017-09-22 15:54:44,703 DEBUG: Start:	 Loading data
2017-09-22 15:54:44,703 DEBUG: Start:	 Loading data
2017-09-22 15:54:44,706 DEBUG: Done:	 Loading data
2017-09-22 15:54:44,706 DEBUG: Done:	 Loading data
2017-09-22 15:54:44,706 DEBUG: Info:	 Classification - Database:awaexp Feature:phog-hist train_size:0.7, CrossValidation k-folds:5, cores:1, algorithm : SGD
2017-09-22 15:54:44,706 DEBUG: Info:	 Classification - Database:awaexp Feature:phog-hist train_size:0.7, CrossValidation k-folds:5, cores:1, algorithm : SVMLinear
2017-09-22 15:54:44,706 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 15:54:44,706 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 15:54:44,721 DEBUG: Info:	 Shape X_train:(766, 252), Length of y_train:766
2017-09-22 15:54:44,721 DEBUG: Info:	 Shape X_train:(766, 252), Length of y_train:766
2017-09-22 15:54:44,721 DEBUG: Info:	 Shape X_test:(326, 252), Length of y_test:326
2017-09-22 15:54:44,721 DEBUG: Info:	 Shape X_test:(326, 252), Length of y_test:326
2017-09-22 15:54:44,721 DEBUG: Done:	 Determine Train/Test split
2017-09-22 15:54:44,721 DEBUG: Done:	 Determine Train/Test split
2017-09-22 15:54:44,721 DEBUG: Start:	 RandomSearch best settings with 20 iterations for SVMLinear
2017-09-22 15:54:44,722 DEBUG: Start:	 RandomSearch best settings with 20 iterations for SGD
2017-09-22 15:54:46,726 DEBUG: Done:	 RandomSearch best settings
2017-09-22 15:54:46,727 DEBUG: Start:	 Training
2017-09-22 15:54:46,732 DEBUG: Done:	 Training
2017-09-22 15:54:46,732 DEBUG: Start:	 Predicting
2017-09-22 15:54:46,733 DEBUG: Done:	 Predicting
2017-09-22 15:54:46,734 DEBUG: Info:	 Time for training and predicting: 2.0305621624[s]
2017-09-22 15:54:46,734 DEBUG: Start:	 Getting Results
2017-09-22 15:54:46,765 DEBUG: Done:	 Getting Results
2017-09-22 15:54:46,765 INFO: Classification on awaexp database for phog-hist with SGD, and 5 statistical iterations

accuracy_score on train : 0.592689295039, with STD : 0.0
accuracy_score on test : 0.564417177914, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : phog-hist	 View shape : (1092, 252)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 5

Classifier configuration : 
	- SGDClassifier with loss : log, penalty : l2
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 20 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 0.592689295039
		- Score on test : 0.564417177914
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.347280334728
		- Score on test : 0.268041237113
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 0.347280334728
		- Score on test : 0.268041237113
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.407310704961
		- Score on test : 0.435582822086
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 0.592689295039
		- Score on test : 0.564417177914
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 0.28121293038
		- Score on test : 0.219597524388
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.873684210526
		- Score on test : 0.838709677419
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.216710182768
		- Score on test : 0.159509202454
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 0.592689295039
		- Score on test : 0.564417177914
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.407310704961
		- Score on test : 0.435582822086


 Classification took 0:00:02
2017-09-22 15:54:46,766 INFO: Done:	 Result Analysis
2017-09-22 15:54:54,621 DEBUG: Done:	 RandomSearch best settings
2017-09-22 15:54:54,621 DEBUG: Start:	 Training
2017-09-22 15:54:55,155 DEBUG: Done:	 Training
2017-09-22 15:54:55,155 DEBUG: Start:	 Predicting
2017-09-22 15:54:55,414 DEBUG: Done:	 Predicting
2017-09-22 15:54:55,414 DEBUG: Info:	 Time for training and predicting: 10.7104449272[s]
2017-09-22 15:54:55,414 DEBUG: Start:	 Getting Results
2017-09-22 15:54:55,443 DEBUG: Done:	 Getting Results
2017-09-22 15:54:55,443 INFO: Classification on awaexp database for phog-hist with SVMLinear, and 5 statistical iterations

accuracy_score on train : 0.678851174935, with STD : 0.0
accuracy_score on test : 0.61963190184, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : phog-hist	 View shape : (1092, 252)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 5

Classifier configuration : 
	- SVM Linear with C : 3750
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 20 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 0.678851174935
		- Score on test : 0.61963190184
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.715277777778
		- Score on test : 0.683673469388
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 0.715277777778
		- Score on test : 0.683673469388
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.321148825065
		- Score on test : 0.38036809816
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 0.678851174935
		- Score on test : 0.61963190184
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 0.370020340933
		- Score on test : 0.26167425641
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.642411642412
		- Score on test : 0.585152838428
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.806788511749
		- Score on test : 0.822085889571
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 0.678851174935
		- Score on test : 0.61963190184
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.321148825065
		- Score on test : 0.38036809816


 Classification took 0:00:10
2017-09-22 15:54:55,443 INFO: Done:	 Result Analysis
2017-09-22 15:54:55,580 DEBUG: Start:	 Loading data
2017-09-22 15:54:55,581 DEBUG: Start:	 Loading data
2017-09-22 15:54:55,582 DEBUG: Done:	 Loading data
2017-09-22 15:54:55,583 DEBUG: Info:	 Classification - Database:awaexp Feature:phog-hist train_size:0.7, CrossValidation k-folds:5, cores:1, algorithm : SVMPoly
2017-09-22 15:54:55,583 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 15:54:55,583 DEBUG: Done:	 Loading data
2017-09-22 15:54:55,583 DEBUG: Info:	 Classification - Database:awaexp Feature:phog-hist train_size:0.7, CrossValidation k-folds:5, cores:1, algorithm : SVMRBF
2017-09-22 15:54:55,584 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 15:54:55,597 DEBUG: Info:	 Shape X_train:(766, 252), Length of y_train:766
2017-09-22 15:54:55,598 DEBUG: Info:	 Shape X_test:(326, 252), Length of y_test:326
2017-09-22 15:54:55,598 DEBUG: Done:	 Determine Train/Test split
2017-09-22 15:54:55,598 DEBUG: Start:	 RandomSearch best settings with 20 iterations for SVMPoly
2017-09-22 15:54:55,601 DEBUG: Info:	 Shape X_train:(766, 252), Length of y_train:766
2017-09-22 15:54:55,601 DEBUG: Info:	 Shape X_test:(326, 252), Length of y_test:326
2017-09-22 15:54:55,601 DEBUG: Done:	 Determine Train/Test split
2017-09-22 15:54:55,601 DEBUG: Start:	 RandomSearch best settings with 20 iterations for SVMRBF
2017-09-22 15:55:08,024 DEBUG: Done:	 RandomSearch best settings
2017-09-22 15:55:08,024 DEBUG: Start:	 Training
2017-09-22 15:55:08,745 DEBUG: Done:	 Training
2017-09-22 15:55:08,745 DEBUG: Start:	 Predicting
2017-09-22 15:55:09,099 DEBUG: Done:	 Predicting
2017-09-22 15:55:09,099 DEBUG: Info:	 Time for training and predicting: 13.5177659988[s]
2017-09-22 15:55:09,099 DEBUG: Start:	 Getting Results
2017-09-22 15:55:09,130 DEBUG: Done:	 Getting Results
2017-09-22 15:55:09,130 INFO: Classification on awaexp database for phog-hist with SVMRBF, and 5 statistical iterations

accuracy_score on train : 0.832898172324, with STD : 0.0
accuracy_score on test : 0.659509202454, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : phog-hist	 View shape : (1092, 252)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 5

Classifier configuration : 
	- SVM RBF with C : 1030
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 20 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 0.832898172324
		- Score on test : 0.659509202454
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.843902439024
		- Score on test : 0.689075630252
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 0.843902439024
		- Score on test : 0.689075630252
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.167101827676
		- Score on test : 0.340490797546
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 0.832898172324
		- Score on test : 0.659509202454
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 0.672514283873
		- Score on test : 0.324949230649
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.79176201373
		- Score on test : 0.634020618557
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.903394255875
		- Score on test : 0.754601226994
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 0.832898172324
		- Score on test : 0.659509202454
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.167101827676
		- Score on test : 0.340490797546


 Classification took 0:00:13
2017-09-22 15:55:09,130 INFO: Done:	 Result Analysis
2017-09-22 15:55:10,542 DEBUG: Done:	 RandomSearch best settings
2017-09-22 15:55:10,542 DEBUG: Start:	 Training
2017-09-22 15:55:11,389 DEBUG: Done:	 Training
2017-09-22 15:55:11,389 DEBUG: Start:	 Predicting
2017-09-22 15:55:11,870 DEBUG: Done:	 Predicting
2017-09-22 15:55:11,870 DEBUG: Info:	 Time for training and predicting: 16.2899699211[s]
2017-09-22 15:55:11,870 DEBUG: Start:	 Getting Results
2017-09-22 15:55:11,903 DEBUG: Done:	 Getting Results
2017-09-22 15:55:11,903 INFO: Classification on awaexp database for phog-hist with SVMPoly, and 5 statistical iterations

accuracy_score on train : 0.844647519582, with STD : 0.0
accuracy_score on test : 0.598159509202, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : phog-hist	 View shape : (1092, 252)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 5

Classifier configuration : 
	- SVM Poly with C : 3750
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 20 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 0.844647519582
		- Score on test : 0.598159509202
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.859504132231
		- Score on test : 0.656167979003
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 0.859504132231
		- Score on test : 0.656167979003
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.155352480418
		- Score on test : 0.401840490798
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 0.844647519582
		- Score on test : 0.598159509202
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 0.705247353516
		- Score on test : 0.208549836535
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.784482758621
		- Score on test : 0.573394495413
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.950391644909
		- Score on test : 0.766871165644
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 0.844647519582
		- Score on test : 0.598159509202
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.155352480418
		- Score on test : 0.401840490798


 Classification took 0:00:16
2017-09-22 15:55:11,904 INFO: Done:	 Result Analysis
2017-09-22 15:55:12,063 INFO: ### Main Programm for Multiview Classification
2017-09-22 15:55:12,064 INFO: ### Classification - Database : awaexp ; Views : cq-hist, lss-hist, phog-hist ; Algorithm : Fusion ; Cores : 1
2017-09-22 15:55:12,064 INFO: ### Main Programm for Multiview Classification
2017-09-22 15:55:12,064 INFO: ### Classification - Database : awaexp ; Views : cq-hist, lss-hist, phog-hist ; Algorithm : Fusion ; Cores : 1
2017-09-22 15:55:12,065 INFO: Info:	 Shape of cq-hist :(1092, 2688)
2017-09-22 15:55:12,065 INFO: Info:	 Shape of cq-hist :(1092, 2688)
2017-09-22 15:55:12,065 INFO: Info:	 Shape of lss-hist :(1092, 2000)
2017-09-22 15:55:12,066 INFO: Info:	 Shape of lss-hist :(1092, 2000)
2017-09-22 15:55:12,066 INFO: Info:	 Shape of phog-hist :(1092, 252)
2017-09-22 15:55:12,066 INFO: Done:	 Read Database Files
2017-09-22 15:55:12,066 INFO: Start:	 Determine validation split for ratio 0.7
2017-09-22 15:55:12,067 INFO: Info:	 Shape of phog-hist :(1092, 252)
2017-09-22 15:55:12,067 INFO: Done:	 Read Database Files
2017-09-22 15:55:12,067 INFO: Start:	 Determine validation split for ratio 0.7
2017-09-22 15:55:12,131 INFO: Done:	 Determine validation split
2017-09-22 15:55:12,131 INFO: Start:	 Determine 5 folds
2017-09-22 15:55:12,145 INFO: Done:	 Determine validation split
2017-09-22 15:55:12,145 INFO: Start:	 Determine 5 folds
2017-09-22 15:58:31,803 INFO: Done:	 Classification
2017-09-22 15:58:32,358 INFO: Done:	 Classification
2017-09-22 15:58:32,953 INFO: Done:	 Classification
2017-09-22 15:58:33,484 INFO: Done:	 Classification
2017-09-22 15:58:34,069 INFO: Done:	 Classification
2017-09-22 15:58:34,069 INFO: Info:	 Time for Classification: 202[s]
2017-09-22 15:58:34,069 INFO: Start:	 Result Analysis for Fusion
2017-09-22 15:58:34,744 INFO: 		Result for Multiview classification with LateFusion

Average accuracy_score :
	-On Train : 0.903133159269
	-On Test : 0.809202453988

Dataset info :
	-Database name : awaexp
	-Labels : 
	-Views : cq-hist, lss-hist, phog-hist
	-5 folds

Classification configuration : 
	-Algorithm used : LateFusion with Bayesian Inference using a weight for each view : 0.477239577855, 0.236511491673, 0.286248930471
	-With monoview classifiers : 
		- SGDClassifier with loss : log, penalty : l2
		- SGDClassifier with loss : log, penalty : l2
		- SGDClassifier with loss : log, penalty : l2

	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 0.903133159269 with STD : 0.0624201116681
		- Score on test : 0.809202453988 with STD : 0.028140723782

	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.912705861478 with STD : 0.0474044942861
		- Score on test : 0.819195169506 with STD : 0.0145004045657

	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 0.912705861478 with STD : 0.0474044942861
		- Score on test : 0.819195169506 with STD : 0.0145004045657

	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.0968668407311 with STD : 0.0624201116681
		- Score on test : 0.190797546012 with STD : 0.028140723782

	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 0.903133159269 with STD : 0.0624201116681
		- Score on test : 0.809202453988 with STD : 0.028140723782

	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 0.821343523657 with STD : 0.100808821945
		- Score on test : 0.631495658738 with STD : 0.0389063078408

	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.869561689481 with STD : 0.0934807591073
		- Score on test : 0.790289416542 with STD : 0.0635398535929

	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.969190600522 with STD : 0.0234928916537
		- Score on test : 0.861349693252 with STD : 0.0677185017254

	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 0.903133159269 with STD : 0.0624201116681
		- Score on test : 0.809202453988 with STD : 0.028140723782

	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.0968668407311 with STD : 0.0624201116681
		- Score on test : 0.190797546012 with STD : 0.028140723782


2017-09-22 15:58:34,745 INFO: Done:	 Result Analysis
2017-09-22 15:58:41,403 INFO: Done:	 Classification
2017-09-22 15:58:41,842 INFO: Done:	 Classification
2017-09-22 15:58:42,286 INFO: Done:	 Classification
2017-09-22 15:58:42,730 INFO: Done:	 Classification
2017-09-22 15:58:43,177 INFO: Done:	 Classification
2017-09-22 15:58:43,177 INFO: Info:	 Time for Classification: 211[s]
2017-09-22 15:58:43,177 INFO: Start:	 Result Analysis for Fusion
2017-09-22 15:58:43,586 INFO: 		Result for Multiview classification with LateFusion

Average accuracy_score :
	-On Train : 0.682506527415
	-On Test : 0.669938650307

Dataset info :
	-Database name : awaexp
	-Labels : 
	-Views : cq-hist, lss-hist, phog-hist
	-5 folds

Classification configuration : 
	-Algorithm used : LateFusion with Majority Voting 
	-With monoview classifiers : 
		- SGDClassifier with loss : log, penalty : l2
		- SGDClassifier with loss : log, penalty : l2
		- SGDClassifier with loss : log, penalty : l2

	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 0.682506527415 with STD : 0.00657424454935
		- Score on test : 0.669938650307 with STD : 0.00688648598793

	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.674439638676 with STD : 0.0295114256546
		- Score on test : 0.661890004968 with STD : 0.0327476466189

	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 0.674439638676 with STD : 0.0295114256546
		- Score on test : 0.661890004968 with STD : 0.0327476466189

	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.317493472585 with STD : 0.00657424454935
		- Score on test : 0.330061349693 with STD : 0.00688648598793

	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 0.682506527415 with STD : 0.00657424454935
		- Score on test : 0.669938650307 with STD : 0.00688648598793

	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 0.369275003784 with STD : 0.0133682817705
		- Score on test : 0.344948865665 with STD : 0.0143090016406

	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.693564492842 with STD : 0.0283381941508
		- Score on test : 0.681019396548 with STD : 0.0334400547567

	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.664229765013 with STD : 0.0770053525556
		- Score on test : 0.653987730061 with STD : 0.0853268154636

	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 0.682506527415 with STD : 0.00657424454935
		- Score on test : 0.669938650307 with STD : 0.00688648598793

	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.317493472585 with STD : 0.00657424454935
		- Score on test : 0.330061349693 with STD : 0.00688648598793


2017-09-22 15:58:43,587 INFO: Done:	 Result Analysis
2017-09-22 15:58:43,657 INFO: ### Main Programm for Multiview Classification
2017-09-22 15:58:43,657 INFO: ### Classification - Database : awaexp ; Views : cq-hist, lss-hist, phog-hist ; Algorithm : Fusion ; Cores : 1
2017-09-22 15:58:43,658 INFO: ### Main Programm for Multiview Classification
2017-09-22 15:58:43,659 INFO: ### Classification - Database : awaexp ; Views : cq-hist, lss-hist, phog-hist ; Algorithm : Fusion ; Cores : 1
2017-09-22 15:58:43,659 INFO: Info:	 Shape of cq-hist :(1092, 2688)
2017-09-22 15:58:43,660 INFO: Info:	 Shape of cq-hist :(1092, 2688)
2017-09-22 15:58:43,660 INFO: Info:	 Shape of lss-hist :(1092, 2000)
2017-09-22 15:58:43,662 INFO: Info:	 Shape of lss-hist :(1092, 2000)
2017-09-22 15:58:43,662 INFO: Info:	 Shape of phog-hist :(1092, 252)
2017-09-22 15:58:43,662 INFO: Done:	 Read Database Files
2017-09-22 15:58:43,662 INFO: Start:	 Determine validation split for ratio 0.7
2017-09-22 15:58:43,663 INFO: Info:	 Shape of phog-hist :(1092, 252)
2017-09-22 15:58:43,663 INFO: Done:	 Read Database Files
2017-09-22 15:58:43,663 INFO: Start:	 Determine validation split for ratio 0.7
2017-09-22 15:58:43,755 INFO: Done:	 Determine validation split
2017-09-22 15:58:43,755 INFO: Done:	 Determine validation split
2017-09-22 15:58:43,755 INFO: Start:	 Determine 5 folds
2017-09-22 15:58:43,755 INFO: Start:	 Determine 5 folds
2017-09-22 16:03:01,278 INFO: Done:	 Classification
2017-09-22 16:03:02,212 INFO: Done:	 Classification
2017-09-22 16:03:03,148 INFO: Done:	 Classification
2017-09-22 16:03:04,087 INFO: Done:	 Classification
2017-09-22 16:03:05,194 INFO: Done:	 Classification
2017-09-22 16:03:05,204 INFO: Info:	 Time for Classification: 261[s]
2017-09-22 16:03:05,205 INFO: Start:	 Result Analysis for Fusion
2017-09-22 16:03:06,079 INFO: 		Result for Multiview classification with LateFusion

Average accuracy_score :
	-On Train : 0.827676240209
	-On Test : 0.760736196319

Dataset info :
	-Database name : awaexp
	-Labels : 
	-Views : cq-hist, lss-hist, phog-hist
	-5 folds

Classification configuration : 
	-Algorithm used : LateFusion with SVM for linear 
	-With monoview classifiers : 
		- SGDClassifier with loss : log, penalty : l2
		- SGDClassifier with loss : log, penalty : l2
		- SGDClassifier with loss : log, penalty : l2

	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 0.827676240209 with STD : 0.0
		- Score on test : 0.760736196319 with STD : 0.0

	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.823056300268 with STD : 1.11022302463e-16
		- Score on test : 0.75625 with STD : 0.0

	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 0.823056300268 with STD : 1.11022302463e-16
		- Score on test : 0.75625 with STD : 0.0

	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.172323759791 with STD : 0.0
		- Score on test : 0.239263803681 with STD : 0.0

	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 0.827676240209 with STD : 0.0
		- Score on test : 0.760736196319 with STD : 0.0

	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 0.656247838383 with STD : 0.0
		- Score on test : 0.521826039844 with STD : 0.0

	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.845730027548 with STD : 0.0
		- Score on test : 0.770700636943 with STD : 0.0

	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.801566579634 with STD : 0.0
		- Score on test : 0.742331288344 with STD : 0.0

	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 0.827676240209 with STD : 1.11022302463e-16
		- Score on test : 0.760736196319 with STD : 0.0

	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.172323759791 with STD : 0.0
		- Score on test : 0.239263803681 with STD : 0.0


2017-09-22 16:03:06,080 INFO: Done:	 Result Analysis
2017-09-22 16:04:28,892 INFO: Done:	 Classification
2017-09-22 16:04:29,728 INFO: Done:	 Classification
2017-09-22 16:04:30,740 INFO: Done:	 Classification
2017-09-22 16:04:31,563 INFO: Done:	 Classification
2017-09-22 16:04:32,313 INFO: Done:	 Classification
2017-09-22 16:04:32,313 INFO: Info:	 Time for Classification: 348[s]
2017-09-22 16:04:32,313 INFO: Start:	 Result Analysis for Fusion
2017-09-22 16:04:32,742 INFO: 		Result for Multiview classification with LateFusion

Average accuracy_score :
	-On Train : 0.882506527415
	-On Test : 0.757668711656

Dataset info :
	-Database name : awaexp
	-Labels : 
	-Views : cq-hist, lss-hist, phog-hist
	-5 folds

Classification configuration : 
	-Algorithm used : LateFusion with SCM for linear with max_attributes : 14, p : 0.0241145218036 model_type : conjunction has chosen 1 rule(s) 
	-With monoview classifiers : 
		- SGDClassifier with loss : log, penalty : l2
		- SGDClassifier with loss : log, penalty : l2
		- SGDClassifier with loss : log, penalty : l2

	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 0.882506527415 with STD : 0.0
		- Score on test : 0.757668711656 with STD : 0.0

	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.867256637168 with STD : 1.11022302463e-16
		- Score on test : 0.710622710623 with STD : 0.0

	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 0.867256637168 with STD : 1.11022302463e-16
		- Score on test : 0.710622710623 with STD : 0.0

	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.117493472585 with STD : 0.0
		- Score on test : 0.242331288344 with STD : 0.0

	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 0.882506527415 with STD : 0.0
		- Score on test : 0.757668711656 with STD : 0.0

	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 0.78604273629 with STD : 0.0
		- Score on test : 0.544949260913 with STD : 0.0

	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.996610169492 with STD : 0.0
		- Score on test : 0.881818181818 with STD : 0.0

	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.767624020888 with STD : 0.0
		- Score on test : 0.59509202454 with STD : 0.0

	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 0.882506527415 with STD : 0.0
		- Score on test : 0.757668711656 with STD : 0.0

	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.117493472585 with STD : 0.0
		- Score on test : 0.242331288344 with STD : 2.77555756156e-17


2017-09-22 16:04:32,742 INFO: Done:	 Result Analysis
2017-09-22 16:04:32,827 INFO: ### Main Programm for Multiview Classification
2017-09-22 16:04:32,828 INFO: ### Classification - Database : awaexp ; Views : cq-hist, lss-hist, phog-hist ; Algorithm : Fusion ; Cores : 1
2017-09-22 16:04:32,828 INFO: ### Main Programm for Multiview Classification
2017-09-22 16:04:32,828 INFO: ### Classification - Database : awaexp ; Views : cq-hist, lss-hist, phog-hist ; Algorithm : Fusion ; Cores : 1
2017-09-22 16:04:32,829 INFO: Info:	 Shape of cq-hist :(1092, 2688)
2017-09-22 16:04:32,830 INFO: Info:	 Shape of cq-hist :(1092, 2688)
2017-09-22 16:04:32,831 INFO: Info:	 Shape of lss-hist :(1092, 2000)
2017-09-22 16:04:32,831 INFO: Info:	 Shape of lss-hist :(1092, 2000)
2017-09-22 16:04:32,831 INFO: Info:	 Shape of phog-hist :(1092, 252)
2017-09-22 16:04:32,832 INFO: Done:	 Read Database Files
2017-09-22 16:04:32,832 INFO: Start:	 Determine validation split for ratio 0.7
2017-09-22 16:04:32,832 INFO: Info:	 Shape of phog-hist :(1092, 252)
2017-09-22 16:04:32,832 INFO: Done:	 Read Database Files
2017-09-22 16:04:32,832 INFO: Start:	 Determine validation split for ratio 0.7
2017-09-22 16:04:32,889 INFO: Done:	 Determine validation split
2017-09-22 16:04:32,889 INFO: Start:	 Determine 5 folds
2017-09-22 16:04:32,891 INFO: Done:	 Determine validation split
2017-09-22 16:04:32,891 INFO: Start:	 Determine 5 folds

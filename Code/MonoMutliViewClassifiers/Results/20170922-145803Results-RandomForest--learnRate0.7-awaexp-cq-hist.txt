Classification on awaexp database for cq-hist with RandomForest, and 2 statistical iterations

accuracy_score on train : 0.993472584856, with STD : 0.0
accuracy_score on test : 0.733128834356, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : cq-hist	 View shape : (1092, 2688)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 2

Classifier configuration : 
	- Random Forest with num_esimators : 23, max_depth : 10
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 2 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 0.993472584856
		- Score on test : 0.733128834356
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.993446920052
		- Score on test : 0.722044728435
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 0.993446920052
		- Score on test : 0.722044728435
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.0065274151436
		- Score on test : 0.266871165644
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 0.993472584856
		- Score on test : 0.733128834356
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 0.986975447768
		- Score on test : 0.467747665721
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.997368421053
		- Score on test : 0.753333333333
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.98955613577
		- Score on test : 0.693251533742
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 0.993472584856
		- Score on test : 0.733128834356
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.0065274151436
		- Score on test : 0.266871165644


 Classification took 0:00:01
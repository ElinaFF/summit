2017-09-22 15:18:48,417 DEBUG: Start:	 Creating 4 temporary datasets for multiprocessing
2017-09-22 15:18:48,417 WARNING:  WARNING : /!\ This may use a lot of HDD storage space : 0.1600445 Gbytes /!\ 
2017-09-22 15:18:50,304 DEBUG: Start:	 Creating datasets for multiprocessing
2017-09-22 15:18:50,306 INFO: Start:	 Finding all available mono- & multiview algorithms
2017-09-22 15:18:50,380 DEBUG: Start:	 Loading data
2017-09-22 15:18:50,380 DEBUG: Start:	 Loading data
2017-09-22 15:18:50,382 DEBUG: Start:	 Loading data
2017-09-22 15:18:50,383 DEBUG: Start:	 Loading data
2017-09-22 15:18:50,396 DEBUG: Done:	 Loading data
2017-09-22 15:18:50,397 DEBUG: Info:	 Classification - Database:awaexp Feature:cq-hist train_size:0.7, CrossValidation k-folds:2, cores:1, algorithm : DecisionTree
2017-09-22 15:18:50,397 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 15:18:50,397 DEBUG: Done:	 Loading data
2017-09-22 15:18:50,397 DEBUG: Info:	 Classification - Database:awaexp Feature:cq-hist train_size:0.7, CrossValidation k-folds:2, cores:1, algorithm : Adaboost
2017-09-22 15:18:50,397 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 15:18:50,404 DEBUG: Done:	 Loading data
2017-09-22 15:18:50,404 DEBUG: Info:	 Classification - Database:awaexp Feature:cq-hist train_size:0.7, CrossValidation k-folds:2, cores:1, algorithm : RandomForest
2017-09-22 15:18:50,404 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 15:18:50,404 DEBUG: Done:	 Loading data
2017-09-22 15:18:50,404 DEBUG: Info:	 Classification - Database:awaexp Feature:cq-hist train_size:0.7, CrossValidation k-folds:2, cores:1, algorithm : KNN
2017-09-22 15:18:50,405 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 15:18:50,424 DEBUG: Info:	 Shape X_train:(766, 2688), Length of y_train:766
2017-09-22 15:18:50,424 DEBUG: Info:	 Shape X_test:(326, 2688), Length of y_test:326
2017-09-22 15:18:50,424 DEBUG: Done:	 Determine Train/Test split
2017-09-22 15:18:50,424 DEBUG: Start:	 RandomSearch best settings with 20 iterations for DecisionTree
2017-09-22 15:18:50,435 DEBUG: Info:	 Shape X_train:(766, 2688), Length of y_train:766
2017-09-22 15:18:50,436 DEBUG: Info:	 Shape X_test:(326, 2688), Length of y_test:326
2017-09-22 15:18:50,436 DEBUG: Done:	 Determine Train/Test split
2017-09-22 15:18:50,436 DEBUG: Start:	 RandomSearch best settings with 20 iterations for Adaboost
2017-09-22 15:18:51,033 DEBUG: Info:	 Shape X_train:(766, 2688), Length of y_train:766
2017-09-22 15:18:51,033 DEBUG: Info:	 Shape X_test:(326, 2688), Length of y_test:326
2017-09-22 15:18:51,039 DEBUG: Info:	 Shape X_train:(766, 2688), Length of y_train:766
2017-09-22 15:18:51,068 DEBUG: Done:	 Determine Train/Test split
2017-09-22 15:18:51,068 DEBUG: Info:	 Shape X_test:(326, 2688), Length of y_test:326
2017-09-22 15:18:51,068 DEBUG: Start:	 RandomSearch best settings with 20 iterations for RandomForest
2017-09-22 15:18:51,068 DEBUG: Done:	 Determine Train/Test split
2017-09-22 15:18:51,068 DEBUG: Start:	 RandomSearch best settings with 20 iterations for KNN
2017-09-22 15:18:57,193 DEBUG: Done:	 RandomSearch best settings
2017-09-22 15:18:57,194 DEBUG: Start:	 Training
2017-09-22 15:18:57,606 DEBUG: Done:	 Training
2017-09-22 15:18:57,606 DEBUG: Start:	 Predicting
2017-09-22 15:18:57,694 DEBUG: Done:	 Predicting
2017-09-22 15:18:57,694 DEBUG: Info:	 Time for training and predicting: 7.31078577042[s]
2017-09-22 15:18:57,694 DEBUG: Start:	 Getting Results
2017-09-22 15:18:57,726 DEBUG: Done:	 Getting Results
2017-09-22 15:18:57,726 INFO: Classification on awaexp database for cq-hist with RandomForest, and 5 statistical iterations

accuracy_score on train : 1.0, with STD : 0.0
accuracy_score on test : 0.760736196319, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : cq-hist	 View shape : (1092, 2688)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 2

Classifier configuration : 
	- Random Forest with num_esimators : 25, max_depth : 15
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 20 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.760736196319
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.751592356688
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.751592356688
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.0
		- Score on test : 0.239263803681
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.760736196319
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.522891314133
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.781456953642
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.723926380368
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.760736196319
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.0
		- Score on test : 0.239263803681


 Classification took 0:00:07
2017-09-22 15:18:57,727 INFO: Done:	 Result Analysis
2017-09-22 15:19:04,853 DEBUG: Done:	 RandomSearch best settings
2017-09-22 15:19:04,854 DEBUG: Start:	 Training
2017-09-22 15:19:05,109 DEBUG: Done:	 Training
2017-09-22 15:19:05,110 DEBUG: Start:	 Predicting
2017-09-22 15:19:05,126 DEBUG: Done:	 Predicting
2017-09-22 15:19:05,126 DEBUG: Info:	 Time for training and predicting: 14.7456841469[s]
2017-09-22 15:19:05,126 DEBUG: Start:	 Getting Results
2017-09-22 15:19:05,158 DEBUG: Done:	 Getting Results
2017-09-22 15:19:05,158 INFO: Classification on awaexp database for cq-hist with DecisionTree, and 5 statistical iterations

accuracy_score on train : 0.720626631854, with STD : 0.0
accuracy_score on test : 0.653374233129, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : cq-hist	 View shape : (1092, 2688)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 2

Classifier configuration : 
	- Decision Tree with max_depth : 2
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 20 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 0.720626631854
		- Score on test : 0.653374233129
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.743405275779
		- Score on test : 0.678062678063
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 0.743405275779
		- Score on test : 0.678062678063
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.279373368146
		- Score on test : 0.346625766871
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 0.720626631854
		- Score on test : 0.653374233129
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 0.448376824392
		- Score on test : 0.310421316554
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.687361419069
		- Score on test : 0.632978723404
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.809399477807
		- Score on test : 0.730061349693
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 0.720626631854
		- Score on test : 0.653374233129
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.279373368146
		- Score on test : 0.346625766871


 Classification took 0:00:14
2017-09-22 15:19:05,159 INFO: Done:	 Result Analysis
2017-09-22 15:19:09,721 DEBUG: Done:	 RandomSearch best settings
2017-09-22 15:19:09,721 DEBUG: Start:	 Training
2017-09-22 15:19:10,625 DEBUG: Done:	 Training
2017-09-22 15:19:10,625 DEBUG: Start:	 Predicting
2017-09-22 15:19:10,644 DEBUG: Done:	 Predicting
2017-09-22 15:19:10,644 DEBUG: Info:	 Time for training and predicting: 20.2636079788[s]
2017-09-22 15:19:10,644 DEBUG: Start:	 Getting Results
2017-09-22 15:19:10,673 DEBUG: Done:	 Getting Results
2017-09-22 15:19:10,673 INFO: Classification on awaexp database for cq-hist with Adaboost, and 5 statistical iterations

accuracy_score on train : 1.0, with STD : 0.0
accuracy_score on test : 0.693251533742, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : cq-hist	 View shape : (1092, 2688)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 2

Classifier configuration : 
	- Adaboost with num_esimators : 4, base_estimators : DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best')
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 20 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.693251533742
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.683544303797
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.683544303797
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.0
		- Score on test : 0.306748466258
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.693251533742
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.387232484355
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.705882352941
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.662576687117
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.693251533742
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.0
		- Score on test : 0.306748466258


 Classification took 0:00:20
2017-09-22 15:19:10,673 INFO: Done:	 Result Analysis
2017-09-22 15:19:19,163 DEBUG: Done:	 RandomSearch best settings
2017-09-22 15:19:19,163 DEBUG: Start:	 Training
2017-09-22 15:19:19,221 DEBUG: Done:	 Training
2017-09-22 15:19:19,221 DEBUG: Start:	 Predicting
2017-09-22 15:19:26,334 DEBUG: Done:	 Predicting
2017-09-22 15:19:26,335 DEBUG: Info:	 Time for training and predicting: 35.9515879154[s]
2017-09-22 15:19:26,335 DEBUG: Start:	 Getting Results
2017-09-22 15:19:26,361 DEBUG: Done:	 Getting Results
2017-09-22 15:19:26,362 INFO: Classification on awaexp database for cq-hist with KNN, and 5 statistical iterations

accuracy_score on train : 0.778067885117, with STD : 0.0
accuracy_score on test : 0.638036809816, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : cq-hist	 View shape : (1092, 2688)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 2

Classifier configuration : 
	- K nearest Neighbors with  n_neighbors: 6
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 20 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 0.778067885117
		- Score on test : 0.638036809816
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.783715012723
		- Score on test : 0.64880952381
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 0.783715012723
		- Score on test : 0.64880952381
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.221932114883
		- Score on test : 0.361963190184
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 0.778067885117
		- Score on test : 0.638036809816
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 0.556895575998
		- Score on test : 0.276594631682
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.764267990074
		- Score on test : 0.630057803468
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.804177545692
		- Score on test : 0.668711656442
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 0.778067885117
		- Score on test : 0.638036809816
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.221932114883
		- Score on test : 0.361963190184


 Classification took 0:00:35
2017-09-22 15:19:26,362 INFO: Done:	 Result Analysis
2017-09-22 15:19:26,518 DEBUG: Start:	 Loading data
2017-09-22 15:19:26,518 DEBUG: Start:	 Loading data
2017-09-22 15:19:26,519 DEBUG: Start:	 Loading data
2017-09-22 15:19:26,519 DEBUG: Start:	 Loading data
2017-09-22 15:19:26,542 DEBUG: Done:	 Loading data
2017-09-22 15:19:26,542 DEBUG: Done:	 Loading data
2017-09-22 15:19:26,542 DEBUG: Info:	 Classification - Database:awaexp Feature:cq-hist train_size:0.7, CrossValidation k-folds:2, cores:1, algorithm : SVMLinear
2017-09-22 15:19:26,542 DEBUG: Info:	 Classification - Database:awaexp Feature:cq-hist train_size:0.7, CrossValidation k-folds:2, cores:1, algorithm : SGD
2017-09-22 15:19:26,542 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 15:19:26,542 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 15:19:26,543 DEBUG: Done:	 Loading data
2017-09-22 15:19:26,543 DEBUG: Done:	 Loading data
2017-09-22 15:19:26,543 DEBUG: Info:	 Classification - Database:awaexp Feature:cq-hist train_size:0.7, CrossValidation k-folds:2, cores:1, algorithm : SVMRBF
2017-09-22 15:19:26,543 DEBUG: Info:	 Classification - Database:awaexp Feature:cq-hist train_size:0.7, CrossValidation k-folds:2, cores:1, algorithm : SVMPoly
2017-09-22 15:19:26,544 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 15:19:26,544 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 15:19:26,590 DEBUG: Info:	 Shape X_train:(766, 2688), Length of y_train:766
2017-09-22 15:19:26,590 DEBUG: Info:	 Shape X_test:(326, 2688), Length of y_test:326
2017-09-22 15:19:26,590 DEBUG: Done:	 Determine Train/Test split
2017-09-22 15:19:26,590 DEBUG: Start:	 RandomSearch best settings with 20 iterations for SVMLinear
2017-09-22 15:19:26,595 DEBUG: Info:	 Shape X_train:(766, 2688), Length of y_train:766
2017-09-22 15:19:26,595 DEBUG: Info:	 Shape X_train:(766, 2688), Length of y_train:766
2017-09-22 15:19:26,595 DEBUG: Info:	 Shape X_test:(326, 2688), Length of y_test:326
2017-09-22 15:19:26,595 DEBUG: Info:	 Shape X_test:(326, 2688), Length of y_test:326
2017-09-22 15:19:26,595 DEBUG: Done:	 Determine Train/Test split
2017-09-22 15:19:26,595 DEBUG: Done:	 Determine Train/Test split
2017-09-22 15:19:26,596 DEBUG: Start:	 RandomSearch best settings with 20 iterations for SGD
2017-09-22 15:19:26,596 DEBUG: Start:	 RandomSearch best settings with 20 iterations for SVMPoly
2017-09-22 15:19:26,607 DEBUG: Info:	 Shape X_train:(766, 2688), Length of y_train:766
2017-09-22 15:19:26,607 DEBUG: Info:	 Shape X_test:(326, 2688), Length of y_test:326
2017-09-22 15:19:26,607 DEBUG: Done:	 Determine Train/Test split
2017-09-22 15:19:26,607 DEBUG: Start:	 RandomSearch best settings with 20 iterations for SVMRBF
2017-09-22 15:19:30,317 DEBUG: Done:	 RandomSearch best settings
2017-09-22 15:19:30,317 DEBUG: Start:	 Training
2017-09-22 15:19:30,394 DEBUG: Done:	 Training
2017-09-22 15:19:30,395 DEBUG: Start:	 Predicting
2017-09-22 15:19:30,410 DEBUG: Done:	 Predicting
2017-09-22 15:19:30,410 DEBUG: Info:	 Time for training and predicting: 3.89180397987[s]
2017-09-22 15:19:30,410 DEBUG: Start:	 Getting Results
2017-09-22 15:19:30,461 DEBUG: Done:	 Getting Results
2017-09-22 15:19:30,462 INFO: Classification on awaexp database for cq-hist with SGD, and 5 statistical iterations

accuracy_score on train : 0.671018276762, with STD : 0.0
accuracy_score on test : 0.650306748466, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : cq-hist	 View shape : (1092, 2688)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 2

Classifier configuration : 
	- SGDClassifier with loss : modified_huber, penalty : l2
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 20 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 0.671018276762
		- Score on test : 0.650306748466
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.688118811881
		- Score on test : 0.666666666667
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 0.688118811881
		- Score on test : 0.666666666667
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.328981723238
		- Score on test : 0.349693251534
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 0.671018276762
		- Score on test : 0.650306748466
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 0.34411186005
		- Score on test : 0.302072296401
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.654117647059
		- Score on test : 0.63687150838
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.725848563969
		- Score on test : 0.699386503067
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 0.671018276762
		- Score on test : 0.650306748466
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.328981723238
		- Score on test : 0.349693251534


 Classification took 0:00:03
2017-09-22 15:19:30,464 INFO: Done:	 Result Analysis
2017-09-22 15:20:05,341 DEBUG: Done:	 RandomSearch best settings
2017-09-22 15:20:05,341 DEBUG: Start:	 Training
2017-09-22 15:20:08,383 DEBUG: Done:	 RandomSearch best settings
2017-09-22 15:20:08,383 DEBUG: Start:	 Training
2017-09-22 15:20:13,364 DEBUG: Done:	 Training
2017-09-22 15:20:13,364 DEBUG: Start:	 Predicting
2017-09-22 15:20:17,509 DEBUG: Done:	 Predicting
2017-09-22 15:20:17,509 DEBUG: Info:	 Time for training and predicting: 50.9905340672[s]
2017-09-22 15:20:17,509 DEBUG: Start:	 Getting Results
2017-09-22 15:20:17,543 DEBUG: Done:	 Getting Results
2017-09-22 15:20:17,543 INFO: Classification on awaexp database for cq-hist with SVMLinear, and 5 statistical iterations

accuracy_score on train : 0.998694516971, with STD : 0.0
accuracy_score on test : 0.644171779141, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : cq-hist	 View shape : (1092, 2688)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 2

Classifier configuration : 
	- SVM Linear with C : 4431
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 20 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 0.998694516971
		- Score on test : 0.644171779141
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.998692810458
		- Score on test : 0.646341463415
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 0.998692810458
		- Score on test : 0.646341463415
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.00130548302872
		- Score on test : 0.355828220859
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 0.998694516971
		- Score on test : 0.644171779141
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 0.997392433632
		- Score on test : 0.288365265996
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.642424242424
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.997389033943
		- Score on test : 0.650306748466
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 0.998694516971
		- Score on test : 0.644171779141
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.00130548302872
		- Score on test : 0.355828220859


 Classification took 0:00:50
2017-09-22 15:20:17,543 INFO: Done:	 Result Analysis
2017-09-22 15:20:17,862 DEBUG: Done:	 Training
2017-09-22 15:20:17,862 DEBUG: Start:	 Predicting
2017-09-22 15:20:19,009 DEBUG: Done:	 RandomSearch best settings
2017-09-22 15:20:19,010 DEBUG: Start:	 Training
2017-09-22 15:20:22,118 DEBUG: Done:	 Predicting
2017-09-22 15:20:22,118 DEBUG: Info:	 Time for training and predicting: 55.5985689163[s]
2017-09-22 15:20:22,118 DEBUG: Start:	 Getting Results
2017-09-22 15:20:22,147 DEBUG: Done:	 Getting Results
2017-09-22 15:20:22,147 INFO: Classification on awaexp database for cq-hist with SVMRBF, and 5 statistical iterations

accuracy_score on train : 0.912532637076, with STD : 0.0
accuracy_score on test : 0.662576687117, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : cq-hist	 View shape : (1092, 2688)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 2

Classifier configuration : 
	- SVM RBF with C : 2076
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 20 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 0.912532637076
		- Score on test : 0.662576687117
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.911957950066
		- Score on test : 0.664634146341
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 0.911957950066
		- Score on test : 0.664634146341
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.0874673629243
		- Score on test : 0.337423312883
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 0.912532637076
		- Score on test : 0.662576687117
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 0.825135590497
		- Score on test : 0.325177853144
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.917989417989
		- Score on test : 0.660606060606
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.906005221932
		- Score on test : 0.668711656442
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 0.912532637076
		- Score on test : 0.662576687117
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.0874673629243
		- Score on test : 0.337423312883


 Classification took 0:00:55
2017-09-22 15:20:22,148 INFO: Done:	 Result Analysis
2017-09-22 15:20:26,330 DEBUG: Done:	 Training
2017-09-22 15:20:26,330 DEBUG: Start:	 Predicting
2017-09-22 15:20:29,941 DEBUG: Done:	 Predicting
2017-09-22 15:20:29,941 DEBUG: Info:	 Time for training and predicting: 63.4220380783[s]
2017-09-22 15:20:29,941 DEBUG: Start:	 Getting Results
2017-09-22 15:20:29,969 DEBUG: Done:	 Getting Results
2017-09-22 15:20:29,969 INFO: Classification on awaexp database for cq-hist with SVMPoly, and 5 statistical iterations

accuracy_score on train : 0.882506527415, with STD : 0.0
accuracy_score on test : 0.69018404908, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : cq-hist	 View shape : (1092, 2688)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 2

Classifier configuration : 
	- SVM Poly with C : 2640
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 20 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 0.882506527415
		- Score on test : 0.69018404908
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.880636604775
		- Score on test : 0.691131498471
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 0.880636604775
		- Score on test : 0.691131498471
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.117493472585
		- Score on test : 0.30981595092
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 0.882506527415
		- Score on test : 0.69018404908
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 0.765388826201
		- Score on test : 0.38037525648
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.894878706199
		- Score on test : 0.689024390244
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.86684073107
		- Score on test : 0.693251533742
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 0.882506527415
		- Score on test : 0.69018404908
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.117493472585
		- Score on test : 0.30981595092


 Classification took 0:01:03
2017-09-22 15:20:29,969 INFO: Done:	 Result Analysis
2017-09-22 15:20:30,084 DEBUG: Start:	 Loading data
2017-09-22 15:20:30,084 DEBUG: Start:	 Loading data
2017-09-22 15:20:30,086 DEBUG: Start:	 Loading data
2017-09-22 15:20:30,086 DEBUG: Start:	 Loading data
2017-09-22 15:20:30,099 DEBUG: Done:	 Loading data
2017-09-22 15:20:30,100 DEBUG: Info:	 Classification - Database:awaexp Feature:lss-hist train_size:0.7, CrossValidation k-folds:2, cores:1, algorithm : RandomForest
2017-09-22 15:20:30,100 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 15:20:30,101 DEBUG: Done:	 Loading data
2017-09-22 15:20:30,101 DEBUG: Info:	 Classification - Database:awaexp Feature:lss-hist train_size:0.7, CrossValidation k-folds:2, cores:1, algorithm : Adaboost
2017-09-22 15:20:30,101 DEBUG: Done:	 Loading data
2017-09-22 15:20:30,101 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 15:20:30,101 DEBUG: Info:	 Classification - Database:awaexp Feature:lss-hist train_size:0.7, CrossValidation k-folds:2, cores:1, algorithm : KNN
2017-09-22 15:20:30,101 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 15:20:30,103 DEBUG: Done:	 Loading data
2017-09-22 15:20:30,103 DEBUG: Info:	 Classification - Database:awaexp Feature:lss-hist train_size:0.7, CrossValidation k-folds:2, cores:1, algorithm : DecisionTree
2017-09-22 15:20:30,104 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 15:20:30,118 DEBUG: Info:	 Shape X_train:(766, 2000), Length of y_train:766
2017-09-22 15:20:30,118 DEBUG: Info:	 Shape X_test:(326, 2000), Length of y_test:326
2017-09-22 15:20:30,118 DEBUG: Done:	 Determine Train/Test split
2017-09-22 15:20:30,119 DEBUG: Start:	 RandomSearch best settings with 20 iterations for RandomForest
2017-09-22 15:20:30,122 DEBUG: Info:	 Shape X_train:(766, 2000), Length of y_train:766
2017-09-22 15:20:30,122 DEBUG: Info:	 Shape X_test:(326, 2000), Length of y_test:326
2017-09-22 15:20:30,122 DEBUG: Done:	 Determine Train/Test split
2017-09-22 15:20:30,123 DEBUG: Start:	 RandomSearch best settings with 20 iterations for KNN
2017-09-22 15:20:30,127 DEBUG: Info:	 Shape X_train:(766, 2000), Length of y_train:766
2017-09-22 15:20:30,127 DEBUG: Info:	 Shape X_test:(326, 2000), Length of y_test:326
2017-09-22 15:20:30,127 DEBUG: Done:	 Determine Train/Test split
2017-09-22 15:20:30,128 DEBUG: Start:	 RandomSearch best settings with 20 iterations for Adaboost
2017-09-22 15:20:30,132 DEBUG: Info:	 Shape X_train:(766, 2000), Length of y_train:766
2017-09-22 15:20:30,132 DEBUG: Info:	 Shape X_test:(326, 2000), Length of y_test:326
2017-09-22 15:20:30,132 DEBUG: Done:	 Determine Train/Test split
2017-09-22 15:20:30,133 DEBUG: Start:	 RandomSearch best settings with 20 iterations for DecisionTree
2017-09-22 15:20:35,522 DEBUG: Done:	 RandomSearch best settings
2017-09-22 15:20:35,523 DEBUG: Start:	 Training
2017-09-22 15:20:35,789 DEBUG: Done:	 Training
2017-09-22 15:20:35,789 DEBUG: Start:	 Predicting
2017-09-22 15:20:35,859 DEBUG: Done:	 Predicting
2017-09-22 15:20:35,859 DEBUG: Info:	 Time for training and predicting: 5.77298998833[s]
2017-09-22 15:20:35,859 DEBUG: Start:	 Getting Results
2017-09-22 15:20:35,891 DEBUG: Done:	 Getting Results
2017-09-22 15:20:35,891 INFO: Classification on awaexp database for lss-hist with RandomForest, and 5 statistical iterations

accuracy_score on train : 0.994778067885, with STD : 0.0
accuracy_score on test : 0.696319018405, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : lss-hist	 View shape : (1092, 2000)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 2

Classifier configuration : 
	- Random Forest with num_esimators : 20, max_depth : 23
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 20 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 0.994778067885
		- Score on test : 0.696319018405
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.994764397906
		- Score on test : 0.683706070288
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 0.994764397906
		- Score on test : 0.683706070288
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.00522193211488
		- Score on test : 0.303680981595
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 0.994778067885
		- Score on test : 0.696319018405
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 0.989569627939
		- Score on test : 0.393892771134
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.997375328084
		- Score on test : 0.713333333333
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.992167101828
		- Score on test : 0.656441717791
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 0.994778067885
		- Score on test : 0.696319018405
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.00522193211488
		- Score on test : 0.303680981595


 Classification took 0:00:05
2017-09-22 15:20:35,891 INFO: Done:	 Result Analysis
2017-09-22 15:20:38,421 DEBUG: Done:	 RandomSearch best settings
2017-09-22 15:20:38,422 DEBUG: Start:	 Training
2017-09-22 15:20:38,492 DEBUG: Done:	 Training
2017-09-22 15:20:38,492 DEBUG: Start:	 Predicting
2017-09-22 15:20:38,504 DEBUG: Done:	 Predicting
2017-09-22 15:20:38,505 DEBUG: Info:	 Time for training and predicting: 8.41998815536[s]
2017-09-22 15:20:38,505 DEBUG: Start:	 Getting Results
2017-09-22 15:20:38,536 DEBUG: Done:	 Getting Results
2017-09-22 15:20:38,537 INFO: Classification on awaexp database for lss-hist with DecisionTree, and 5 statistical iterations

accuracy_score on train : 0.737597911227, with STD : 0.0
accuracy_score on test : 0.696319018405, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : lss-hist	 View shape : (1092, 2000)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 2

Classifier configuration : 
	- Decision Tree with max_depth : 1
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 20 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 0.737597911227
		- Score on test : 0.696319018405
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.715700141443
		- Score on test : 0.64
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 0.715700141443
		- Score on test : 0.64
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.262402088773
		- Score on test : 0.303680981595
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 0.737597911227
		- Score on test : 0.696319018405
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 0.480936510756
		- Score on test : 0.413393911463
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.780864197531
		- Score on test : 0.785714285714
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.660574412533
		- Score on test : 0.539877300613
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 0.737597911227
		- Score on test : 0.696319018405
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.262402088773
		- Score on test : 0.303680981595


 Classification took 0:00:08
2017-09-22 15:20:38,537 INFO: Done:	 Result Analysis
2017-09-22 15:20:41,155 DEBUG: Done:	 RandomSearch best settings
2017-09-22 15:20:41,155 DEBUG: Start:	 Training
2017-09-22 15:20:41,697 DEBUG: Done:	 Training
2017-09-22 15:20:41,698 DEBUG: Start:	 Predicting
2017-09-22 15:20:41,714 DEBUG: Done:	 Predicting
2017-09-22 15:20:41,714 DEBUG: Info:	 Time for training and predicting: 11.6299190521[s]
2017-09-22 15:20:41,714 DEBUG: Start:	 Getting Results
2017-09-22 15:20:41,746 DEBUG: Done:	 Getting Results
2017-09-22 15:20:41,747 INFO: Classification on awaexp database for lss-hist with Adaboost, and 5 statistical iterations

accuracy_score on train : 1.0, with STD : 0.0
accuracy_score on test : 0.656441717791, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : lss-hist	 View shape : (1092, 2000)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 2

Classifier configuration : 
	- Adaboost with num_esimators : 4, base_estimators : DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best')
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 20 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.656441717791
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.645569620253
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.645569620253
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.0
		- Score on test : 0.343558282209
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.656441717791
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.313473915907
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.666666666667
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.625766871166
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.656441717791
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.0
		- Score on test : 0.343558282209


 Classification took 0:00:11
2017-09-22 15:20:41,747 INFO: Done:	 Result Analysis
2017-09-22 15:20:50,095 DEBUG: Done:	 RandomSearch best settings
2017-09-22 15:20:50,095 DEBUG: Start:	 Training
2017-09-22 15:20:50,125 DEBUG: Done:	 Training
2017-09-22 15:20:50,125 DEBUG: Start:	 Predicting
2017-09-22 15:20:55,347 DEBUG: Done:	 Predicting
2017-09-22 15:20:55,347 DEBUG: Info:	 Time for training and predicting: 25.260666132[s]
2017-09-22 15:20:55,348 DEBUG: Start:	 Getting Results
2017-09-22 15:20:55,374 DEBUG: Done:	 Getting Results
2017-09-22 15:20:55,374 INFO: Classification on awaexp database for lss-hist with KNN, and 5 statistical iterations

accuracy_score on train : 0.659268929504, with STD : 0.0
accuracy_score on test : 0.659509202454, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : lss-hist	 View shape : (1092, 2000)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 2

Classifier configuration : 
	- K nearest Neighbors with  n_neighbors: 43
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 20 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 0.659268929504
		- Score on test : 0.659509202454
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.607518796992
		- Score on test : 0.621160409556
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 0.607518796992
		- Score on test : 0.621160409556
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.340731070496
		- Score on test : 0.340490797546
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 0.659268929504
		- Score on test : 0.659509202454
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 0.330227012588
		- Score on test : 0.325764407171
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.716312056738
		- Score on test : 0.7
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.527415143603
		- Score on test : 0.558282208589
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 0.659268929504
		- Score on test : 0.659509202454
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.340731070496
		- Score on test : 0.340490797546


 Classification took 0:00:25
2017-09-22 15:20:55,375 INFO: Done:	 Result Analysis
2017-09-22 15:20:55,508 DEBUG: Start:	 Loading data
2017-09-22 15:20:55,508 DEBUG: Start:	 Loading data
2017-09-22 15:20:55,509 DEBUG: Start:	 Loading data
2017-09-22 15:20:55,509 DEBUG: Start:	 Loading data
2017-09-22 15:20:55,527 DEBUG: Done:	 Loading data
2017-09-22 15:20:55,528 DEBUG: Done:	 Loading data
2017-09-22 15:20:55,528 DEBUG: Done:	 Loading data
2017-09-22 15:20:55,528 DEBUG: Info:	 Classification - Database:awaexp Feature:lss-hist train_size:0.7, CrossValidation k-folds:2, cores:1, algorithm : SGD
2017-09-22 15:20:55,528 DEBUG: Info:	 Classification - Database:awaexp Feature:lss-hist train_size:0.7, CrossValidation k-folds:2, cores:1, algorithm : SVMPoly
2017-09-22 15:20:55,528 DEBUG: Info:	 Classification - Database:awaexp Feature:lss-hist train_size:0.7, CrossValidation k-folds:2, cores:1, algorithm : SVMLinear
2017-09-22 15:20:55,528 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 15:20:55,528 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 15:20:55,528 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 15:20:55,529 DEBUG: Done:	 Loading data
2017-09-22 15:20:55,529 DEBUG: Info:	 Classification - Database:awaexp Feature:lss-hist train_size:0.7, CrossValidation k-folds:2, cores:1, algorithm : SVMRBF
2017-09-22 15:20:55,529 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 15:20:55,564 DEBUG: Info:	 Shape X_train:(766, 2000), Length of y_train:766
2017-09-22 15:20:55,564 DEBUG: Info:	 Shape X_train:(766, 2000), Length of y_train:766
2017-09-22 15:20:55,565 DEBUG: Info:	 Shape X_test:(326, 2000), Length of y_test:326
2017-09-22 15:20:55,565 DEBUG: Info:	 Shape X_test:(326, 2000), Length of y_test:326
2017-09-22 15:20:55,565 DEBUG: Done:	 Determine Train/Test split
2017-09-22 15:20:55,565 DEBUG: Done:	 Determine Train/Test split
2017-09-22 15:20:55,565 DEBUG: Start:	 RandomSearch best settings with 20 iterations for SVMPoly
2017-09-22 15:20:55,565 DEBUG: Start:	 RandomSearch best settings with 20 iterations for SGD
2017-09-22 15:20:55,565 DEBUG: Info:	 Shape X_train:(766, 2000), Length of y_train:766
2017-09-22 15:20:55,566 DEBUG: Info:	 Shape X_test:(326, 2000), Length of y_test:326
2017-09-22 15:20:55,566 DEBUG: Done:	 Determine Train/Test split
2017-09-22 15:20:55,566 DEBUG: Start:	 RandomSearch best settings with 20 iterations for SVMRBF
2017-09-22 15:20:55,568 DEBUG: Info:	 Shape X_train:(766, 2000), Length of y_train:766
2017-09-22 15:20:55,568 DEBUG: Info:	 Shape X_test:(326, 2000), Length of y_test:326
2017-09-22 15:20:55,568 DEBUG: Done:	 Determine Train/Test split
2017-09-22 15:20:55,568 DEBUG: Start:	 RandomSearch best settings with 20 iterations for SVMLinear
2017-09-22 15:20:58,849 DEBUG: Done:	 RandomSearch best settings
2017-09-22 15:20:58,849 DEBUG: Start:	 Training
2017-09-22 15:20:58,986 DEBUG: Done:	 Training
2017-09-22 15:20:58,986 DEBUG: Start:	 Predicting
2017-09-22 15:20:58,998 DEBUG: Done:	 Predicting
2017-09-22 15:20:58,998 DEBUG: Info:	 Time for training and predicting: 3.48953294754[s]
2017-09-22 15:20:58,998 DEBUG: Start:	 Getting Results
2017-09-22 15:20:59,057 DEBUG: Done:	 Getting Results
2017-09-22 15:20:59,057 INFO: Classification on awaexp database for lss-hist with SGD, and 5 statistical iterations

accuracy_score on train : 0.90861618799, with STD : 0.0
accuracy_score on test : 0.766871165644, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : lss-hist	 View shape : (1092, 2000)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 2

Classifier configuration : 
	- SGDClassifier with loss : modified_huber, penalty : elasticnet
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 20 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 0.90861618799
		- Score on test : 0.766871165644
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.915254237288
		- Score on test : 0.788888888889
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 0.915254237288
		- Score on test : 0.788888888889
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.0913838120104
		- Score on test : 0.233128834356
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 0.90861618799
		- Score on test : 0.766871165644
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 0.827448957764
		- Score on test : 0.545746908693
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.853273137698
		- Score on test : 0.720812182741
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.986945169713
		- Score on test : 0.871165644172
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 0.90861618799
		- Score on test : 0.766871165644
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.0913838120104
		- Score on test : 0.233128834356


 Classification took 0:00:03
2017-09-22 15:20:59,058 INFO: Done:	 Result Analysis
2017-09-22 15:21:12,034 DEBUG: Done:	 RandomSearch best settings
2017-09-22 15:21:12,035 DEBUG: Start:	 Training
2017-09-22 15:21:17,556 DEBUG: Done:	 Training
2017-09-22 15:21:17,557 DEBUG: Start:	 Predicting
2017-09-22 15:21:20,345 DEBUG: Done:	 Predicting
2017-09-22 15:21:20,346 DEBUG: Info:	 Time for training and predicting: 24.8365252018[s]
2017-09-22 15:21:20,346 DEBUG: Start:	 Getting Results
2017-09-22 15:21:20,379 DEBUG: Done:	 Getting Results
2017-09-22 15:21:20,379 INFO: Classification on awaexp database for lss-hist with SVMPoly, and 5 statistical iterations

accuracy_score on train : 1.0, with STD : 0.0
accuracy_score on test : 0.763803680982, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : lss-hist	 View shape : (1092, 2000)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 2

Classifier configuration : 
	- SVM Poly with C : 2640
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 20 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.763803680982
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.757097791798
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.757097791798
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.0
		- Score on test : 0.236196319018
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.763803680982
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.528413454807
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.779220779221
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.736196319018
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.763803680982
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.0
		- Score on test : 0.236196319018


 Classification took 0:00:24
2017-09-22 15:21:20,395 INFO: Done:	 Result Analysis
2017-09-22 15:21:21,321 DEBUG: Done:	 RandomSearch best settings
2017-09-22 15:21:21,322 DEBUG: Start:	 Training
2017-09-22 15:21:25,872 DEBUG: Done:	 Training
2017-09-22 15:21:25,872 DEBUG: Start:	 Predicting
2017-09-22 15:21:28,131 DEBUG: Done:	 Predicting
2017-09-22 15:21:28,131 DEBUG: Info:	 Time for training and predicting: 32.6222882271[s]
2017-09-22 15:21:28,131 DEBUG: Start:	 Getting Results
2017-09-22 15:21:28,159 DEBUG: Done:	 Getting Results
2017-09-22 15:21:28,159 INFO: Classification on awaexp database for lss-hist with SVMLinear, and 5 statistical iterations

accuracy_score on train : 1.0, with STD : 0.0
accuracy_score on test : 0.751533742331, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : lss-hist	 View shape : (1092, 2000)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 2

Classifier configuration : 
	- SVM Linear with C : 4431
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 20 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.751533742331
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.744479495268
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.744479495268
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.0
		- Score on test : 0.248466257669
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.751533742331
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.503836084816
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.766233766234
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.723926380368
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.751533742331
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.0
		- Score on test : 0.248466257669


 Classification took 0:00:32
2017-09-22 15:21:28,160 INFO: Done:	 Result Analysis
2017-09-22 15:21:31,268 DEBUG: Done:	 RandomSearch best settings
2017-09-22 15:21:31,268 DEBUG: Start:	 Training
2017-09-22 15:21:37,402 DEBUG: Done:	 Training
2017-09-22 15:21:37,402 DEBUG: Start:	 Predicting
2017-09-22 15:21:40,890 DEBUG: Done:	 Predicting
2017-09-22 15:21:40,890 DEBUG: Info:	 Time for training and predicting: 45.38053298[s]
2017-09-22 15:21:40,890 DEBUG: Start:	 Getting Results
2017-09-22 15:21:40,917 DEBUG: Done:	 Getting Results
2017-09-22 15:21:40,917 INFO: Classification on awaexp database for lss-hist with SVMRBF, and 5 statistical iterations

accuracy_score on train : 1.0, with STD : 0.0
accuracy_score on test : 0.536809815951, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : lss-hist	 View shape : (1092, 2000)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 2

Classifier configuration : 
	- SVM RBF with C : 4431
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 20 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.536809815951
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.678038379531
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.678038379531
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.0
		- Score on test : 0.463190184049
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.536809815951
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.153392997769
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.519607843137
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.975460122699
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.536809815951
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.0
		- Score on test : 0.463190184049


 Classification took 0:00:45
2017-09-22 15:21:40,917 INFO: Done:	 Result Analysis
2017-09-22 15:21:41,069 INFO: ### Main Programm for Multiview Classification
2017-09-22 15:21:41,070 INFO: ### Classification - Database : awaexp ; Views : cq-hist, lss-hist ; Algorithm : Fusion ; Cores : 1
2017-09-22 15:21:41,070 INFO: ### Main Programm for Multiview Classification
2017-09-22 15:21:41,070 INFO: ### Classification - Database : awaexp ; Views : cq-hist, lss-hist ; Algorithm : Fusion ; Cores : 1
2017-09-22 15:21:41,071 INFO: ### Main Programm for Multiview Classification
2017-09-22 15:21:41,071 INFO: ### Classification - Database : awaexp ; Views : cq-hist, lss-hist ; Algorithm : Fusion ; Cores : 1
2017-09-22 15:21:41,071 INFO: Info:	 Shape of cq-hist :(1092, 2688)
2017-09-22 15:21:41,072 INFO: Info:	 Shape of cq-hist :(1092, 2688)
2017-09-22 15:21:41,072 INFO: ### Main Programm for Multiview Classification
2017-09-22 15:21:41,072 INFO: ### Classification - Database : awaexp ; Views : cq-hist, lss-hist ; Algorithm : Fusion ; Cores : 1
2017-09-22 15:21:41,072 INFO: Info:	 Shape of lss-hist :(1092, 2000)
2017-09-22 15:21:41,072 INFO: Info:	 Shape of cq-hist :(1092, 2688)
2017-09-22 15:21:41,072 INFO: Done:	 Read Database Files
2017-09-22 15:21:41,072 INFO: Info:	 Shape of lss-hist :(1092, 2000)
2017-09-22 15:21:41,072 INFO: Start:	 Determine validation split for ratio 0.7
2017-09-22 15:21:41,073 INFO: Done:	 Read Database Files
2017-09-22 15:21:41,073 INFO: Start:	 Determine validation split for ratio 0.7
2017-09-22 15:21:41,073 INFO: Info:	 Shape of lss-hist :(1092, 2000)
2017-09-22 15:21:41,073 INFO: Done:	 Read Database Files
2017-09-22 15:21:41,073 INFO: Info:	 Shape of cq-hist :(1092, 2688)
2017-09-22 15:21:41,073 INFO: Start:	 Determine validation split for ratio 0.7
2017-09-22 15:21:41,074 INFO: Info:	 Shape of lss-hist :(1092, 2000)
2017-09-22 15:21:41,074 INFO: Done:	 Read Database Files
2017-09-22 15:21:41,074 INFO: Start:	 Determine validation split for ratio 0.7
2017-09-22 15:21:41,175 INFO: Done:	 Determine validation split
2017-09-22 15:21:41,175 INFO: Start:	 Determine 2 folds
2017-09-22 15:21:41,176 INFO: Done:	 Determine validation split
2017-09-22 15:21:41,176 INFO: Start:	 Determine 2 folds
2017-09-22 15:21:41,176 INFO: Done:	 Determine validation split
2017-09-22 15:21:41,176 INFO: Done:	 Determine validation split
2017-09-22 15:21:41,176 INFO: Start:	 Determine 2 folds
2017-09-22 15:21:41,176 INFO: Start:	 Determine 2 folds
2017-09-22 15:23:20,892 INFO: Done:	 Classification
2017-09-22 15:23:21,861 INFO: Done:	 Classification
2017-09-22 15:23:22,796 INFO: Done:	 Classification
2017-09-22 15:23:23,579 INFO: Done:	 Classification
2017-09-22 15:23:24,525 INFO: Done:	 Classification
2017-09-22 15:23:24,526 INFO: Info:	 Time for Classification: 103[s]
2017-09-22 15:23:24,526 INFO: Start:	 Result Analysis for Fusion
2017-09-22 15:23:25,723 INFO: 		Result for Multiview classification with LateFusion

Average accuracy_score :
	-On Train : 0.935770234987
	-On Test : 0.765644171779

Dataset info :
	-Database name : awaexp
	-Labels : 
	-Views : cq-hist, lss-hist
	-2 folds

Classification configuration : 
	-Algorithm used : LateFusion with Bayesian Inference using a weight for each view : 0.468344038717, 0.531655961283
	-With monoview classifiers : 
		- SGDClassifier with loss : modified_huber, penalty : l2
		- SGDClassifier with loss : modified_huber, penalty : elasticnet

	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 0.935770234987 with STD : 0.0100919833369
		- Score on test : 0.765644171779 with STD : 0.0205864561173

	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.935715958222 with STD : 0.0104056406106
		- Score on test : 0.774713716177 with STD : 0.0119980053689

	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 0.935715958222 with STD : 0.0104056406106
		- Score on test : 0.774713716177 with STD : 0.0119980053689

	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.0642297650131 with STD : 0.0100919833369
		- Score on test : 0.234355828221 with STD : 0.0205864561173

	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 0.935770234987 with STD : 0.0100919833369
		- Score on test : 0.765644171779 with STD : 0.0205864561173

	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 0.873353087698 with STD : 0.0208530817938
		- Score on test : 0.536583295537 with STD : 0.0376442422002

	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.937028186848 with STD : 0.0288106065084
		- Score on test : 0.750864226564 with STD : 0.0439764143916

	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.936292428198 with STD : 0.0343458666369
		- Score on test : 0.80490797546 with STD : 0.043966804582

	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 0.935770234987 with STD : 0.0100919833369
		- Score on test : 0.765644171779 with STD : 0.0205864561173

	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.0642297650131 with STD : 0.0100919833369
		- Score on test : 0.234355828221 with STD : 0.0205864561173


2017-09-22 15:23:25,729 INFO: Done:	 Result Analysis
2017-09-22 15:23:30,891 INFO: Done:	 Classification
2017-09-22 15:23:31,604 INFO: Done:	 Classification
2017-09-22 15:23:32,737 INFO: Done:	 Classification
2017-09-22 15:23:33,428 INFO: Done:	 Classification
2017-09-22 15:23:34,238 INFO: Done:	 Classification
2017-09-22 15:23:34,239 INFO: Info:	 Time for Classification: 113[s]
2017-09-22 15:23:34,239 INFO: Start:	 Result Analysis for Fusion
2017-09-22 15:23:35,008 INFO: 		Result for Multiview classification with LateFusion

Average accuracy_score :
	-On Train : 0.921409921671
	-On Test : 0.771165644172

Dataset info :
	-Database name : awaexp
	-Labels : 
	-Views : cq-hist, lss-hist
	-2 folds

Classification configuration : 
	-Algorithm used : LateFusion with Majority Voting 
	-With monoview classifiers : 
		- SGDClassifier with loss : modified_huber, penalty : l2
		- SGDClassifier with loss : modified_huber, penalty : elasticnet

	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 0.921409921671 with STD : 0.010746274479
		- Score on test : 0.771165644172 with STD : 0.0120533022726

	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.920511234097 with STD : 0.0103233115923
		- Score on test : 0.769568689392 with STD : 0.0219732543554

	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 0.920511234097 with STD : 0.0103233115923
		- Score on test : 0.769568689392 with STD : 0.0219732543554

	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.078590078329 with STD : 0.010746274479
		- Score on test : 0.228834355828 with STD : 0.0120533022726

	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 0.921409921671 with STD : 0.010746274479
		- Score on test : 0.771165644172 with STD : 0.0120533022726

	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 0.848090681947 with STD : 0.0198951734938
		- Score on test : 0.55154560512 with STD : 0.0269686279704

	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.936431809467 with STD : 0.0523933339542
		- Score on test : 0.780105771849 with STD : 0.0530162883504

	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.910704960836 with STD : 0.0519942932131
		- Score on test : 0.771779141104 with STD : 0.0899479401625

	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 0.921409921671 with STD : 0.010746274479
		- Score on test : 0.771165644172 with STD : 0.0120533022726

	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.078590078329 with STD : 0.010746274479
		- Score on test : 0.228834355828 with STD : 0.0120533022726


2017-09-22 15:23:35,013 INFO: Done:	 Result Analysis
2017-09-22 15:23:37,771 INFO: Done:	 Classification
2017-09-22 15:23:38,394 INFO: Done:	 Classification
2017-09-22 15:23:39,013 INFO: Done:	 Classification
2017-09-22 15:23:39,626 INFO: Done:	 Classification
2017-09-22 15:23:40,246 INFO: Done:	 Classification
2017-09-22 15:23:40,246 INFO: Info:	 Time for Classification: 119[s]
2017-09-22 15:23:40,247 INFO: Start:	 Result Analysis for Fusion
2017-09-22 15:23:40,772 INFO: 		Result for Multiview classification with LateFusion

Average accuracy_score :
	-On Train : 0.925587467363
	-On Test : 0.720858895706

Dataset info :
	-Database name : awaexp
	-Labels : 
	-Views : cq-hist, lss-hist
	-2 folds

Classification configuration : 
	-Algorithm used : LateFusion with SVM for linear 
	-With monoview classifiers : 
		- SGDClassifier with loss : modified_huber, penalty : l2
		- SGDClassifier with loss : modified_huber, penalty : elasticnet

	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 0.925587467363 with STD : 0.0
		- Score on test : 0.720858895706 with STD : 0.0

	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.921595598349 with STD : 0.0
		- Score on test : 0.693602693603 with STD : 0.0

	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 0.921595598349 with STD : 0.0
		- Score on test : 0.693602693603 with STD : 0.0

	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.0744125326371 with STD : 0.0
		- Score on test : 0.279141104294 with STD : 0.0

	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 0.925587467363 with STD : 0.0
		- Score on test : 0.720858895706 with STD : 0.0

	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 0.85562241482 with STD : 0.0
		- Score on test : 0.448879201248 with STD : 5.55111512313e-17

	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.973837209302 with STD : 0.0
		- Score on test : 0.768656716418 with STD : 0.0

	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.874673629243 with STD : 0.0
		- Score on test : 0.631901840491 with STD : 0.0

	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 0.925587467363 with STD : 0.0
		- Score on test : 0.720858895706 with STD : 0.0

	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.0744125326371 with STD : 0.0
		- Score on test : 0.279141104294 with STD : 0.0


2017-09-22 15:23:40,773 INFO: Done:	 Result Analysis
2017-09-22 15:23:56,413 INFO: Done:	 Classification
2017-09-22 15:23:57,189 INFO: Done:	 Classification
2017-09-22 15:23:57,923 INFO: Done:	 Classification
2017-09-22 15:23:58,681 INFO: Done:	 Classification
2017-09-22 15:23:59,440 INFO: Done:	 Classification
2017-09-22 15:23:59,440 INFO: Info:	 Time for Classification: 138[s]
2017-09-22 15:23:59,440 INFO: Start:	 Result Analysis for Fusion
2017-09-22 15:23:59,908 INFO: 		Result for Multiview classification with LateFusion

Average accuracy_score :
	-On Train : 0.960835509138
	-On Test : 0.794478527607

Dataset info :
	-Database name : awaexp
	-Labels : 
	-Views : cq-hist, lss-hist
	-2 folds

Classification configuration : 
	-Algorithm used : LateFusion with SCM for linear with max_attributes : 12, p : 0.310533606766 model_type : disjunction has chosen 1 rule(s) 
	-With monoview classifiers : 
		- SGDClassifier with loss : modified_huber, penalty : l2
		- SGDClassifier with loss : modified_huber, penalty : elasticnet

	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 0.960835509138 with STD : 0.0
		- Score on test : 0.794478527607 with STD : 0.0

	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.961038961039 with STD : 1.11022302463e-16
		- Score on test : 0.804664723032 with STD : 1.11022302463e-16

	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 0.961038961039 with STD : 1.11022302463e-16
		- Score on test : 0.804664723032 with STD : 1.11022302463e-16

	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.0391644908616 with STD : 0.0
		- Score on test : 0.205521472393 with STD : 0.0

	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 0.960835509138 with STD : 0.0
		- Score on test : 0.794478527607 with STD : 0.0

	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 0.9217212877 with STD : 0.0
		- Score on test : 0.592186568158 with STD : 0.0

	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.956072351421 with STD : 0.0
		- Score on test : 0.766666666667 with STD : 0.0

	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.966057441253 with STD : 0.0
		- Score on test : 0.846625766871 with STD : 1.11022302463e-16

	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 0.960835509138 with STD : 0.0
		- Score on test : 0.794478527607 with STD : 0.0

	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.0391644908616 with STD : 0.0
		- Score on test : 0.205521472393 with STD : 2.77555756156e-17


2017-09-22 15:23:59,908 INFO: Done:	 Result Analysis
2017-09-22 15:24:00,001 INFO: ### Main Programm for Multiview Classification
2017-09-22 15:24:00,002 INFO: ### Classification - Database : awaexp ; Views : cq-hist, lss-hist ; Algorithm : Fusion ; Cores : 1
2017-09-22 15:24:00,002 INFO: ### Main Programm for Multiview Classification
2017-09-22 15:24:00,002 INFO: ### Classification - Database : awaexp ; Views : cq-hist, lss-hist ; Algorithm : Fusion ; Cores : 1
2017-09-22 15:24:00,003 INFO: Info:	 Shape of cq-hist :(1092, 2688)
2017-09-22 15:24:00,003 INFO: ### Main Programm for Multiview Classification
2017-09-22 15:24:00,003 INFO: ### Classification - Database : awaexp ; Views : cq-hist, lss-hist ; Algorithm : Fusion ; Cores : 1
2017-09-22 15:24:00,004 INFO: Info:	 Shape of cq-hist :(1092, 2688)
2017-09-22 15:24:00,004 INFO: Info:	 Shape of lss-hist :(1092, 2000)
2017-09-22 15:24:00,004 INFO: Done:	 Read Database Files
2017-09-22 15:24:00,004 INFO: Start:	 Determine validation split for ratio 0.7
2017-09-22 15:24:00,004 INFO: ### Main Programm for Multiview Classification
2017-09-22 15:24:00,005 INFO: ### Classification - Database : awaexp ; Views : cq-hist, lss-hist ; Algorithm : Fusion ; Cores : 1
2017-09-22 15:24:00,005 INFO: Info:	 Shape of lss-hist :(1092, 2000)
2017-09-22 15:24:00,005 INFO: Info:	 Shape of cq-hist :(1092, 2688)
2017-09-22 15:24:00,005 INFO: Done:	 Read Database Files
2017-09-22 15:24:00,005 INFO: Start:	 Determine validation split for ratio 0.7
2017-09-22 15:24:00,006 INFO: Info:	 Shape of lss-hist :(1092, 2000)
2017-09-22 15:24:00,006 INFO: Done:	 Read Database Files
2017-09-22 15:24:00,006 INFO: Info:	 Shape of cq-hist :(1092, 2688)
2017-09-22 15:24:00,006 INFO: Start:	 Determine validation split for ratio 0.7
2017-09-22 15:24:00,007 INFO: Info:	 Shape of lss-hist :(1092, 2000)
2017-09-22 15:24:00,007 INFO: Done:	 Read Database Files
2017-09-22 15:24:00,008 INFO: Start:	 Determine validation split for ratio 0.7
2017-09-22 15:24:00,104 INFO: Done:	 Determine validation split
2017-09-22 15:24:00,104 INFO: Start:	 Determine 2 folds
2017-09-22 15:24:00,105 INFO: Done:	 Determine validation split
2017-09-22 15:24:00,105 INFO: Start:	 Determine 2 folds
2017-09-22 15:24:00,106 INFO: Done:	 Determine validation split
2017-09-22 15:24:00,106 INFO: Start:	 Determine 2 folds
2017-09-22 15:24:00,107 INFO: Done:	 Determine validation split
2017-09-22 15:24:00,107 INFO: Start:	 Determine 2 folds
2017-09-22 15:24:53,056 INFO: Done:	 Classification
2017-09-22 15:24:53,479 INFO: Done:	 Classification
2017-09-22 15:24:53,905 INFO: Done:	 Classification
2017-09-22 15:24:54,332 INFO: Done:	 Classification
2017-09-22 15:24:54,768 INFO: Done:	 Classification
2017-09-22 15:24:54,768 INFO: Info:	 Time for Classification: 54[s]
2017-09-22 15:24:54,768 INFO: Start:	 Result Analysis for Fusion
2017-09-22 15:24:55,254 INFO: 		Result for Multiview classification with LateFusion

Average accuracy_score :
	-On Train : 0.5
	-On Test : 0.5

Dataset info :
	-Database name : awaexp
	-Labels : 
	-Views : cq-hist, lss-hist
	-2 folds

Classification configuration : 
	-Algorithm used : LateFusion with Weighted linear using a weight for each view : 0.880915616157, 1.0
	-With monoview classifiers : 
		- SGDClassifier with loss : modified_huber, penalty : l2
		- SGDClassifier with loss : modified_huber, penalty : elasticnet

	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 0.5 with STD : 0.0
		- Score on test : 0.5 with STD : 0.0

	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.666666666667 with STD : 0.0
		- Score on test : 0.666666666667 with STD : 0.0

	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 0.666666666667 with STD : 0.0
		- Score on test : 0.666666666667 with STD : 0.0

	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.5 with STD : 0.0
		- Score on test : 0.5 with STD : 0.0

	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 0.5 with STD : 0.0
		- Score on test : 0.5 with STD : 0.0

	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 0.0 with STD : 0.0
		- Score on test : 0.0 with STD : 0.0

	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.5 with STD : 0.0
		- Score on test : 0.5 with STD : 0.0

	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0 with STD : 0.0
		- Score on test : 1.0 with STD : 0.0

	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 0.5 with STD : 0.0
		- Score on test : 0.5 with STD : 0.0

	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.5 with STD : 0.0
		- Score on test : 0.5 with STD : 0.0


2017-09-22 15:24:55,254 INFO: Done:	 Result Analysis
2017-09-22 15:25:40,130 INFO: Done:	 Classification
2017-09-22 15:25:40,969 INFO: Done:	 Classification
2017-09-22 15:25:41,807 INFO: Done:	 Classification
2017-09-22 15:25:42,648 INFO: Done:	 Classification
2017-09-22 15:25:43,496 INFO: Done:	 Classification
2017-09-22 15:25:43,497 INFO: Info:	 Time for Classification: 103[s]
2017-09-22 15:25:43,497 INFO: Start:	 Result Analysis for Fusion
2017-09-22 15:25:43,942 INFO: 		Result for Multiview classification with EarlyFusion

Average accuracy_score :
	-On Train : 0.81592689295
	-On Test : 0.761349693252

Dataset info :
	-Database name : awaexp
	-Labels : 
	-Views : cq-hist, lss-hist
	-2 folds

Classification configuration : 
	-Algorithm used : EarlyFusion with weighted concatenation, using weights : 0.880915616157, 1.0 with monoview classifier : 
		- Decision Tree with max_depth : 3

	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 0.81592689295 with STD : 0.0
		- Score on test : 0.761349693252 with STD : 0.00122699386503

	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.814229249012 with STD : 0.0
		- Score on test : 0.763814289686 with STD : 0.000355852098971

	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 0.814229249012 with STD : 0.0
		- Score on test : 0.763814289686 with STD : 0.000355852098971

	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.18407310705 with STD : 0.0
		- Score on test : 0.238650306748 with STD : 0.00122699386503

	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 0.81592689295 with STD : 0.0
		- Score on test : 0.761349693252 with STD : 0.00122699386503

	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 0.63195934458 with STD : 0.0
		- Score on test : 0.522827042555 with STD : 0.0023951243455

	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.821808510638 with STD : 1.11022302463e-16
		- Score on test : 0.756031838762 with STD : 0.00308164159486

	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.806788511749 with STD : 0.0
		- Score on test : 0.771779141104 with STD : 0.00245398773006

	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 0.81592689295 with STD : 0.0
		- Score on test : 0.761349693252 with STD : 0.00122699386503

	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.18407310705 with STD : 0.0
		- Score on test : 0.238650306748 with STD : 0.00122699386503


2017-09-22 15:25:43,942 INFO: Done:	 Result Analysis
2017-09-22 15:26:49,465 INFO: Done:	 Classification
2017-09-22 15:26:50,915 INFO: Done:	 Classification
2017-09-22 15:26:52,405 INFO: Done:	 Classification
2017-09-22 15:26:53,885 INFO: Done:	 Classification
2017-09-22 15:26:55,337 INFO: Done:	 Classification
2017-09-22 15:26:55,337 INFO: Info:	 Time for Classification: 175[s]
2017-09-22 15:26:55,337 INFO: Start:	 Result Analysis for Fusion
2017-09-22 15:26:55,730 INFO: 		Result for Multiview classification with EarlyFusion

Average accuracy_score :
	-On Train : 1.0
	-On Test : 0.676073619632

Dataset info :
	-Database name : awaexp
	-Labels : 
	-Views : cq-hist, lss-hist
	-2 folds

Classification configuration : 
	-Algorithm used : EarlyFusion with weighted concatenation, using weights : 0.880915616157, 1.0 with monoview classifier : 
		- Adaboost with num_esimators : 2, base_estimators : DecisionTreeClassifier

	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 1.0 with STD : 0.0
		- Score on test : 0.676073619632 with STD : 0.0103751745554

	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0 with STD : 0.0
		- Score on test : 0.670346314584 with STD : 0.0115934576486

	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 1.0 with STD : 0.0
		- Score on test : 0.670346314584 with STD : 0.0115934576486

	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.0 with STD : 0.0
		- Score on test : 0.323926380368 with STD : 0.0103751745554

	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 1.0 with STD : 0.0
		- Score on test : 0.676073619632 with STD : 0.0103751745554

	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 1.0 with STD : 0.0
		- Score on test : 0.352483888102 with STD : 0.020663312867

	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0 with STD : 0.0
		- Score on test : 0.682484956007 with STD : 0.0117935360735

	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0 with STD : 0.0
		- Score on test : 0.658895705521 with STD : 0.0171779141104

	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 1.0 with STD : 0.0
		- Score on test : 0.676073619632 with STD : 0.0103751745554

	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.0 with STD : 0.0
		- Score on test : 0.323926380368 with STD : 0.0103751745554


2017-09-22 15:26:55,730 INFO: Done:	 Result Analysis
2017-09-22 15:29:27,698 INFO: Done:	 Classification
2017-09-22 15:29:32,746 INFO: Done:	 Classification
2017-09-22 15:29:37,762 INFO: Done:	 Classification
2017-09-22 15:29:42,797 INFO: Done:	 Classification
2017-09-22 15:29:47,805 INFO: Done:	 Classification
2017-09-22 15:29:47,805 INFO: Info:	 Time for Classification: 347[s]
2017-09-22 15:29:47,805 INFO: Start:	 Result Analysis for Fusion
2017-09-22 15:29:48,173 INFO: 		Result for Multiview classification with EarlyFusion

Average accuracy_score :
	-On Train : 1.0
	-On Test : 0.592024539877

Dataset info :
	-Database name : awaexp
	-Labels : 
	-Views : cq-hist, lss-hist
	-2 folds

Classification configuration : 
	-Algorithm used : EarlyFusion with weighted concatenation, using weights : 0.880915616157, 1.0 with monoview classifier : 
		- K nearest Neighbors with  n_neighbors: 1.0

	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 1.0 with STD : 0.0
		- Score on test : 0.592024539877 with STD : 0.0

	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0 with STD : 0.0
		- Score on test : 0.583072100313 with STD : 0.0

	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 1.0 with STD : 0.0
		- Score on test : 0.583072100313 with STD : 0.0

	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.0 with STD : 0.0
		- Score on test : 0.407975460123 with STD : 0.0

	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 1.0 with STD : 0.0
		- Score on test : 0.592024539877 with STD : 0.0

	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 1.0 with STD : 0.0
		- Score on test : 0.184219031546 with STD : 0.0

	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0 with STD : 0.0
		- Score on test : 0.596153846154 with STD : 0.0

	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0 with STD : 0.0
		- Score on test : 0.570552147239 with STD : 0.0

	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 1.0 with STD : 0.0
		- Score on test : 0.592024539877 with STD : 0.0

	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.0 with STD : 0.0
		- Score on test : 0.407975460123 with STD : 0.0


2017-09-22 15:29:48,173 INFO: Done:	 Result Analysis
2017-09-22 15:29:48,255 INFO: ### Main Programm for Multiview Classification
2017-09-22 15:29:48,255 INFO: ### Classification - Database : awaexp ; Views : cq-hist, lss-hist ; Algorithm : Fusion ; Cores : 1
2017-09-22 15:29:48,256 INFO: ### Main Programm for Multiview Classification
2017-09-22 15:29:48,256 INFO: ### Classification - Database : awaexp ; Views : cq-hist, lss-hist ; Algorithm : Fusion ; Cores : 1
2017-09-22 15:29:48,256 INFO: ### Main Programm for Multiview Classification
2017-09-22 15:29:48,256 INFO: ### Classification - Database : awaexp ; Views : cq-hist, lss-hist ; Algorithm : Fusion ; Cores : 1
2017-09-22 15:29:48,257 INFO: Info:	 Shape of cq-hist :(1092, 2688)
2017-09-22 15:29:48,257 INFO: Info:	 Shape of lss-hist :(1092, 2000)
2017-09-22 15:29:48,257 INFO: Info:	 Shape of cq-hist :(1092, 2688)
2017-09-22 15:29:48,257 INFO: Done:	 Read Database Files
2017-09-22 15:29:48,257 INFO: Info:	 Shape of cq-hist :(1092, 2688)
2017-09-22 15:29:48,258 INFO: Start:	 Determine validation split for ratio 0.7
2017-09-22 15:29:48,258 INFO: ### Main Programm for Multiview Classification
2017-09-22 15:29:48,258 INFO: Info:	 Shape of lss-hist :(1092, 2000)
2017-09-22 15:29:48,258 INFO: Done:	 Read Database Files
2017-09-22 15:29:48,258 INFO: ### Classification - Database : awaexp ; Views : cq-hist, lss-hist ; Algorithm : Fusion ; Cores : 1
2017-09-22 15:29:48,258 INFO: Start:	 Determine validation split for ratio 0.7
2017-09-22 15:29:48,258 INFO: Info:	 Shape of lss-hist :(1092, 2000)
2017-09-22 15:29:48,259 INFO: Done:	 Read Database Files
2017-09-22 15:29:48,259 INFO: Start:	 Determine validation split for ratio 0.7
2017-09-22 15:29:48,260 INFO: Info:	 Shape of cq-hist :(1092, 2688)
2017-09-22 15:29:48,260 INFO: Info:	 Shape of lss-hist :(1092, 2000)
2017-09-22 15:29:48,261 INFO: Done:	 Read Database Files
2017-09-22 15:29:48,261 INFO: Start:	 Determine validation split for ratio 0.7
2017-09-22 15:29:48,317 INFO: Done:	 Determine validation split
2017-09-22 15:29:48,317 INFO: Start:	 Determine 2 folds
2017-09-22 15:29:48,319 INFO: Done:	 Determine validation split
2017-09-22 15:29:48,319 INFO: Start:	 Determine 2 folds
2017-09-22 15:29:48,366 INFO: Done:	 Determine validation split
2017-09-22 15:29:48,366 INFO: Start:	 Determine 2 folds
2017-09-22 15:29:48,368 INFO: Done:	 Determine validation split
2017-09-22 15:29:48,368 INFO: Start:	 Determine 2 folds
2017-09-22 15:30:45,224 INFO: Done:	 Classification
2017-09-22 15:30:45,775 INFO: Done:	 Classification
2017-09-22 15:30:46,324 INFO: Done:	 Classification
2017-09-22 15:30:46,863 INFO: Done:	 Classification
2017-09-22 15:30:47,410 INFO: Done:	 Classification
2017-09-22 15:30:47,410 INFO: Info:	 Time for Classification: 59[s]
2017-09-22 15:30:47,410 INFO: Start:	 Result Analysis for Fusion
2017-09-22 15:30:48,065 INFO: 		Result for Multiview classification with EarlyFusion

Average accuracy_score :
	-On Train : 0.898955613577
	-On Test : 0.753987730061

Dataset info :
	-Database name : awaexp
	-Labels : 
	-Views : cq-hist, lss-hist
	-2 folds

Classification configuration : 
	-Algorithm used : EarlyFusion with weighted concatenation, using weights : 0.880915616157, 1.0 with monoview classifier : 
		- SGDClassifier with loss : log, penalty : l2

	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 0.898955613577 with STD : 0.0718210275075
		- Score on test : 0.753987730061 with STD : 0.037084861987

	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.908951683797 with STD : 0.0540728241158
		- Score on test : 0.763621260416 with STD : 0.00772558921165

	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 0.908951683797 with STD : 0.0540728241158
		- Score on test : 0.763621260416 with STD : 0.00772558921165

	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.101044386423 with STD : 0.0718210275075
		- Score on test : 0.246012269939 with STD : 0.037084861987

	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 0.898955613577 with STD : 0.0718210275075
		- Score on test : 0.753987730061 with STD : 0.037084861987

	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 0.813276317483 with STD : 0.116263516032
		- Score on test : 0.524172372511 with STD : 0.0514608194751

	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.878849832215 with STD : 0.107924714973
		- Score on test : 0.753947637281 with STD : 0.0775135641749

	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.952480417755 with STD : 0.0242918085632
		- Score on test : 0.791411042945 with STD : 0.0870214636883

	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 0.898955613577 with STD : 0.0718210275075
		- Score on test : 0.753987730061 with STD : 0.037084861987

	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.101044386423 with STD : 0.0718210275075
		- Score on test : 0.246012269939 with STD : 0.037084861987


2017-09-22 15:30:48,065 INFO: Done:	 Result Analysis
2017-09-22 15:31:23,834 INFO: Done:	 Classification
2017-09-22 15:31:24,749 INFO: Done:	 Classification
2017-09-22 15:31:25,649 INFO: Done:	 Classification
2017-09-22 15:31:26,560 INFO: Done:	 Classification
2017-09-22 15:31:27,480 INFO: Done:	 Classification
2017-09-22 15:31:27,481 INFO: Info:	 Time for Classification: 99[s]
2017-09-22 15:31:27,481 INFO: Start:	 Result Analysis for Fusion
2017-09-22 15:31:27,949 INFO: 		Result for Multiview classification with EarlyFusion

Average accuracy_score :
	-On Train : 0.5
	-On Test : 0.5

Dataset info :
	-Database name : awaexp
	-Labels : 
	-Views : cq-hist, lss-hist
	-2 folds

Classification configuration : 
	-Algorithm used : EarlyFusion with weighted concatenation, using weights : 0.880915616157, 1.0 with monoview classifier : 
		- SCM with max_attributes : 1

	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 0.5 with STD : 0.0
		- Score on test : 0.5 with STD : 0.0

	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.0 with STD : 0.0
		- Score on test : 0.0 with STD : 0.0

	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 0.0 with STD : 0.0
		- Score on test : 0.0 with STD : 0.0

	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.5 with STD : 0.0
		- Score on test : 0.5 with STD : 0.0

	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 0.5 with STD : 0.0
		- Score on test : 0.5 with STD : 0.0

	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 0.0 with STD : 0.0
		- Score on test : 0.0 with STD : 0.0

	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.0 with STD : 0.0
		- Score on test : 0.0 with STD : 0.0

	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.0 with STD : 0.0
		- Score on test : 0.0 with STD : 0.0

	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 0.5 with STD : 0.0
		- Score on test : 0.5 with STD : 0.0

	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.5 with STD : 0.0
		- Score on test : 0.5 with STD : 0.0


2017-09-22 15:31:27,950 INFO: Done:	 Result Analysis
2017-09-22 15:31:33,986 INFO: Done:	 Classification
2017-09-22 15:31:34,595 INFO: Done:	 Classification
2017-09-22 15:31:35,243 INFO: Done:	 Classification
2017-09-22 15:31:35,854 INFO: Done:	 Classification
2017-09-22 15:31:36,474 INFO: Done:	 Classification
2017-09-22 15:31:36,474 INFO: Info:	 Time for Classification: 108[s]
2017-09-22 15:31:36,474 INFO: Start:	 Result Analysis for Fusion
2017-09-22 15:31:36,878 INFO: 		Result for Multiview classification with EarlyFusion

Average accuracy_score :
	-On Train : 0.915143603133
	-On Test : 0.741717791411

Dataset info :
	-Database name : awaexp
	-Labels : 
	-Views : cq-hist, lss-hist
	-2 folds

Classification configuration : 
	-Algorithm used : EarlyFusion with weighted concatenation, using weights : 0.880915616157, 1.0 with monoview classifier : 
		- Random Forest with num_esimators : 25, max_depth : 5

	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 0.915143603133 with STD : 0.00340428324031
		- Score on test : 0.741717791411 with STD : 0.00785659415636

	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.911464433058 with STD : 0.00359680668862
		- Score on test : 0.738297988431 with STD : 0.00916250860792

	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 0.911464433058 with STD : 0.00359680668862
		- Score on test : 0.738297988431 with STD : 0.00916250860792

	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.0848563968668 with STD : 0.00340428324031
		- Score on test : 0.258282208589 with STD : 0.00785659415636

	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 0.915143603133 with STD : 0.00340428324031
		- Score on test : 0.741717791411 with STD : 0.00785659415636

	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 0.833242709103 with STD : 0.00688042213647
		- Score on test : 0.483653710409 with STD : 0.0156462607003

	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.952834664301 with STD : 0.00775427616681
		- Score on test : 0.7481099822 with STD : 0.00693626746348

	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.87362924282 with STD : 0.00749488255583
		- Score on test : 0.728834355828 with STD : 0.0136632254303

	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 0.915143603133 with STD : 0.00340428324031
		- Score on test : 0.741717791411 with STD : 0.00785659415636

	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.0848563968668 with STD : 0.00340428324031
		- Score on test : 0.258282208589 with STD : 0.00785659415636


2017-09-22 15:31:36,878 INFO: Done:	 Result Analysis

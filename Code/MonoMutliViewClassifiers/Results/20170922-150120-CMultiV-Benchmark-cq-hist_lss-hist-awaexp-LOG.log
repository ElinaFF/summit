2017-09-22 15:01:26,012 DEBUG: Info:	 Enough copies of the dataset are already available
2017-09-22 15:01:26,014 INFO: Start:	 Finding all available mono- & multiview algorithms
2017-09-22 15:01:26,083 DEBUG: Start:	 Loading data
2017-09-22 15:01:26,083 DEBUG: Start:	 Loading data
2017-09-22 15:01:26,096 DEBUG: Done:	 Loading data
2017-09-22 15:01:26,096 DEBUG: Done:	 Loading data
2017-09-22 15:01:26,096 DEBUG: Info:	 Classification - Database:awaexp Feature:cq-hist train_size:0.7, CrossValidation k-folds:2, cores:1, algorithm : DecisionTree
2017-09-22 15:01:26,096 DEBUG: Info:	 Classification - Database:awaexp Feature:cq-hist train_size:0.7, CrossValidation k-folds:2, cores:1, algorithm : Adaboost
2017-09-22 15:01:26,096 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 15:01:26,096 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 15:01:26,130 DEBUG: Info:	 Shape X_train:(766, 2688), Length of y_train:766
2017-09-22 15:01:26,130 DEBUG: Info:	 Shape X_train:(766, 2688), Length of y_train:766
2017-09-22 15:01:26,130 DEBUG: Info:	 Shape X_test:(326, 2688), Length of y_test:326
2017-09-22 15:01:26,130 DEBUG: Done:	 Determine Train/Test split
2017-09-22 15:01:26,130 DEBUG: Info:	 Shape X_test:(326, 2688), Length of y_test:326
2017-09-22 15:01:26,131 DEBUG: Done:	 Determine Train/Test split
2017-09-22 15:01:26,131 DEBUG: Start:	 RandomSearch best settings with 2 iterations for Adaboost
2017-09-22 15:01:26,131 DEBUG: Start:	 RandomSearch best settings with 2 iterations for DecisionTree
2017-09-22 15:01:29,195 DEBUG: Done:	 RandomSearch best settings
2017-09-22 15:01:29,195 DEBUG: Start:	 Training
2017-09-22 15:01:29,224 DEBUG: Done:	 RandomSearch best settings
2017-09-22 15:01:29,225 DEBUG: Start:	 Training
2017-09-22 15:01:30,013 DEBUG: Done:	 Training
2017-09-22 15:01:30,014 DEBUG: Start:	 Predicting
2017-09-22 15:01:30,032 DEBUG: Done:	 Predicting
2017-09-22 15:01:30,032 DEBUG: Info:	 Time for training and predicting: 3.94928002357[s]
2017-09-22 15:01:30,032 DEBUG: Start:	 Getting Results
2017-09-22 15:01:30,062 DEBUG: Done:	 Getting Results
2017-09-22 15:01:30,062 INFO: Classification on awaexp database for cq-hist with Adaboost, and 2 statistical iterations

accuracy_score on train : 1.0, with STD : 0.0
accuracy_score on test : 0.647239263804, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : cq-hist	 View shape : (1092, 2688)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 2

Classifier configuration : 
	- Adaboost with num_esimators : 10, base_estimators : DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best')
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 2 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.647239263804
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.654654654655
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.654654654655
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.0
		- Score on test : 0.352760736196
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.647239263804
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.294750450473
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.641176470588
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.668711656442
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.647239263804
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.0
		- Score on test : 0.352760736196


 Classification took 0:00:03
2017-09-22 15:01:30,062 INFO: Done:	 Result Analysis
2017-09-22 15:01:30,110 DEBUG: Done:	 Training
2017-09-22 15:01:30,110 DEBUG: Start:	 Predicting
2017-09-22 15:01:30,124 DEBUG: Done:	 Predicting
2017-09-22 15:01:30,124 DEBUG: Info:	 Time for training and predicting: 4.04104685783[s]
2017-09-22 15:01:30,124 DEBUG: Start:	 Getting Results
2017-09-22 15:01:30,151 DEBUG: Done:	 Getting Results
2017-09-22 15:01:30,151 INFO: Classification on awaexp database for cq-hist with DecisionTree, and 2 statistical iterations

accuracy_score on train : 1.0, with STD : 0.0
accuracy_score on test : 0.628834355828, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : cq-hist	 View shape : (1092, 2688)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 2

Classifier configuration : 
	- Decision Tree with max_depth : 26
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 2 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.628834355828
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.627692307692
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.627692307692
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.0
		- Score on test : 0.371165644172
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.628834355828
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.257673560841
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.62962962963
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.625766871166
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.628834355828
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.0
		- Score on test : 0.371165644172


 Classification took 0:00:04
2017-09-22 15:01:30,151 INFO: Done:	 Result Analysis
2017-09-22 15:01:30,250 DEBUG: Start:	 Loading data
2017-09-22 15:01:30,250 DEBUG: Start:	 Loading data
2017-09-22 15:01:30,263 DEBUG: Done:	 Loading data
2017-09-22 15:01:30,263 DEBUG: Done:	 Loading data
2017-09-22 15:01:30,263 DEBUG: Info:	 Classification - Database:awaexp Feature:cq-hist train_size:0.7, CrossValidation k-folds:2, cores:1, algorithm : KNN
2017-09-22 15:01:30,263 DEBUG: Info:	 Classification - Database:awaexp Feature:cq-hist train_size:0.7, CrossValidation k-folds:2, cores:1, algorithm : RandomForest
2017-09-22 15:01:30,263 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 15:01:30,263 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 15:01:30,296 DEBUG: Info:	 Shape X_train:(766, 2688), Length of y_train:766
2017-09-22 15:01:30,297 DEBUG: Info:	 Shape X_test:(326, 2688), Length of y_test:326
2017-09-22 15:01:30,297 DEBUG: Done:	 Determine Train/Test split
2017-09-22 15:01:30,297 DEBUG: Start:	 RandomSearch best settings with 2 iterations for RandomForest
2017-09-22 15:01:30,298 DEBUG: Info:	 Shape X_train:(766, 2688), Length of y_train:766
2017-09-22 15:01:30,298 DEBUG: Info:	 Shape X_test:(326, 2688), Length of y_test:326
2017-09-22 15:01:30,298 DEBUG: Done:	 Determine Train/Test split
2017-09-22 15:01:30,298 DEBUG: Start:	 RandomSearch best settings with 2 iterations for KNN
2017-09-22 15:01:31,490 DEBUG: Done:	 RandomSearch best settings
2017-09-22 15:01:31,490 DEBUG: Start:	 Training
2017-09-22 15:01:31,817 DEBUG: Done:	 Training
2017-09-22 15:01:31,817 DEBUG: Start:	 Predicting
2017-09-22 15:01:31,891 DEBUG: Done:	 Predicting
2017-09-22 15:01:31,891 DEBUG: Info:	 Time for training and predicting: 1.64091086388[s]
2017-09-22 15:01:31,891 DEBUG: Start:	 Getting Results
2017-09-22 15:01:31,926 DEBUG: Done:	 Getting Results
2017-09-22 15:01:31,926 INFO: Classification on awaexp database for cq-hist with RandomForest, and 2 statistical iterations

accuracy_score on train : 0.998694516971, with STD : 0.0
accuracy_score on test : 0.742331288344, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : cq-hist	 View shape : (1092, 2688)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 2

Classifier configuration : 
	- Random Forest with num_esimators : 15, max_depth : 26
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 2 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 0.998694516971
		- Score on test : 0.742331288344
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.998692810458
		- Score on test : 0.732484076433
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 0.998692810458
		- Score on test : 0.732484076433
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.00130548302872
		- Score on test : 0.257668711656
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 0.998694516971
		- Score on test : 0.742331288344
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 0.997392433632
		- Score on test : 0.485981339017
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.761589403974
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.997389033943
		- Score on test : 0.705521472393
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 0.998694516971
		- Score on test : 0.742331288344
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.00130548302872
		- Score on test : 0.257668711656


 Classification took 0:00:01
2017-09-22 15:01:31,926 INFO: Done:	 Result Analysis
2017-09-22 15:01:33,540 DEBUG: Done:	 RandomSearch best settings
2017-09-22 15:01:33,540 DEBUG: Start:	 Training
2017-09-22 15:01:33,591 DEBUG: Done:	 Training
2017-09-22 15:01:33,591 DEBUG: Start:	 Predicting
2017-09-22 15:01:40,710 DEBUG: Done:	 Predicting
2017-09-22 15:01:40,711 DEBUG: Info:	 Time for training and predicting: 10.4605879784[s]
2017-09-22 15:01:40,711 DEBUG: Start:	 Getting Results
2017-09-22 15:01:40,738 DEBUG: Done:	 Getting Results
2017-09-22 15:01:40,738 INFO: Classification on awaexp database for cq-hist with KNN, and 2 statistical iterations

accuracy_score on train : 0.689295039164, with STD : 0.0
accuracy_score on test : 0.638036809816, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : cq-hist	 View shape : (1092, 2688)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 2

Classifier configuration : 
	- K nearest Neighbors with  n_neighbors: 15
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 2 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 0.689295039164
		- Score on test : 0.638036809816
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.739035087719
		- Score on test : 0.70202020202
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 0.739035087719
		- Score on test : 0.70202020202
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.310704960836
		- Score on test : 0.361963190184
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 0.689295039164
		- Score on test : 0.638036809816
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 0.409511397204
		- Score on test : 0.305698338982
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.637051039698
		- Score on test : 0.596566523605
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.879895561358
		- Score on test : 0.852760736196
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 0.689295039164
		- Score on test : 0.638036809816
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.310704960836
		- Score on test : 0.361963190184


 Classification took 0:00:10
2017-09-22 15:01:40,738 INFO: Done:	 Result Analysis
2017-09-22 15:01:40,830 DEBUG: Start:	 Loading data
2017-09-22 15:01:40,830 DEBUG: Start:	 Loading data
2017-09-22 15:01:40,843 DEBUG: Done:	 Loading data
2017-09-22 15:01:40,843 DEBUG: Done:	 Loading data
2017-09-22 15:01:40,844 DEBUG: Info:	 Classification - Database:awaexp Feature:cq-hist train_size:0.7, CrossValidation k-folds:2, cores:1, algorithm : SVMLinear
2017-09-22 15:01:40,844 DEBUG: Info:	 Classification - Database:awaexp Feature:cq-hist train_size:0.7, CrossValidation k-folds:2, cores:1, algorithm : SGD
2017-09-22 15:01:40,844 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 15:01:40,844 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 15:01:40,877 DEBUG: Info:	 Shape X_train:(766, 2688), Length of y_train:766
2017-09-22 15:01:40,877 DEBUG: Info:	 Shape X_test:(326, 2688), Length of y_test:326
2017-09-22 15:01:40,877 DEBUG: Done:	 Determine Train/Test split
2017-09-22 15:01:40,877 DEBUG: Start:	 RandomSearch best settings with 2 iterations for SGD
2017-09-22 15:01:40,878 DEBUG: Info:	 Shape X_train:(766, 2688), Length of y_train:766
2017-09-22 15:01:40,878 DEBUG: Info:	 Shape X_test:(326, 2688), Length of y_test:326
2017-09-22 15:01:40,878 DEBUG: Done:	 Determine Train/Test split
2017-09-22 15:01:40,878 DEBUG: Start:	 RandomSearch best settings with 2 iterations for SVMLinear
2017-09-22 15:01:41,486 DEBUG: Done:	 RandomSearch best settings
2017-09-22 15:01:41,487 DEBUG: Start:	 Training
2017-09-22 15:01:41,634 DEBUG: Done:	 Training
2017-09-22 15:01:41,634 DEBUG: Start:	 Predicting
2017-09-22 15:01:41,643 DEBUG: Done:	 Predicting
2017-09-22 15:01:41,643 DEBUG: Info:	 Time for training and predicting: 0.812498092651[s]
2017-09-22 15:01:41,643 DEBUG: Start:	 Getting Results
2017-09-22 15:01:41,674 DEBUG: Done:	 Getting Results
2017-09-22 15:01:41,674 INFO: Classification on awaexp database for cq-hist with SGD, and 2 statistical iterations

accuracy_score on train : 0.72454308094, with STD : 0.0
accuracy_score on test : 0.671779141104, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : cq-hist	 View shape : (1092, 2688)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 2

Classifier configuration : 
	- SGDClassifier with loss : log, penalty : elasticnet
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 2 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 0.72454308094
		- Score on test : 0.671779141104
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.720529801325
		- Score on test : 0.676737160121
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 0.720529801325
		- Score on test : 0.676737160121
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.27545691906
		- Score on test : 0.328220858896
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 0.72454308094
		- Score on test : 0.671779141104
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 0.449271496384
		- Score on test : 0.343720031298
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.731182795699
		- Score on test : 0.666666666667
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.710182767624
		- Score on test : 0.687116564417
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 0.72454308094
		- Score on test : 0.671779141104
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.27545691906
		- Score on test : 0.328220858896


 Classification took 0:00:00
2017-09-22 15:01:41,675 INFO: Done:	 Result Analysis
2017-09-22 15:01:44,617 DEBUG: Done:	 RandomSearch best settings
2017-09-22 15:01:44,617 DEBUG: Start:	 Training
2017-09-22 15:01:50,152 DEBUG: Done:	 Training
2017-09-22 15:01:50,153 DEBUG: Start:	 Predicting
2017-09-22 15:01:53,024 DEBUG: Done:	 Predicting
2017-09-22 15:01:53,025 DEBUG: Info:	 Time for training and predicting: 12.1938760281[s]
2017-09-22 15:01:53,025 DEBUG: Start:	 Getting Results
2017-09-22 15:01:53,051 DEBUG: Done:	 Getting Results
2017-09-22 15:01:53,051 INFO: Classification on awaexp database for cq-hist with SVMLinear, and 2 statistical iterations

accuracy_score on train : 1.0, with STD : 0.0
accuracy_score on test : 0.653374233129, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : cq-hist	 View shape : (1092, 2688)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 2

Classifier configuration : 
	- SVM Linear with C : 2330
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 2 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.653374233129
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.666666666667
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.666666666667
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.0
		- Score on test : 0.346625766871
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.653374233129
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.307728727448
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.642045454545
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.693251533742
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.653374233129
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.0
		- Score on test : 0.346625766871


 Classification took 0:00:12
2017-09-22 15:01:53,052 INFO: Done:	 Result Analysis
2017-09-22 15:01:53,216 DEBUG: Start:	 Loading data
2017-09-22 15:01:53,217 DEBUG: Start:	 Loading data
2017-09-22 15:01:53,230 DEBUG: Done:	 Loading data
2017-09-22 15:01:53,230 DEBUG: Done:	 Loading data
2017-09-22 15:01:53,230 DEBUG: Info:	 Classification - Database:awaexp Feature:cq-hist train_size:0.7, CrossValidation k-folds:2, cores:1, algorithm : SVMPoly
2017-09-22 15:01:53,230 DEBUG: Info:	 Classification - Database:awaexp Feature:cq-hist train_size:0.7, CrossValidation k-folds:2, cores:1, algorithm : SVMRBF
2017-09-22 15:01:53,230 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 15:01:53,230 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 15:01:53,264 DEBUG: Info:	 Shape X_train:(766, 2688), Length of y_train:766
2017-09-22 15:01:53,264 DEBUG: Info:	 Shape X_test:(326, 2688), Length of y_test:326
2017-09-22 15:01:53,264 DEBUG: Done:	 Determine Train/Test split
2017-09-22 15:01:53,264 DEBUG: Start:	 RandomSearch best settings with 2 iterations for SVMRBF
2017-09-22 15:01:53,265 DEBUG: Info:	 Shape X_train:(766, 2688), Length of y_train:766
2017-09-22 15:01:53,265 DEBUG: Info:	 Shape X_test:(326, 2688), Length of y_test:326
2017-09-22 15:01:53,265 DEBUG: Done:	 Determine Train/Test split
2017-09-22 15:01:53,265 DEBUG: Start:	 RandomSearch best settings with 2 iterations for SVMPoly
2017-09-22 15:01:59,955 DEBUG: Done:	 RandomSearch best settings
2017-09-22 15:01:59,955 DEBUG: Start:	 Training
2017-09-22 15:02:02,365 DEBUG: Done:	 RandomSearch best settings
2017-09-22 15:02:02,366 DEBUG: Start:	 Training
2017-09-22 15:02:10,969 DEBUG: Done:	 Training
2017-09-22 15:02:10,969 DEBUG: Start:	 Predicting
2017-09-22 15:02:17,000 DEBUG: Done:	 Predicting
2017-09-22 15:02:17,001 DEBUG: Info:	 Time for training and predicting: 23.7835571766[s]
2017-09-22 15:02:17,001 DEBUG: Start:	 Getting Results
2017-09-22 15:02:17,046 DEBUG: Done:	 Getting Results
2017-09-22 15:02:17,046 INFO: Classification on awaexp database for cq-hist with SVMRBF, and 2 statistical iterations

accuracy_score on train : 0.926892950392, with STD : 0.0
accuracy_score on test : 0.674846625767, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : cq-hist	 View shape : (1092, 2688)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 2

Classifier configuration : 
	- SVM RBF with C : 2330
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 2 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 0.926892950392
		- Score on test : 0.674846625767
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.927648578811
		- Score on test : 0.684523809524
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 0.927648578811
		- Score on test : 0.684523809524
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.0731070496084
		- Score on test : 0.325153374233
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 0.926892950392
		- Score on test : 0.674846625767
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 0.85397221395
		- Score on test : 0.350353200131
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.918158567775
		- Score on test : 0.664739884393
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.937336814621
		- Score on test : 0.705521472393
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 0.926892950392
		- Score on test : 0.674846625767
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.0731070496084
		- Score on test : 0.325153374233


 Classification took 0:00:23
2017-09-22 15:02:17,047 INFO: Done:	 Result Analysis
2017-09-22 15:02:17,195 DEBUG: Done:	 Training
2017-09-22 15:02:17,195 DEBUG: Start:	 Predicting
2017-09-22 15:02:21,914 DEBUG: Done:	 Predicting
2017-09-22 15:02:21,914 DEBUG: Info:	 Time for training and predicting: 28.6970870495[s]
2017-09-22 15:02:21,915 DEBUG: Start:	 Getting Results
2017-09-22 15:02:21,947 DEBUG: Done:	 Getting Results
2017-09-22 15:02:21,947 INFO: Classification on awaexp database for cq-hist with SVMPoly, and 2 statistical iterations

accuracy_score on train : 0.934725848564, with STD : 0.0
accuracy_score on test : 0.546012269939, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : cq-hist	 View shape : (1092, 2688)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 2

Classifier configuration : 
	- SVM Poly with C : 2330
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 2 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 0.934725848564
		- Score on test : 0.546012269939
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.931129476584
		- Score on test : 0.350877192982
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 0.931129476584
		- Score on test : 0.350877192982
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.065274151436
		- Score on test : 0.453987730061
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 0.934725848564
		- Score on test : 0.546012269939
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 0.874232585037
		- Score on test : 0.115163359926
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.985422740525
		- Score on test : 0.615384615385
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.882506527415
		- Score on test : 0.245398773006
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 0.934725848564
		- Score on test : 0.546012269939
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.065274151436
		- Score on test : 0.453987730061


 Classification took 0:00:28
2017-09-22 15:02:21,948 INFO: Done:	 Result Analysis
2017-09-22 15:02:22,034 DEBUG: Start:	 Loading data
2017-09-22 15:02:22,035 DEBUG: Start:	 Loading data
2017-09-22 15:02:22,045 DEBUG: Done:	 Loading data
2017-09-22 15:02:22,045 DEBUG: Done:	 Loading data
2017-09-22 15:02:22,045 DEBUG: Info:	 Classification - Database:awaexp Feature:lss-hist train_size:0.7, CrossValidation k-folds:2, cores:1, algorithm : Adaboost
2017-09-22 15:02:22,046 DEBUG: Info:	 Classification - Database:awaexp Feature:lss-hist train_size:0.7, CrossValidation k-folds:2, cores:1, algorithm : DecisionTree
2017-09-22 15:02:22,046 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 15:02:22,046 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 15:02:22,073 DEBUG: Info:	 Shape X_train:(766, 2000), Length of y_train:766
2017-09-22 15:02:22,073 DEBUG: Info:	 Shape X_test:(326, 2000), Length of y_test:326
2017-09-22 15:02:22,074 DEBUG: Done:	 Determine Train/Test split
2017-09-22 15:02:22,074 DEBUG: Start:	 RandomSearch best settings with 2 iterations for DecisionTree
2017-09-22 15:02:22,074 DEBUG: Info:	 Shape X_train:(766, 2000), Length of y_train:766
2017-09-22 15:02:22,074 DEBUG: Info:	 Shape X_test:(326, 2000), Length of y_test:326
2017-09-22 15:02:22,075 DEBUG: Done:	 Determine Train/Test split
2017-09-22 15:02:22,075 DEBUG: Start:	 RandomSearch best settings with 2 iterations for Adaboost
2017-09-22 15:02:23,764 DEBUG: Done:	 RandomSearch best settings
2017-09-22 15:02:23,764 DEBUG: Start:	 Training
2017-09-22 15:02:23,825 DEBUG: Done:	 RandomSearch best settings
2017-09-22 15:02:23,825 DEBUG: Start:	 Training
2017-09-22 15:02:24,472 DEBUG: Done:	 Training
2017-09-22 15:02:24,472 DEBUG: Start:	 Predicting
2017-09-22 15:02:24,474 DEBUG: Done:	 Training
2017-09-22 15:02:24,474 DEBUG: Start:	 Predicting
2017-09-22 15:02:24,488 DEBUG: Done:	 Predicting
2017-09-22 15:02:24,488 DEBUG: Info:	 Time for training and predicting: 2.45340418816[s]
2017-09-22 15:02:24,489 DEBUG: Start:	 Getting Results
2017-09-22 15:02:24,492 DEBUG: Done:	 Predicting
2017-09-22 15:02:24,492 DEBUG: Info:	 Time for training and predicting: 2.45775198936[s]
2017-09-22 15:02:24,493 DEBUG: Start:	 Getting Results
2017-09-22 15:02:24,532 DEBUG: Done:	 Getting Results
2017-09-22 15:02:24,532 INFO: Classification on awaexp database for lss-hist with DecisionTree, and 2 statistical iterations

accuracy_score on train : 1.0, with STD : 0.0
accuracy_score on test : 0.662576687117, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : lss-hist	 View shape : (1092, 2000)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 2

Classifier configuration : 
	- Decision Tree with max_depth : 26
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 2 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.662576687117
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.670658682635
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.670658682635
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.0
		- Score on test : 0.337423312883
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.662576687117
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.325545701512
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.654970760234
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.687116564417
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.662576687117
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.0
		- Score on test : 0.337423312883


 Classification took 0:00:02
2017-09-22 15:02:24,532 INFO: Done:	 Result Analysis
2017-09-22 15:02:24,536 DEBUG: Done:	 Getting Results
2017-09-22 15:02:24,537 INFO: Classification on awaexp database for lss-hist with Adaboost, and 2 statistical iterations

accuracy_score on train : 1.0, with STD : 0.0
accuracy_score on test : 0.634969325153, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : lss-hist	 View shape : (1092, 2000)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 2

Classifier configuration : 
	- Adaboost with num_esimators : 10, base_estimators : DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best')
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 2 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.634969325153
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.624605678233
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.624605678233
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.0
		- Score on test : 0.365030674847
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.634969325153
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.270351069901
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.642857142857
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.60736196319
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.634969325153
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.0
		- Score on test : 0.365030674847


 Classification took 0:00:02
2017-09-22 15:02:24,537 INFO: Done:	 Result Analysis
2017-09-22 15:02:24,694 DEBUG: Start:	 Loading data
2017-09-22 15:02:24,694 DEBUG: Start:	 Loading data
2017-09-22 15:02:24,705 DEBUG: Done:	 Loading data
2017-09-22 15:02:24,705 DEBUG: Done:	 Loading data
2017-09-22 15:02:24,705 DEBUG: Info:	 Classification - Database:awaexp Feature:lss-hist train_size:0.7, CrossValidation k-folds:2, cores:1, algorithm : RandomForest
2017-09-22 15:02:24,705 DEBUG: Info:	 Classification - Database:awaexp Feature:lss-hist train_size:0.7, CrossValidation k-folds:2, cores:1, algorithm : KNN
2017-09-22 15:02:24,705 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 15:02:24,705 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 15:02:24,734 DEBUG: Info:	 Shape X_train:(766, 2000), Length of y_train:766
2017-09-22 15:02:24,734 DEBUG: Info:	 Shape X_test:(326, 2000), Length of y_test:326
2017-09-22 15:02:24,734 DEBUG: Done:	 Determine Train/Test split
2017-09-22 15:02:24,735 DEBUG: Start:	 RandomSearch best settings with 2 iterations for RandomForest
2017-09-22 15:02:24,735 DEBUG: Info:	 Shape X_train:(766, 2000), Length of y_train:766
2017-09-22 15:02:24,735 DEBUG: Info:	 Shape X_test:(326, 2000), Length of y_test:326
2017-09-22 15:02:24,735 DEBUG: Done:	 Determine Train/Test split
2017-09-22 15:02:24,736 DEBUG: Start:	 RandomSearch best settings with 2 iterations for KNN
2017-09-22 15:02:25,705 DEBUG: Done:	 RandomSearch best settings
2017-09-22 15:02:25,706 DEBUG: Start:	 Training
2017-09-22 15:02:25,948 DEBUG: Done:	 Training
2017-09-22 15:02:25,948 DEBUG: Start:	 Predicting
2017-09-22 15:02:26,015 DEBUG: Done:	 Predicting
2017-09-22 15:02:26,015 DEBUG: Info:	 Time for training and predicting: 1.32054591179[s]
2017-09-22 15:02:26,015 DEBUG: Start:	 Getting Results
2017-09-22 15:02:26,057 DEBUG: Done:	 Getting Results
2017-09-22 15:02:26,057 INFO: Classification on awaexp database for lss-hist with RandomForest, and 2 statistical iterations

accuracy_score on train : 0.998694516971, with STD : 0.0
accuracy_score on test : 0.687116564417, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : lss-hist	 View shape : (1092, 2000)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 2

Classifier configuration : 
	- Random Forest with num_esimators : 15, max_depth : 26
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 2 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 0.998694516971
		- Score on test : 0.687116564417
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.998692810458
		- Score on test : 0.692771084337
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 0.998692810458
		- Score on test : 0.692771084337
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.00130548302872
		- Score on test : 0.312883435583
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 0.998694516971
		- Score on test : 0.687116564417
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 0.997392433632
		- Score on test : 0.374486922712
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.680473372781
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.997389033943
		- Score on test : 0.705521472393
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 0.998694516971
		- Score on test : 0.687116564417
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.00130548302872
		- Score on test : 0.312883435583


 Classification took 0:00:01
2017-09-22 15:02:26,057 INFO: Done:	 Result Analysis
2017-09-22 15:02:27,144 DEBUG: Done:	 RandomSearch best settings
2017-09-22 15:02:27,144 DEBUG: Start:	 Training
2017-09-22 15:02:27,173 DEBUG: Done:	 Training
2017-09-22 15:02:27,173 DEBUG: Start:	 Predicting
2017-09-22 15:02:32,275 DEBUG: Done:	 Predicting
2017-09-22 15:02:32,275 DEBUG: Info:	 Time for training and predicting: 7.58051395416[s]
2017-09-22 15:02:32,275 DEBUG: Start:	 Getting Results
2017-09-22 15:02:32,312 DEBUG: Done:	 Getting Results
2017-09-22 15:02:32,312 INFO: Classification on awaexp database for lss-hist with KNN, and 2 statistical iterations

accuracy_score on train : 0.711488250653, with STD : 0.0
accuracy_score on test : 0.696319018405, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : lss-hist	 View shape : (1092, 2000)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 2

Classifier configuration : 
	- K nearest Neighbors with  n_neighbors: 15
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 2 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 0.711488250653
		- Score on test : 0.696319018405
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.690042075736
		- Score on test : 0.650176678445
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 0.690042075736
		- Score on test : 0.650176678445
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.288511749347
		- Score on test : 0.303680981595
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 0.711488250653
		- Score on test : 0.696319018405
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 0.427085473492
		- Score on test : 0.407057481052
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.745454545455
		- Score on test : 0.766666666667
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.642297650131
		- Score on test : 0.564417177914
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 0.711488250653
		- Score on test : 0.696319018405
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.288511749347
		- Score on test : 0.303680981595


 Classification took 0:00:07
2017-09-22 15:02:32,313 INFO: Done:	 Result Analysis
2017-09-22 15:02:32,473 DEBUG: Start:	 Loading data
2017-09-22 15:02:32,473 DEBUG: Start:	 Loading data
2017-09-22 15:02:32,483 DEBUG: Done:	 Loading data
2017-09-22 15:02:32,483 DEBUG: Done:	 Loading data
2017-09-22 15:02:32,483 DEBUG: Info:	 Classification - Database:awaexp Feature:lss-hist train_size:0.7, CrossValidation k-folds:2, cores:1, algorithm : SVMLinear
2017-09-22 15:02:32,483 DEBUG: Info:	 Classification - Database:awaexp Feature:lss-hist train_size:0.7, CrossValidation k-folds:2, cores:1, algorithm : SGD
2017-09-22 15:02:32,483 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 15:02:32,483 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 15:02:32,511 DEBUG: Info:	 Shape X_train:(766, 2000), Length of y_train:766
2017-09-22 15:02:32,511 DEBUG: Info:	 Shape X_test:(326, 2000), Length of y_test:326
2017-09-22 15:02:32,511 DEBUG: Done:	 Determine Train/Test split
2017-09-22 15:02:32,511 DEBUG: Start:	 RandomSearch best settings with 2 iterations for SVMLinear
2017-09-22 15:02:32,511 DEBUG: Info:	 Shape X_train:(766, 2000), Length of y_train:766
2017-09-22 15:02:32,512 DEBUG: Info:	 Shape X_test:(326, 2000), Length of y_test:326
2017-09-22 15:02:32,512 DEBUG: Done:	 Determine Train/Test split
2017-09-22 15:02:32,512 DEBUG: Start:	 RandomSearch best settings with 2 iterations for SGD
2017-09-22 15:02:32,894 DEBUG: Done:	 RandomSearch best settings
2017-09-22 15:02:32,895 DEBUG: Start:	 Training
2017-09-22 15:02:32,994 DEBUG: Done:	 Training
2017-09-22 15:02:32,995 DEBUG: Start:	 Predicting
2017-09-22 15:02:33,002 DEBUG: Done:	 Predicting
2017-09-22 15:02:33,003 DEBUG: Info:	 Time for training and predicting: 0.529504060745[s]
2017-09-22 15:02:33,003 DEBUG: Start:	 Getting Results
2017-09-22 15:02:33,034 DEBUG: Done:	 Getting Results
2017-09-22 15:02:33,035 INFO: Classification on awaexp database for lss-hist with SGD, and 2 statistical iterations

accuracy_score on train : 0.94908616188, with STD : 0.0
accuracy_score on test : 0.78527607362, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : lss-hist	 View shape : (1092, 2000)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 2

Classifier configuration : 
	- SGDClassifier with loss : log, penalty : elasticnet
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 2 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 0.94908616188
		- Score on test : 0.78527607362
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.951188986233
		- Score on test : 0.802259887006
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 0.951188986233
		- Score on test : 0.802259887006
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.0509138381201
		- Score on test : 0.21472392638
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 0.94908616188
		- Score on test : 0.78527607362
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 0.901524959581
		- Score on test : 0.579161095181
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.913461538462
		- Score on test : 0.743455497382
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.992167101828
		- Score on test : 0.871165644172
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 0.94908616188
		- Score on test : 0.78527607362
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.0509138381201
		- Score on test : 0.21472392638


 Classification took 0:00:00
2017-09-22 15:02:33,035 INFO: Done:	 Result Analysis
2017-09-22 15:02:34,972 DEBUG: Done:	 RandomSearch best settings
2017-09-22 15:02:34,972 DEBUG: Start:	 Training
2017-09-22 15:02:38,711 DEBUG: Done:	 Training
2017-09-22 15:02:38,711 DEBUG: Start:	 Predicting
2017-09-22 15:02:40,569 DEBUG: Done:	 Predicting
2017-09-22 15:02:40,570 DEBUG: Info:	 Time for training and predicting: 8.09667515755[s]
2017-09-22 15:02:40,570 DEBUG: Start:	 Getting Results
2017-09-22 15:02:40,597 DEBUG: Done:	 Getting Results
2017-09-22 15:02:40,597 INFO: Classification on awaexp database for lss-hist with SVMLinear, and 2 statistical iterations

accuracy_score on train : 1.0, with STD : 0.0
accuracy_score on test : 0.760736196319, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : lss-hist	 View shape : (1092, 2000)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 2

Classifier configuration : 
	- SVM Linear with C : 2330
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 2 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.760736196319
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.757763975155
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.757763975155
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.0
		- Score on test : 0.239263803681
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.760736196319
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.521629480383
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.767295597484
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.748466257669
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.760736196319
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.0
		- Score on test : 0.239263803681


 Classification took 0:00:08
2017-09-22 15:02:40,597 INFO: Done:	 Result Analysis
2017-09-22 15:02:40,747 DEBUG: Start:	 Loading data
2017-09-22 15:02:40,748 DEBUG: Start:	 Loading data
2017-09-22 15:02:40,758 DEBUG: Done:	 Loading data
2017-09-22 15:02:40,758 DEBUG: Done:	 Loading data
2017-09-22 15:02:40,758 DEBUG: Info:	 Classification - Database:awaexp Feature:lss-hist train_size:0.7, CrossValidation k-folds:2, cores:1, algorithm : SVMPoly
2017-09-22 15:02:40,758 DEBUG: Info:	 Classification - Database:awaexp Feature:lss-hist train_size:0.7, CrossValidation k-folds:2, cores:1, algorithm : SVMRBF
2017-09-22 15:02:40,759 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 15:02:40,759 DEBUG: Start:	 Determine Train/Test split for iteration 1
2017-09-22 15:02:40,785 DEBUG: Info:	 Shape X_train:(766, 2000), Length of y_train:766
2017-09-22 15:02:40,786 DEBUG: Info:	 Shape X_test:(326, 2000), Length of y_test:326
2017-09-22 15:02:40,786 DEBUG: Done:	 Determine Train/Test split
2017-09-22 15:02:40,786 DEBUG: Start:	 RandomSearch best settings with 2 iterations for SVMPoly
2017-09-22 15:02:40,787 DEBUG: Info:	 Shape X_train:(766, 2000), Length of y_train:766
2017-09-22 15:02:40,787 DEBUG: Info:	 Shape X_test:(326, 2000), Length of y_test:326
2017-09-22 15:02:40,788 DEBUG: Done:	 Determine Train/Test split
2017-09-22 15:02:40,788 DEBUG: Start:	 RandomSearch best settings with 2 iterations for SVMRBF
2017-09-22 15:02:44,010 DEBUG: Done:	 RandomSearch best settings
2017-09-22 15:02:44,010 DEBUG: Start:	 Training
2017-09-22 15:02:46,331 DEBUG: Done:	 RandomSearch best settings
2017-09-22 15:02:46,332 DEBUG: Start:	 Training
2017-09-22 15:02:47,036 DEBUG: Done:	 Training
2017-09-22 15:02:47,036 DEBUG: Start:	 Predicting
2017-09-22 15:02:48,488 DEBUG: Done:	 Predicting
2017-09-22 15:02:48,489 DEBUG: Info:	 Time for training and predicting: 7.74067902565[s]
2017-09-22 15:02:48,489 DEBUG: Start:	 Getting Results
2017-09-22 15:02:48,518 DEBUG: Done:	 Getting Results
2017-09-22 15:02:48,518 INFO: Classification on awaexp database for lss-hist with SVMPoly, and 2 statistical iterations

accuracy_score on train : 0.661879895561, with STD : 0.0
accuracy_score on test : 0.656441717791, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : lss-hist	 View shape : (1092, 2000)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 2

Classifier configuration : 
	- SVM Poly with C : 2330
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 2 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 0.661879895561
		- Score on test : 0.656441717791
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.681426814268
		- Score on test : 0.681818181818
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 0.681426814268
		- Score on test : 0.681818181818
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.338120104439
		- Score on test : 0.343558282209
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 0.661879895561
		- Score on test : 0.656441717791
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 0.32622543483
		- Score on test : 0.316941413476
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.644186046512
		- Score on test : 0.634920634921
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 0.723237597911
		- Score on test : 0.736196319018
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 0.661879895561
		- Score on test : 0.656441717791
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.338120104439
		- Score on test : 0.343558282209


 Classification took 0:00:07
2017-09-22 15:02:48,518 INFO: Done:	 Result Analysis
2017-09-22 15:02:52,780 DEBUG: Done:	 Training
2017-09-22 15:02:52,780 DEBUG: Start:	 Predicting
2017-09-22 15:02:56,290 DEBUG: Done:	 Predicting
2017-09-22 15:02:56,290 DEBUG: Info:	 Time for training and predicting: 15.5415859222[s]
2017-09-22 15:02:56,290 DEBUG: Start:	 Getting Results
2017-09-22 15:02:56,316 DEBUG: Done:	 Getting Results
2017-09-22 15:02:56,316 INFO: Classification on awaexp database for lss-hist with SVMRBF, and 2 statistical iterations

accuracy_score on train : 1.0, with STD : 0.0
accuracy_score on test : 0.521472392638, with STD : 0.0

Database configuration : 
	- Database name : awaexp
	- View name : lss-hist	 View shape : (1092, 2000)
	- Learning Rate : 0.7
	- Labels used : 
	- Number of cross validation folds : 2

Classifier configuration : 
	- SVM RBF with C : 2330
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 2 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.521472392638
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.669491525424
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, binary as average, 1.0 as beta (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.669491525424
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.0
		- Score on test : 0.478527607362
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.521472392638
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.0965815875096
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.511326860841
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.969325153374
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.521472392638
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.0
		- Score on test : 0.478527607362


 Classification took 0:00:15
2017-09-22 15:02:56,317 INFO: Done:	 Result Analysis
2017-09-22 15:02:56,431 INFO: ### Main Programm for Multiview Classification
2017-09-22 15:02:56,432 INFO: ### Classification - Database : awaexp ; Views : cq-hist, lss-hist ; Algorithm : Fusion ; Cores : 1
2017-09-22 15:02:56,433 INFO: ### Main Programm for Multiview Classification
2017-09-22 15:02:56,433 INFO: ### Classification - Database : awaexp ; Views : cq-hist, lss-hist ; Algorithm : Fusion ; Cores : 1
2017-09-22 15:02:56,434 INFO: Info:	 Shape of cq-hist :(1092, 2688)
2017-09-22 15:02:56,435 INFO: Info:	 Shape of cq-hist :(1092, 2688)
2017-09-22 15:02:56,435 INFO: Info:	 Shape of lss-hist :(1092, 2000)
2017-09-22 15:02:56,436 INFO: Done:	 Read Database Files
2017-09-22 15:02:56,436 INFO: Start:	 Determine validation split for ratio 0.7
2017-09-22 15:02:56,436 INFO: Info:	 Shape of lss-hist :(1092, 2000)
2017-09-22 15:02:56,436 INFO: Done:	 Read Database Files
2017-09-22 15:02:56,436 INFO: Start:	 Determine validation split for ratio 0.7

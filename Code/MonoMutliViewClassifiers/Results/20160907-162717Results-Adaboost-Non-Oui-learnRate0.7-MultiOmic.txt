Classification on MultiOmic database for Methyl with Adaboost

accuracy_score on train : 1.0
accuracy_score on test : 0.790476190476

Database configuration : 
	- Database name : MultiOmic
	- View name : Methyl	 View shape : (347, 25978)
	- Learning Rate : 0.7
	- Labels used : Non, Oui
	- Number of cross validation folds : 5

Classifier configuration : 
	- Adaboost with num_esimators : 14, base_estimators : DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,
            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best')
	- Executed on 1 core(s) 
	- Got configuration using randomized search with 1 iterations 


	For Accuracy score using None as sample_weights (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.790476190476
	For F1 score using None as sample_weights, None as labels, 1 as pos_label, micro as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.592592592593
	For F-beta score using None as sample_weights, None as labels, 1 as pos_label, micro as average, 1.0 as beta (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.592592592593
	For Hamming loss using None as classes (lower is better) : 
		- Score on train : 0.0
		- Score on test : 0.209523809524
	For Jaccard similarity score using None as sample_weights (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.790476190476
	For Log loss using None as sample_weights, 1e-15 as eps (lower is better) : 
		- Score on train : nan
		- Score on test : nan
	For Matthews correlation coefficient (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.482108339669
	For Precision score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.761904761905
	For Recall score using None as sample_weights, None as labels, 1 as pos_label, binary as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.484848484848
	For ROC AUC score using None as sample_weights, micro as average (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.707702020202
	For Zero one loss using None as sample_weights (lower is better) : 
		- Score on train : 0.0
		- Score on test : 0.209523809524


 Classification took 0:00:13